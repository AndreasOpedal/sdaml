{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import kurtosis,skew\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "import yasa\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_eeg1 = pd.read_csv(\"train_eeg1.csv\").drop(\"Id\", axis = 1)\n",
    "xtrain_eeg2 = pd.read_csv(\"train_eeg2.csv\").drop(\"Id\", axis = 1)\n",
    "xtrain_emg = pd.read_csv(\"train_emg.csv\").drop(\"Id\", axis = 1)\n",
    "\n",
    "ytrain = pd.read_csv(\"train_labels.csv\").drop(\"Id\", axis = 1)\n",
    "\n",
    "xtest_eeg1 = pd.read_csv(\"test_eeg1.csv\").drop(\"Id\", axis = 1)\n",
    "xtest_eeg2 = pd.read_csv(\"test_eeg2.csv\").drop(\"Id\", axis = 1)\n",
    "xtest_emg = pd.read_csv(\"test_emg.csv\").drop(\"Id\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64800, 512)\n",
      "(64800, 512)\n",
      "(64800, 512)\n",
      "(43200, 512)\n",
      "(43200, 512)\n",
      "(43200, 512)\n",
      "(64800, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_eeg1.shape)\n",
    "print(xtrain_eeg2.shape)\n",
    "print(xtrain_emg.shape)\n",
    "print(xtest_eeg1.shape)\n",
    "print(xtest_eeg2.shape)\n",
    "print(xtest_emg.shape)\n",
    "print(ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x503</th>\n",
       "      <th>x504</th>\n",
       "      <th>x505</th>\n",
       "      <th>x506</th>\n",
       "      <th>x507</th>\n",
       "      <th>x508</th>\n",
       "      <th>x509</th>\n",
       "      <th>x510</th>\n",
       "      <th>x511</th>\n",
       "      <th>x512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.00016</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.00031</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.00007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-0.000390</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>-0.00032</td>\n",
       "      <td>-0.00021</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>-0.00120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.00066</td>\n",
       "      <td>0.00088</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>-0.00120</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>-0.00140</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>-0.00091</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>-0.00027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000680</td>\n",
       "      <td>-0.000880</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-0.000680</td>\n",
       "      <td>-0.00073</td>\n",
       "      <td>-0.00073</td>\n",
       "      <td>-0.00062</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>-0.000540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000140</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.00043</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.00058</td>\n",
       "      <td>-0.00075</td>\n",
       "      <td>-0.00110</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>-0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001100</td>\n",
       "      <td>-0.000790</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>-0.00014</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>-0.00053</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>-0.00041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.00016</td>\n",
       "      <td>-0.00023</td>\n",
       "      <td>-0.00023</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3       x4        x5       x6        x7  \\\n",
       "0  0.000400  0.000470  0.000067 -0.00016 -0.000003  0.00031  0.000360   \n",
       "1  0.000067  0.000095  0.000270  0.00028  0.000250  0.00012  0.000094   \n",
       "2  0.000160 -0.000210 -0.000840 -0.00120 -0.001200 -0.00140 -0.001400   \n",
       "3 -0.000140  0.000260  0.000390  0.00043  0.000280  0.00023  0.000390   \n",
       "4 -0.001100 -0.000790 -0.000081  0.00014  0.000200 -0.00014 -0.000430   \n",
       "\n",
       "        x8        x9      x10  ...      x503      x504      x505      x506  \\\n",
       "0  0.00019 -0.000072 -0.00007  ... -0.000086  0.000033 -0.000046 -0.000270   \n",
       "1 -0.00034 -0.000960 -0.00120  ...  0.000046  0.000300  0.000630  0.000710   \n",
       "2 -0.00091 -0.000600 -0.00027  ... -0.000680 -0.000880 -0.001000 -0.000770   \n",
       "3  0.00022  0.000150  0.00022  ...  0.000720  0.000760  0.000380  0.000052   \n",
       "4 -0.00053 -0.000580 -0.00041  ...  0.000290  0.000600  0.000670  0.000190   \n",
       "\n",
       "       x507     x508     x509     x510      x511      x512  \n",
       "0 -0.000390 -0.00034 -0.00032 -0.00021  0.000042  0.000053  \n",
       "1  0.000520  0.00041  0.00066  0.00088  0.000770  0.000410  \n",
       "2 -0.000680 -0.00073 -0.00073 -0.00062 -0.000550 -0.000540  \n",
       "3 -0.000260 -0.00058 -0.00075 -0.00110 -0.001200 -0.001200  \n",
       "4 -0.000055 -0.00016 -0.00023 -0.00023 -0.000330 -0.000810  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_eeg1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal = xtrain_eeg1.iloc[0,:].values\n",
    "# signal = xtrain_eeg1.values.ravel()\n",
    "\n",
    "# Define sampling frequency and time vector\n",
    "sf = 128.\n",
    "time = np.arange(signal.size) / sf\n",
    "\n",
    "# Plot the signal\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "plt.plot(time, signal, lw=1.5, color='k')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Voltage')\n",
    "plt.xlim([time.min(), time.max()])\n",
    "plt.title('EEG data')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract features from eeg signal\n",
    "# Note that yasa's bandpower function limits the row length to the amount of columns divided by 2\n",
    "# Therefore, iterate in for loop 100 rows at a time\n",
    "\n",
    "def extract_features_eeg(eeg_signal, frequency = 128):\n",
    "    for i in (np.arange(eeg_signal.shape[0] / 100) + 1):\n",
    "        if i == 1:\n",
    "            df = yasa.bandpower(eeg_signal.iloc[0:int(100*i),:].values, sf=frequency)\n",
    "        else:\n",
    "            df = df.append(yasa.bandpower(eeg_signal.iloc[int(100*(i-1)):int(100*i),:].values, sf=frequency))\n",
    "    \n",
    "    df = df.set_index(np.arange(eeg_signal.shape[0]))\n",
    "    df = df.drop(columns = [\"FreqRes\",\"Relative\"], axis = 1)\n",
    "    return df\n",
    "\n",
    "def process_emg(emg_signal, fs = 128):\n",
    "    # First remove offset by mean\n",
    "    means = emg_signal.apply(np.mean, axis = 1)\n",
    "    for i in np.arange(len(emg_signal)):\n",
    "        emg_signal.iloc[i,:] = emg_signal.iloc[i,:] - means[i]\n",
    "    \n",
    "    # Second, filter signal with high and low pass filter settings\n",
    "    high = 2.56/(fs/2) # these values can be changed\n",
    "    low = 57.6/(fs/2) # these values can be changed\n",
    "    b, a = sp.signal.butter(4, [high,low], btype='bandpass')\n",
    "    for i in np.arange(len(emg_signal)):\n",
    "        emg_signal.iloc[i,:] = sp.signal.filtfilt(b, a, emg_signal.iloc[i,:].values)\n",
    "    \n",
    "    # Third, rectify signal (absolute value)\n",
    "    ## TRY REMOVING \n",
    "    emg_signal = emg_signal.abs()\n",
    "    \n",
    "    return emg_signal\n",
    "    \n",
    "\n",
    "def simple_statistics(sig, fs=128):\n",
    "    \"\"\" TESTED for (nxd) matrix input \"\"\"\n",
    "    # Check if it is not a 1d array\n",
    "    if (len(sig.shape) > 1) and (sig.shape[1]!=1):\n",
    "        return np.array([np.mean(sig, axis=1), np.median(sig, axis=1),\n",
    "                    np.std(sig, axis=1), np.max(sig, axis=1),\n",
    "                    np.min(sig, axis=1), kurtosis(sig, axis=1),\n",
    "                    skew(sig, axis=1)]).T\n",
    "    else:\n",
    "        print(\"Not Tested with this input!\")\n",
    "        return np.array([np.mean(sig), np.median(sig), np.std(sig),\n",
    "                np.max(sig), np.min(sig), float(kurtosis(sig)),\n",
    "                float(skew(sig))])\n",
    "\n",
    "def vectorized_adv_stat(signal, fs=128):\n",
    "    K_boundary = 10         # to be tuned\n",
    "    t_fisher = 12          # to be tuned\n",
    "    d_fisher = 40          # to be tuned\n",
    "    features_num = 11\n",
    "    threshold =  0.0009\n",
    "    advanced_stats = np.zeros((signal.shape[0],features_num))\n",
    "    print(\"Gathering advanced statistics...\")\n",
    "    feat_array = np.array([\n",
    "                           pfd(signal),\n",
    "                           hfd(signal, K_boundary),\n",
    "                           np.sum((np.power(np.abs(signal),(-0.3)) > 20), axis=1),\n",
    "                           np.sum((np.abs(signal)) > threshold, axis=1),\n",
    "                           np.std(np.power(np.abs(signal),(0.05)), axis=1),\n",
    "                           np.sqrt(np.mean(np.power(np.diff(signal, axis=1), 2), axis=1)),\n",
    "                           np.mean(np.abs(np.diff(signal, axis=1)), axis=1),\n",
    "                           np.mean(np.power(signal, 5), axis=1),\n",
    "                           np.sum(np.power(signal, 2), axis=1)\n",
    "                           ]).T\n",
    "    return feat_array\n",
    "\n",
    "def pfd(X):\n",
    "    return pfd(X.values)\n",
    "\n",
    "def pfd(X):\n",
    "    \"\"\"VECTORIZED!!! TESTED, matches the 1d time series output. Now accepts (nxd) matrices as input\n",
    "    Compute Petrosian Fractal Dimension of a time series from either two\n",
    "    cases below:\n",
    "        1. X, the time series of type list (default)\n",
    "        2. D, the first order differential sequence of X (if D is provided,\n",
    "           recommended to speed up)\n",
    "    In case 1, D is computed using Numpy's difference function.\n",
    "    To speed up, it is recommended to compute D before calling this function\n",
    "    because D may also be used by other functions whereas computing it here\n",
    "    again will slow down.\n",
    "    \"\"\"\n",
    "    n = X.shape[1]\n",
    "    diff = np.diff(X, axis=1)\n",
    "    N_delta = np.sum(diff[:, 1:-1] * diff[:, 0:-2] < 0, axis=1)\n",
    "    return np.log10(n) / (np.log10(n) + np.log10(n / (n + 0.4 * N_delta)))\n",
    "\n",
    "def hfd(X, Kmax):\n",
    "    return hfd(X.values, Kmax)\n",
    "\n",
    "def hfd(X, Kmax):\n",
    "    \"\"\" VECTORIZED!!! TESTED: Matches the for loop output. Can test easily comparing\n",
    "    to the pyeeg.hfd() function. X now a (nxd) matrix.\n",
    "    Compute Higuchi Fractal Dimension of a time series X. kmax\n",
    "     is an HFD parameter\n",
    "    \"\"\"\n",
    "    L = []\n",
    "    x = []\n",
    "    N = X.shape[1]\n",
    "    for k in tqdm(range(1, Kmax)):\n",
    "        # Lk = np.empty(shape=[0, ])\n",
    "        Lk = np.empty(shape=[X.shape[0], 1])\n",
    "        for m in range(0, k):\n",
    "            Lmk = 0\n",
    "            for i in range(1, int(np.floor((N - m) / k))):\n",
    "                Lmk += np.abs(X[:, m + i * k] - X[:, m + i * k - k])\n",
    "            Lmk = Lmk * (N - 1) / np.floor((N - m) / float(k)) / k\n",
    "            Lmk = np.reshape(Lmk, (Lmk.shape[0], 1))\n",
    "            Lk = np.hstack((Lk, Lmk))\n",
    "\n",
    "        # Remove that first placeholder column of zeros in Lk:\n",
    "        Lk = Lk[:, 1:]\n",
    "        L.append(np.log(np.mean(Lk, axis=1)))\n",
    "        x.append([np.log(float(1) / k), 1]) # Fix this!!!\n",
    "\n",
    "    (p, _, _, _) = np.linalg.lstsq(x, L)\n",
    "    return p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Delta2</th>\n",
       "      <th>Theta2</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167779</td>\n",
       "      <td>0.589067</td>\n",
       "      <td>0.142509</td>\n",
       "      <td>0.084657</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>0.145824</td>\n",
       "      <td>0.627337</td>\n",
       "      <td>0.140520</td>\n",
       "      <td>0.068544</td>\n",
       "      <td>0.017776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.261716</td>\n",
       "      <td>0.384270</td>\n",
       "      <td>0.197637</td>\n",
       "      <td>0.141042</td>\n",
       "      <td>0.015335</td>\n",
       "      <td>0.274465</td>\n",
       "      <td>0.360708</td>\n",
       "      <td>0.230005</td>\n",
       "      <td>0.116119</td>\n",
       "      <td>0.018703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.294706</td>\n",
       "      <td>0.191459</td>\n",
       "      <td>0.337027</td>\n",
       "      <td>0.158918</td>\n",
       "      <td>0.017890</td>\n",
       "      <td>0.360250</td>\n",
       "      <td>0.224307</td>\n",
       "      <td>0.271524</td>\n",
       "      <td>0.124966</td>\n",
       "      <td>0.018952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.168293</td>\n",
       "      <td>0.581209</td>\n",
       "      <td>0.130216</td>\n",
       "      <td>0.105173</td>\n",
       "      <td>0.015109</td>\n",
       "      <td>0.129359</td>\n",
       "      <td>0.648551</td>\n",
       "      <td>0.135427</td>\n",
       "      <td>0.074995</td>\n",
       "      <td>0.011668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.239408</td>\n",
       "      <td>0.542883</td>\n",
       "      <td>0.131650</td>\n",
       "      <td>0.076140</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.118469</td>\n",
       "      <td>0.635031</td>\n",
       "      <td>0.127040</td>\n",
       "      <td>0.107246</td>\n",
       "      <td>0.012214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Delta     Theta     Alpha      Beta     Gamma    Delta2    Theta2  \\\n",
       "0  0.167779  0.589067  0.142509  0.084657  0.015988  0.145824  0.627337   \n",
       "1  0.261716  0.384270  0.197637  0.141042  0.015335  0.274465  0.360708   \n",
       "2  0.294706  0.191459  0.337027  0.158918  0.017890  0.360250  0.224307   \n",
       "3  0.168293  0.581209  0.130216  0.105173  0.015109  0.129359  0.648551   \n",
       "4  0.239408  0.542883  0.131650  0.076140  0.009920  0.118469  0.635031   \n",
       "\n",
       "     Alpha2     Beta2    Gamma2  \n",
       "0  0.140520  0.068544  0.017776  \n",
       "1  0.230005  0.116119  0.018703  \n",
       "2  0.271524  0.124966  0.018952  \n",
       "3  0.135427  0.074995  0.011668  \n",
       "4  0.127040  0.107246  0.012214  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain1 = extract_features_eeg(xtrain_eeg1, 128)\n",
    "xtrain2 = extract_features_eeg(xtrain_eeg2, 128)\n",
    "xtrain2 = xtrain2.rename(columns = {\"Delta\": \"Delta2\", \"Theta\": \"Theta2\", \"Alpha\": \"Alpha2\",\n",
    "                         \"Beta\": \"Beta2\", \"Gamma\": \"Gamma2\"})\n",
    "xtrain_eeg = xtrain1.join(xtrain2)\n",
    "xtrain_eeg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering advanced statistics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.58it/s]\n",
      "/Users/andreasopedaleriksson/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:119: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "/Users/andreasopedaleriksson/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:61: RuntimeWarning: divide by zero encountered in power\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Delta2</th>\n",
       "      <th>Theta2</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>...</th>\n",
       "      <th>Skew_emg</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.167779</td>\n",
       "      <td>0.589067</td>\n",
       "      <td>0.142509</td>\n",
       "      <td>0.084657</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>0.145824</td>\n",
       "      <td>0.627337</td>\n",
       "      <td>0.140520</td>\n",
       "      <td>0.068544</td>\n",
       "      <td>0.017776</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.815205</td>\n",
       "      <td>1.034824</td>\n",
       "      <td>0.945445</td>\n",
       "      <td>502.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041635</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-1.534967e-23</td>\n",
       "      <td>1.141335e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.261716</td>\n",
       "      <td>0.384270</td>\n",
       "      <td>0.197637</td>\n",
       "      <td>0.141042</td>\n",
       "      <td>0.015335</td>\n",
       "      <td>0.274465</td>\n",
       "      <td>0.360708</td>\n",
       "      <td>0.230005</td>\n",
       "      <td>0.116119</td>\n",
       "      <td>0.018703</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.176539</td>\n",
       "      <td>1.035475</td>\n",
       "      <td>0.959493</td>\n",
       "      <td>504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048162</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-1.068713e-23</td>\n",
       "      <td>9.859970e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.294706</td>\n",
       "      <td>0.191459</td>\n",
       "      <td>0.337027</td>\n",
       "      <td>0.158918</td>\n",
       "      <td>0.017890</td>\n",
       "      <td>0.360250</td>\n",
       "      <td>0.224307</td>\n",
       "      <td>0.271524</td>\n",
       "      <td>0.124966</td>\n",
       "      <td>0.018952</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.166946</td>\n",
       "      <td>1.034497</td>\n",
       "      <td>0.933330</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040260</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-5.078667e-24</td>\n",
       "      <td>8.570733e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.168293</td>\n",
       "      <td>0.581209</td>\n",
       "      <td>0.130216</td>\n",
       "      <td>0.105173</td>\n",
       "      <td>0.015109</td>\n",
       "      <td>0.129359</td>\n",
       "      <td>0.648551</td>\n",
       "      <td>0.135427</td>\n",
       "      <td>0.074995</td>\n",
       "      <td>0.011668</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.216652</td>\n",
       "      <td>1.036557</td>\n",
       "      <td>0.937956</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040202</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-1.047347e-23</td>\n",
       "      <td>1.019762e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.239408</td>\n",
       "      <td>0.542883</td>\n",
       "      <td>0.131650</td>\n",
       "      <td>0.076140</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.118469</td>\n",
       "      <td>0.635031</td>\n",
       "      <td>0.127040</td>\n",
       "      <td>0.107246</td>\n",
       "      <td>0.012214</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.203634</td>\n",
       "      <td>1.033407</td>\n",
       "      <td>0.940074</td>\n",
       "      <td>507.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040239</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-7.752188e-24</td>\n",
       "      <td>8.427712e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Delta     Theta     Alpha      Beta     Gamma    Delta2    Theta2  \\\n",
       "0  0.167779  0.589067  0.142509  0.084657  0.015988  0.145824  0.627337   \n",
       "1  0.261716  0.384270  0.197637  0.141042  0.015335  0.274465  0.360708   \n",
       "2  0.294706  0.191459  0.337027  0.158918  0.017890  0.360250  0.224307   \n",
       "3  0.168293  0.581209  0.130216  0.105173  0.015109  0.129359  0.648551   \n",
       "4  0.239408  0.542883  0.131650  0.076140  0.009920  0.118469  0.635031   \n",
       "\n",
       "     Alpha2     Beta2    Gamma2  ...  Skew_emg        x1        x2     x3  \\\n",
       "0  0.140520  0.068544  0.017776  ... -1.815205  1.034824  0.945445  502.0   \n",
       "1  0.230005  0.116119  0.018703  ... -2.176539  1.035475  0.959493  504.0   \n",
       "2  0.271524  0.124966  0.018952  ... -1.166946  1.034497  0.933330  509.0   \n",
       "3  0.135427  0.074995  0.011668  ... -2.216652  1.036557  0.937956  505.0   \n",
       "4  0.127040  0.107246  0.012214  ... -2.203634  1.033407  0.940074  507.0   \n",
       "\n",
       "    x4        x5        x6        x7            x8            x9  \n",
       "0  0.0  0.041635  0.000013  0.000008 -1.534967e-23  1.141335e-07  \n",
       "1  0.0  0.048162  0.000011  0.000007 -1.068713e-23  9.859970e-08  \n",
       "2  0.0  0.040260  0.000010  0.000007 -5.078667e-24  8.570733e-08  \n",
       "3  0.0  0.040202  0.000011  0.000007 -1.047347e-23  1.019762e-07  \n",
       "4  0.0  0.040239  0.000010  0.000006 -7.752188e-24  8.427712e-08  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = simple_statistics(xtrain_eeg1)\n",
    "stats1 = pd.DataFrame({\"Mean\": stats[:,0], \"Median\": stats[:,1], \"Std\": stats[:,2],\n",
    "             \"Max\": stats[:,3], \"Min\": stats[:,4], \"Kurtosis\": stats[:,5], \"Skew\": stats[:,6]})\n",
    "xtrain_eeg = xtrain_eeg.join(stats1)\n",
    "stats = simple_statistics(xtrain_eeg2)\n",
    "stats2 = pd.DataFrame({\"Mean2\": stats[:,0], \"Median2\": stats[:,1], \"Std2\": stats[:,2],\n",
    "             \"Max2\": stats[:,3], \"Min2\": stats[:,4], \"Kurtosis2\": stats[:,5], \"Skew2\": stats[:,6]})\n",
    "xtrain_eeg = xtrain_eeg.join(stats2)\n",
    "\n",
    "#xtrain_emg = process_emg(xtrain_emg)\n",
    "\n",
    "stats = simple_statistics(xtrain_emg)\n",
    "stats3 = pd.DataFrame({\"Mean_emg\": stats[:,0], \"Median_emg\": stats[:,1], \"Std_emg\": stats[:,2],\n",
    "             \"Max_emg\": stats[:,3], \"Min_emg\": stats[:,4], \"Kurtosis_emg\": stats[:,5], \"Skew_emg\": stats[:,6]})\n",
    "xtrain_eeg = xtrain_eeg.join(stats3)\n",
    "\n",
    "stats = vectorized_adv_stat(xtrain_emg.values)\n",
    "stats4 = pd.DataFrame({\"x1\": stats[:,0], \"x2\": stats[:,1], \"x3\": stats[:,2],\n",
    "             \"x4\": stats[:,3], \"x5\": stats[:,4], \"x6\": stats[:,5], \"x7\": stats[:,6],\n",
    "                \"x8\": stats[:,7], \"x9\": stats[:,8]})\n",
    "xtrain_eeg = xtrain_eeg.join(stats4)\n",
    "\n",
    "xtrain_eeg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Delta2</th>\n",
       "      <th>Theta2</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>...</th>\n",
       "      <th>Skew_emg</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.011187</td>\n",
       "      <td>2.268461</td>\n",
       "      <td>-0.420041</td>\n",
       "      <td>-1.136340</td>\n",
       "      <td>-0.688844</td>\n",
       "      <td>-1.306728</td>\n",
       "      <td>2.510711</td>\n",
       "      <td>-0.421807</td>\n",
       "      <td>-1.406019</td>\n",
       "      <td>-0.501901</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.398622</td>\n",
       "      <td>-0.494115</td>\n",
       "      <td>0.313840</td>\n",
       "      <td>1.115484</td>\n",
       "      <td>-0.124582</td>\n",
       "      <td>0.114297</td>\n",
       "      <td>-0.815478</td>\n",
       "      <td>-0.829049</td>\n",
       "      <td>-0.007058</td>\n",
       "      <td>-0.203295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.353931</td>\n",
       "      <td>0.538933</td>\n",
       "      <td>0.035142</td>\n",
       "      <td>-0.043393</td>\n",
       "      <td>-0.719630</td>\n",
       "      <td>-0.352300</td>\n",
       "      <td>0.275443</td>\n",
       "      <td>0.365257</td>\n",
       "      <td>-0.385367</td>\n",
       "      <td>-0.454730</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.694978</td>\n",
       "      <td>-0.294872</td>\n",
       "      <td>0.402868</td>\n",
       "      <td>1.129789</td>\n",
       "      <td>-0.124582</td>\n",
       "      <td>0.724086</td>\n",
       "      <td>-0.829865</td>\n",
       "      <td>-0.843736</td>\n",
       "      <td>-0.007058</td>\n",
       "      <td>-0.203768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.123110</td>\n",
       "      <td>-1.089365</td>\n",
       "      <td>1.186058</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>-0.599066</td>\n",
       "      <td>0.284165</td>\n",
       "      <td>-0.868064</td>\n",
       "      <td>0.730441</td>\n",
       "      <td>-0.195581</td>\n",
       "      <td>-0.442027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.866939</td>\n",
       "      <td>-0.593926</td>\n",
       "      <td>0.237069</td>\n",
       "      <td>1.165554</td>\n",
       "      <td>-0.124582</td>\n",
       "      <td>-0.014148</td>\n",
       "      <td>-0.843336</td>\n",
       "      <td>-0.853970</td>\n",
       "      <td>-0.007058</td>\n",
       "      <td>-0.204161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.007590</td>\n",
       "      <td>2.202099</td>\n",
       "      <td>-0.521540</td>\n",
       "      <td>-0.738669</td>\n",
       "      <td>-0.730314</td>\n",
       "      <td>-1.428885</td>\n",
       "      <td>2.688560</td>\n",
       "      <td>-0.466600</td>\n",
       "      <td>-1.267628</td>\n",
       "      <td>-0.812704</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.727877</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.266380</td>\n",
       "      <td>1.136942</td>\n",
       "      <td>-0.124582</td>\n",
       "      <td>-0.019604</td>\n",
       "      <td>-0.837730</td>\n",
       "      <td>-0.851165</td>\n",
       "      <td>-0.007058</td>\n",
       "      <td>-0.203665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.510020</td>\n",
       "      <td>1.878431</td>\n",
       "      <td>-0.509704</td>\n",
       "      <td>-1.301434</td>\n",
       "      <td>-0.975195</td>\n",
       "      <td>-1.509683</td>\n",
       "      <td>2.575216</td>\n",
       "      <td>-0.540365</td>\n",
       "      <td>-0.575737</td>\n",
       "      <td>-0.784925</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.717200</td>\n",
       "      <td>-0.927550</td>\n",
       "      <td>0.279802</td>\n",
       "      <td>1.151248</td>\n",
       "      <td>-0.124582</td>\n",
       "      <td>-0.016146</td>\n",
       "      <td>-0.841858</td>\n",
       "      <td>-0.856954</td>\n",
       "      <td>-0.007058</td>\n",
       "      <td>-0.204205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Delta     Theta     Alpha      Beta     Gamma    Delta2    Theta2  \\\n",
       "0 -1.011187  2.268461 -0.420041 -1.136340 -0.688844 -1.306728  2.510711   \n",
       "1 -0.353931  0.538933  0.035142 -0.043393 -0.719630 -0.352300  0.275443   \n",
       "2 -0.123110 -1.089365  1.186058  0.303118 -0.599066  0.284165 -0.868064   \n",
       "3 -1.007590  2.202099 -0.521540 -0.738669 -0.730314 -1.428885  2.688560   \n",
       "4 -0.510020  1.878431 -0.509704 -1.301434 -0.975195 -1.509683  2.575216   \n",
       "\n",
       "     Alpha2     Beta2    Gamma2  ...  Skew_emg        x1        x2        x3  \\\n",
       "0 -0.421807 -1.406019 -0.501901  ... -1.398622 -0.494115  0.313840  1.115484   \n",
       "1  0.365257 -0.385367 -0.454730  ... -1.694978 -0.294872  0.402868  1.129789   \n",
       "2  0.730441 -0.195581 -0.442027  ... -0.866939 -0.593926  0.237069  1.165554   \n",
       "3 -0.466600 -1.267628 -0.812704  ... -1.727877  0.036082  0.266380  1.136942   \n",
       "4 -0.540365 -0.575737 -0.784925  ... -1.717200 -0.927550  0.279802  1.151248   \n",
       "\n",
       "         x4        x5        x6        x7        x8        x9  \n",
       "0 -0.124582  0.114297 -0.815478 -0.829049 -0.007058 -0.203295  \n",
       "1 -0.124582  0.724086 -0.829865 -0.843736 -0.007058 -0.203768  \n",
       "2 -0.124582 -0.014148 -0.843336 -0.853970 -0.007058 -0.204161  \n",
       "3 -0.124582 -0.019604 -0.837730 -0.851165 -0.007058 -0.203665  \n",
       "4 -0.124582 -0.016146 -0.841858 -0.856954 -0.007058 -0.204205  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "xtrain_scaled = scaler.fit_transform(xtrain_eeg)\n",
    "xtrain_scaled = pd.DataFrame(xtrain_scaled, columns = xtrain_eeg.columns)\n",
    "xtrain_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Delta2</th>\n",
       "      <th>Theta2</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>...</th>\n",
       "      <th>Skew_emg</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.237751</td>\n",
       "      <td>0.199109</td>\n",
       "      <td>-0.231032</td>\n",
       "      <td>-0.317460</td>\n",
       "      <td>-0.622888</td>\n",
       "      <td>0.145964</td>\n",
       "      <td>0.243162</td>\n",
       "      <td>-0.188634</td>\n",
       "      <td>-0.317625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136050</td>\n",
       "      <td>-0.345841</td>\n",
       "      <td>-0.244870</td>\n",
       "      <td>0.682687</td>\n",
       "      <td>-0.107671</td>\n",
       "      <td>-0.166074</td>\n",
       "      <td>-0.682439</td>\n",
       "      <td>-0.671854</td>\n",
       "      <td>-0.004103</td>\n",
       "      <td>-0.167770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delta</th>\n",
       "      <td>0.237751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.401326</td>\n",
       "      <td>-0.526869</td>\n",
       "      <td>-0.421306</td>\n",
       "      <td>-0.465146</td>\n",
       "      <td>0.833979</td>\n",
       "      <td>-0.267251</td>\n",
       "      <td>-0.476656</td>\n",
       "      <td>-0.380655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050828</td>\n",
       "      <td>-0.102096</td>\n",
       "      <td>-0.070040</td>\n",
       "      <td>0.375448</td>\n",
       "      <td>-0.063770</td>\n",
       "      <td>0.126314</td>\n",
       "      <td>-0.362203</td>\n",
       "      <td>-0.364426</td>\n",
       "      <td>-0.004738</td>\n",
       "      <td>-0.095444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Theta</th>\n",
       "      <td>0.199109</td>\n",
       "      <td>-0.401326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.454961</td>\n",
       "      <td>-0.120266</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>-0.339174</td>\n",
       "      <td>0.825450</td>\n",
       "      <td>-0.433043</td>\n",
       "      <td>-0.079128</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020549</td>\n",
       "      <td>-0.066416</td>\n",
       "      <td>-0.056101</td>\n",
       "      <td>0.075205</td>\n",
       "      <td>-0.000753</td>\n",
       "      <td>-0.076689</td>\n",
       "      <td>-0.059121</td>\n",
       "      <td>-0.067041</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>-0.009251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>-0.231032</td>\n",
       "      <td>-0.526869</td>\n",
       "      <td>-0.454961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098135</td>\n",
       "      <td>0.141579</td>\n",
       "      <td>-0.459464</td>\n",
       "      <td>-0.461018</td>\n",
       "      <td>0.929158</td>\n",
       "      <td>0.158225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078632</td>\n",
       "      <td>0.095525</td>\n",
       "      <td>0.058331</td>\n",
       "      <td>-0.320558</td>\n",
       "      <td>0.026960</td>\n",
       "      <td>-0.061224</td>\n",
       "      <td>0.266313</td>\n",
       "      <td>0.278435</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.058152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>-0.317460</td>\n",
       "      <td>-0.421306</td>\n",
       "      <td>-0.120266</td>\n",
       "      <td>0.098135</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.518205</td>\n",
       "      <td>-0.310798</td>\n",
       "      <td>-0.071866</td>\n",
       "      <td>0.089228</td>\n",
       "      <td>0.694898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024971</td>\n",
       "      <td>0.100771</td>\n",
       "      <td>0.099809</td>\n",
       "      <td>-0.227107</td>\n",
       "      <td>0.061542</td>\n",
       "      <td>-0.044534</td>\n",
       "      <td>0.258455</td>\n",
       "      <td>0.258257</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.077809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gamma</th>\n",
       "      <td>-0.622888</td>\n",
       "      <td>-0.465146</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.141579</td>\n",
       "      <td>0.518205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.346971</td>\n",
       "      <td>-0.000216</td>\n",
       "      <td>0.107003</td>\n",
       "      <td>0.413496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069029</td>\n",
       "      <td>0.268454</td>\n",
       "      <td>0.209522</td>\n",
       "      <td>-0.567523</td>\n",
       "      <td>0.130408</td>\n",
       "      <td>0.034931</td>\n",
       "      <td>0.622030</td>\n",
       "      <td>0.612482</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>0.173651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delta2</th>\n",
       "      <td>0.145964</td>\n",
       "      <td>0.833979</td>\n",
       "      <td>-0.339174</td>\n",
       "      <td>-0.459464</td>\n",
       "      <td>-0.310798</td>\n",
       "      <td>-0.346971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.420585</td>\n",
       "      <td>-0.511523</td>\n",
       "      <td>-0.410763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025211</td>\n",
       "      <td>-0.140893</td>\n",
       "      <td>-0.129974</td>\n",
       "      <td>0.251577</td>\n",
       "      <td>-0.053139</td>\n",
       "      <td>0.079973</td>\n",
       "      <td>-0.286949</td>\n",
       "      <td>-0.290065</td>\n",
       "      <td>-0.002057</td>\n",
       "      <td>-0.076955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Theta2</th>\n",
       "      <td>0.243162</td>\n",
       "      <td>-0.267251</td>\n",
       "      <td>0.825450</td>\n",
       "      <td>-0.461018</td>\n",
       "      <td>-0.071866</td>\n",
       "      <td>-0.000216</td>\n",
       "      <td>-0.420585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.465863</td>\n",
       "      <td>-0.166457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080298</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.045501</td>\n",
       "      <td>0.182887</td>\n",
       "      <td>0.011053</td>\n",
       "      <td>-0.030901</td>\n",
       "      <td>-0.084675</td>\n",
       "      <td>-0.093021</td>\n",
       "      <td>-0.004548</td>\n",
       "      <td>-0.005776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha2</th>\n",
       "      <td>-0.188634</td>\n",
       "      <td>-0.476656</td>\n",
       "      <td>-0.433043</td>\n",
       "      <td>0.929158</td>\n",
       "      <td>0.089228</td>\n",
       "      <td>0.107003</td>\n",
       "      <td>-0.511523</td>\n",
       "      <td>-0.465863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066171</td>\n",
       "      <td>0.104476</td>\n",
       "      <td>0.077530</td>\n",
       "      <td>-0.265490</td>\n",
       "      <td>0.022441</td>\n",
       "      <td>-0.045099</td>\n",
       "      <td>0.233797</td>\n",
       "      <td>0.246246</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.048313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta2</th>\n",
       "      <td>-0.317625</td>\n",
       "      <td>-0.380655</td>\n",
       "      <td>-0.079128</td>\n",
       "      <td>0.158225</td>\n",
       "      <td>0.694898</td>\n",
       "      <td>0.413496</td>\n",
       "      <td>-0.410763</td>\n",
       "      <td>-0.166457</td>\n",
       "      <td>0.164288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064247</td>\n",
       "      <td>0.036342</td>\n",
       "      <td>-0.000308</td>\n",
       "      <td>-0.290108</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>-0.037331</td>\n",
       "      <td>0.228758</td>\n",
       "      <td>0.231840</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.054518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gamma2</th>\n",
       "      <td>-0.632349</td>\n",
       "      <td>-0.437206</td>\n",
       "      <td>0.008968</td>\n",
       "      <td>0.198670</td>\n",
       "      <td>0.403377</td>\n",
       "      <td>0.781208</td>\n",
       "      <td>-0.372030</td>\n",
       "      <td>-0.095139</td>\n",
       "      <td>0.160886</td>\n",
       "      <td>0.505202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125091</td>\n",
       "      <td>0.242075</td>\n",
       "      <td>0.167443</td>\n",
       "      <td>-0.611465</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>-0.011480</td>\n",
       "      <td>0.586827</td>\n",
       "      <td>0.579518</td>\n",
       "      <td>0.010983</td>\n",
       "      <td>0.154043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>-0.002944</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>-0.013342</td>\n",
       "      <td>-0.031425</td>\n",
       "      <td>-0.016031</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.008581</td>\n",
       "      <td>-0.002379</td>\n",
       "      <td>-0.011162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.055586</td>\n",
       "      <td>0.053180</td>\n",
       "      <td>0.030361</td>\n",
       "      <td>-0.012903</td>\n",
       "      <td>0.041837</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>-0.006523</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>-0.010557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median</th>\n",
       "      <td>-0.140687</td>\n",
       "      <td>-0.061527</td>\n",
       "      <td>0.075839</td>\n",
       "      <td>-0.022918</td>\n",
       "      <td>-0.002664</td>\n",
       "      <td>0.128668</td>\n",
       "      <td>-0.069882</td>\n",
       "      <td>0.057520</td>\n",
       "      <td>-0.016107</td>\n",
       "      <td>0.037279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039828</td>\n",
       "      <td>0.165691</td>\n",
       "      <td>0.147229</td>\n",
       "      <td>-0.061074</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>0.088587</td>\n",
       "      <td>0.113621</td>\n",
       "      <td>0.105754</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.015543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std</th>\n",
       "      <td>0.577428</td>\n",
       "      <td>0.553044</td>\n",
       "      <td>-0.134107</td>\n",
       "      <td>-0.208142</td>\n",
       "      <td>-0.450922</td>\n",
       "      <td>-0.693343</td>\n",
       "      <td>0.454618</td>\n",
       "      <td>-0.107762</td>\n",
       "      <td>-0.172760</td>\n",
       "      <td>-0.351739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042934</td>\n",
       "      <td>-0.385469</td>\n",
       "      <td>-0.342562</td>\n",
       "      <td>0.448347</td>\n",
       "      <td>-0.106825</td>\n",
       "      <td>-0.003803</td>\n",
       "      <td>-0.543506</td>\n",
       "      <td>-0.528753</td>\n",
       "      <td>-0.002626</td>\n",
       "      <td>-0.147944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.463881</td>\n",
       "      <td>0.462369</td>\n",
       "      <td>-0.135950</td>\n",
       "      <td>-0.206702</td>\n",
       "      <td>-0.262139</td>\n",
       "      <td>-0.539296</td>\n",
       "      <td>0.396329</td>\n",
       "      <td>-0.098226</td>\n",
       "      <td>-0.181542</td>\n",
       "      <td>-0.236267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064269</td>\n",
       "      <td>-0.366865</td>\n",
       "      <td>-0.325281</td>\n",
       "      <td>0.366073</td>\n",
       "      <td>-0.081484</td>\n",
       "      <td>-0.036952</td>\n",
       "      <td>-0.457027</td>\n",
       "      <td>-0.445924</td>\n",
       "      <td>-0.001886</td>\n",
       "      <td>-0.116875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>-0.312266</td>\n",
       "      <td>-0.424623</td>\n",
       "      <td>0.101934</td>\n",
       "      <td>0.231723</td>\n",
       "      <td>0.250368</td>\n",
       "      <td>0.360433</td>\n",
       "      <td>-0.349814</td>\n",
       "      <td>0.062627</td>\n",
       "      <td>0.206183</td>\n",
       "      <td>0.198684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025406</td>\n",
       "      <td>0.236715</td>\n",
       "      <td>0.212938</td>\n",
       "      <td>-0.270827</td>\n",
       "      <td>0.071917</td>\n",
       "      <td>-0.055279</td>\n",
       "      <td>0.315051</td>\n",
       "      <td>0.309671</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>0.098893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>-0.098621</td>\n",
       "      <td>0.134666</td>\n",
       "      <td>-0.063393</td>\n",
       "      <td>-0.201244</td>\n",
       "      <td>0.186784</td>\n",
       "      <td>0.141414</td>\n",
       "      <td>0.137844</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>-0.204106</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037378</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>-0.016968</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.043977</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>-0.002242</td>\n",
       "      <td>-0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>0.227270</td>\n",
       "      <td>0.113801</td>\n",
       "      <td>-0.093924</td>\n",
       "      <td>0.018645</td>\n",
       "      <td>-0.034675</td>\n",
       "      <td>-0.264854</td>\n",
       "      <td>0.109302</td>\n",
       "      <td>-0.074277</td>\n",
       "      <td>0.020371</td>\n",
       "      <td>-0.071796</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053605</td>\n",
       "      <td>-0.187950</td>\n",
       "      <td>-0.160384</td>\n",
       "      <td>0.152014</td>\n",
       "      <td>-0.017905</td>\n",
       "      <td>-0.102036</td>\n",
       "      <td>-0.209266</td>\n",
       "      <td>-0.199297</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>-0.033746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean2</th>\n",
       "      <td>-0.003938</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>-0.013993</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>-0.020422</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>-0.002927</td>\n",
       "      <td>-0.007791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013784</td>\n",
       "      <td>0.067622</td>\n",
       "      <td>0.067512</td>\n",
       "      <td>0.037745</td>\n",
       "      <td>-0.016887</td>\n",
       "      <td>0.051882</td>\n",
       "      <td>-0.007101</td>\n",
       "      <td>-0.008553</td>\n",
       "      <td>0.010403</td>\n",
       "      <td>-0.012037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median2</th>\n",
       "      <td>-0.184405</td>\n",
       "      <td>-0.083125</td>\n",
       "      <td>0.052402</td>\n",
       "      <td>-0.013111</td>\n",
       "      <td>0.065983</td>\n",
       "      <td>0.182131</td>\n",
       "      <td>-0.078379</td>\n",
       "      <td>0.050234</td>\n",
       "      <td>-0.015342</td>\n",
       "      <td>0.064267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020961</td>\n",
       "      <td>0.179761</td>\n",
       "      <td>0.171937</td>\n",
       "      <td>-0.085826</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.076085</td>\n",
       "      <td>0.150185</td>\n",
       "      <td>0.141877</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>0.032830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std2</th>\n",
       "      <td>0.457796</td>\n",
       "      <td>0.521398</td>\n",
       "      <td>-0.091540</td>\n",
       "      <td>-0.244764</td>\n",
       "      <td>-0.426433</td>\n",
       "      <td>-0.568063</td>\n",
       "      <td>0.394854</td>\n",
       "      <td>-0.000634</td>\n",
       "      <td>-0.194141</td>\n",
       "      <td>-0.415650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074030</td>\n",
       "      <td>0.108729</td>\n",
       "      <td>0.192854</td>\n",
       "      <td>0.588187</td>\n",
       "      <td>-0.072617</td>\n",
       "      <td>0.239093</td>\n",
       "      <td>-0.405544</td>\n",
       "      <td>-0.401365</td>\n",
       "      <td>-0.006464</td>\n",
       "      <td>-0.114838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max2</th>\n",
       "      <td>0.422406</td>\n",
       "      <td>0.485795</td>\n",
       "      <td>-0.094059</td>\n",
       "      <td>-0.242961</td>\n",
       "      <td>-0.342121</td>\n",
       "      <td>-0.529425</td>\n",
       "      <td>0.376898</td>\n",
       "      <td>-0.028286</td>\n",
       "      <td>-0.198814</td>\n",
       "      <td>-0.308529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059768</td>\n",
       "      <td>-0.026104</td>\n",
       "      <td>0.037888</td>\n",
       "      <td>0.500459</td>\n",
       "      <td>-0.069384</td>\n",
       "      <td>0.173676</td>\n",
       "      <td>-0.401427</td>\n",
       "      <td>-0.396903</td>\n",
       "      <td>-0.000918</td>\n",
       "      <td>-0.109166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min2</th>\n",
       "      <td>-0.213375</td>\n",
       "      <td>-0.399799</td>\n",
       "      <td>0.068267</td>\n",
       "      <td>0.241244</td>\n",
       "      <td>0.261775</td>\n",
       "      <td>0.298940</td>\n",
       "      <td>-0.304166</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.208567</td>\n",
       "      <td>0.236590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038205</td>\n",
       "      <td>-0.181804</td>\n",
       "      <td>-0.236051</td>\n",
       "      <td>-0.385783</td>\n",
       "      <td>0.047416</td>\n",
       "      <td>-0.249714</td>\n",
       "      <td>0.212861</td>\n",
       "      <td>0.216112</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.071701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis2</th>\n",
       "      <td>-0.070741</td>\n",
       "      <td>0.134388</td>\n",
       "      <td>-0.034506</td>\n",
       "      <td>-0.167424</td>\n",
       "      <td>0.083544</td>\n",
       "      <td>0.039917</td>\n",
       "      <td>0.149364</td>\n",
       "      <td>-0.062164</td>\n",
       "      <td>-0.180303</td>\n",
       "      <td>0.127182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>-0.158315</td>\n",
       "      <td>-0.188366</td>\n",
       "      <td>-0.065451</td>\n",
       "      <td>-0.009716</td>\n",
       "      <td>-0.004179</td>\n",
       "      <td>-0.036379</td>\n",
       "      <td>-0.040324</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>-0.010514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew2</th>\n",
       "      <td>0.296265</td>\n",
       "      <td>0.145934</td>\n",
       "      <td>-0.063188</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>-0.121521</td>\n",
       "      <td>-0.332304</td>\n",
       "      <td>0.119439</td>\n",
       "      <td>-0.060380</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>-0.098192</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025852</td>\n",
       "      <td>-0.268445</td>\n",
       "      <td>-0.261488</td>\n",
       "      <td>0.172389</td>\n",
       "      <td>-0.043054</td>\n",
       "      <td>-0.088816</td>\n",
       "      <td>-0.266905</td>\n",
       "      <td>-0.254843</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>-0.063393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_emg</th>\n",
       "      <td>0.016546</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.037666</td>\n",
       "      <td>-0.033649</td>\n",
       "      <td>0.013295</td>\n",
       "      <td>-0.017315</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118580</td>\n",
       "      <td>-0.040189</td>\n",
       "      <td>-0.049743</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>0.192521</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>-0.051951</td>\n",
       "      <td>-0.052589</td>\n",
       "      <td>0.258028</td>\n",
       "      <td>0.298477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median_emg</th>\n",
       "      <td>0.088772</td>\n",
       "      <td>0.060735</td>\n",
       "      <td>0.018715</td>\n",
       "      <td>-0.053970</td>\n",
       "      <td>-0.052508</td>\n",
       "      <td>-0.077930</td>\n",
       "      <td>0.042059</td>\n",
       "      <td>0.028479</td>\n",
       "      <td>-0.041599</td>\n",
       "      <td>-0.053762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073055</td>\n",
       "      <td>0.014546</td>\n",
       "      <td>0.010772</td>\n",
       "      <td>0.158683</td>\n",
       "      <td>-0.204841</td>\n",
       "      <td>0.057133</td>\n",
       "      <td>-0.097587</td>\n",
       "      <td>-0.100792</td>\n",
       "      <td>-0.184653</td>\n",
       "      <td>-0.163503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std_emg</th>\n",
       "      <td>-0.590729</td>\n",
       "      <td>-0.317637</td>\n",
       "      <td>-0.050476</td>\n",
       "      <td>0.235910</td>\n",
       "      <td>0.221528</td>\n",
       "      <td>0.536805</td>\n",
       "      <td>-0.236542</td>\n",
       "      <td>-0.091462</td>\n",
       "      <td>0.199670</td>\n",
       "      <td>0.211922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121589</td>\n",
       "      <td>0.094285</td>\n",
       "      <td>0.022110</td>\n",
       "      <td>-0.797080</td>\n",
       "      <td>0.654940</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.857627</td>\n",
       "      <td>0.851795</td>\n",
       "      <td>0.139517</td>\n",
       "      <td>0.694185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_emg</th>\n",
       "      <td>-0.634006</td>\n",
       "      <td>-0.331344</td>\n",
       "      <td>-0.051766</td>\n",
       "      <td>0.246141</td>\n",
       "      <td>0.226315</td>\n",
       "      <td>0.566329</td>\n",
       "      <td>-0.251864</td>\n",
       "      <td>-0.095736</td>\n",
       "      <td>0.210578</td>\n",
       "      <td>0.223661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280416</td>\n",
       "      <td>0.213715</td>\n",
       "      <td>0.141074</td>\n",
       "      <td>-0.753813</td>\n",
       "      <td>0.391415</td>\n",
       "      <td>0.071759</td>\n",
       "      <td>0.886947</td>\n",
       "      <td>0.857806</td>\n",
       "      <td>0.086102</td>\n",
       "      <td>0.422729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_emg</th>\n",
       "      <td>0.613324</td>\n",
       "      <td>0.317283</td>\n",
       "      <td>0.041462</td>\n",
       "      <td>-0.214246</td>\n",
       "      <td>-0.236491</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>0.248560</td>\n",
       "      <td>0.056965</td>\n",
       "      <td>-0.185202</td>\n",
       "      <td>-0.193531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076394</td>\n",
       "      <td>-0.222163</td>\n",
       "      <td>-0.164774</td>\n",
       "      <td>0.721190</td>\n",
       "      <td>-0.400038</td>\n",
       "      <td>-0.091201</td>\n",
       "      <td>-0.900255</td>\n",
       "      <td>-0.870296</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>-0.420981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis_emg</th>\n",
       "      <td>-0.029162</td>\n",
       "      <td>-0.074353</td>\n",
       "      <td>0.066858</td>\n",
       "      <td>-0.004713</td>\n",
       "      <td>0.027172</td>\n",
       "      <td>0.088676</td>\n",
       "      <td>-0.082249</td>\n",
       "      <td>0.087217</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>-0.016105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041282</td>\n",
       "      <td>0.146473</td>\n",
       "      <td>0.201988</td>\n",
       "      <td>0.086685</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>-0.004723</td>\n",
       "      <td>0.063213</td>\n",
       "      <td>0.012921</td>\n",
       "      <td>-0.001734</td>\n",
       "      <td>-0.004474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew_emg</th>\n",
       "      <td>-0.136050</td>\n",
       "      <td>-0.050828</td>\n",
       "      <td>-0.020549</td>\n",
       "      <td>0.078632</td>\n",
       "      <td>-0.024971</td>\n",
       "      <td>0.069029</td>\n",
       "      <td>-0.025211</td>\n",
       "      <td>-0.080298</td>\n",
       "      <td>0.066171</td>\n",
       "      <td>0.064247</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008604</td>\n",
       "      <td>-0.063255</td>\n",
       "      <td>-0.191600</td>\n",
       "      <td>0.010813</td>\n",
       "      <td>0.023130</td>\n",
       "      <td>0.104838</td>\n",
       "      <td>0.109829</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.027312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>-0.345841</td>\n",
       "      <td>-0.102096</td>\n",
       "      <td>-0.066416</td>\n",
       "      <td>0.095525</td>\n",
       "      <td>0.100771</td>\n",
       "      <td>0.268454</td>\n",
       "      <td>-0.140893</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.104476</td>\n",
       "      <td>0.036342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896590</td>\n",
       "      <td>0.092946</td>\n",
       "      <td>-0.030140</td>\n",
       "      <td>0.340787</td>\n",
       "      <td>0.308772</td>\n",
       "      <td>0.299090</td>\n",
       "      <td>-0.024828</td>\n",
       "      <td>-0.012717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>-0.244870</td>\n",
       "      <td>-0.070040</td>\n",
       "      <td>-0.056101</td>\n",
       "      <td>0.058331</td>\n",
       "      <td>0.099809</td>\n",
       "      <td>0.209522</td>\n",
       "      <td>-0.129974</td>\n",
       "      <td>0.045501</td>\n",
       "      <td>0.077530</td>\n",
       "      <td>-0.000308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063255</td>\n",
       "      <td>0.896590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229093</td>\n",
       "      <td>-0.019028</td>\n",
       "      <td>0.304628</td>\n",
       "      <td>0.239957</td>\n",
       "      <td>0.225877</td>\n",
       "      <td>-0.014202</td>\n",
       "      <td>-0.007551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>0.682687</td>\n",
       "      <td>0.375448</td>\n",
       "      <td>0.075205</td>\n",
       "      <td>-0.320558</td>\n",
       "      <td>-0.227107</td>\n",
       "      <td>-0.567523</td>\n",
       "      <td>0.251577</td>\n",
       "      <td>0.182887</td>\n",
       "      <td>-0.265490</td>\n",
       "      <td>-0.290108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191600</td>\n",
       "      <td>0.092946</td>\n",
       "      <td>0.229093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200244</td>\n",
       "      <td>0.098742</td>\n",
       "      <td>-0.800578</td>\n",
       "      <td>-0.813157</td>\n",
       "      <td>-0.011628</td>\n",
       "      <td>-0.267772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>-0.107671</td>\n",
       "      <td>-0.063770</td>\n",
       "      <td>-0.000753</td>\n",
       "      <td>0.026960</td>\n",
       "      <td>0.061542</td>\n",
       "      <td>0.130408</td>\n",
       "      <td>-0.053139</td>\n",
       "      <td>0.011053</td>\n",
       "      <td>0.022441</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010813</td>\n",
       "      <td>-0.030140</td>\n",
       "      <td>-0.019028</td>\n",
       "      <td>-0.200244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.048415</td>\n",
       "      <td>0.268137</td>\n",
       "      <td>0.260242</td>\n",
       "      <td>0.217408</td>\n",
       "      <td>0.908049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>-0.166074</td>\n",
       "      <td>0.126314</td>\n",
       "      <td>-0.076689</td>\n",
       "      <td>-0.061224</td>\n",
       "      <td>-0.044534</td>\n",
       "      <td>0.034931</td>\n",
       "      <td>0.079973</td>\n",
       "      <td>-0.030901</td>\n",
       "      <td>-0.045099</td>\n",
       "      <td>-0.037331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023130</td>\n",
       "      <td>0.340787</td>\n",
       "      <td>0.304628</td>\n",
       "      <td>0.098742</td>\n",
       "      <td>0.048415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084958</td>\n",
       "      <td>0.069959</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.044709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6</th>\n",
       "      <td>-0.682439</td>\n",
       "      <td>-0.362203</td>\n",
       "      <td>-0.059121</td>\n",
       "      <td>0.266313</td>\n",
       "      <td>0.258455</td>\n",
       "      <td>0.622030</td>\n",
       "      <td>-0.286949</td>\n",
       "      <td>-0.084675</td>\n",
       "      <td>0.233797</td>\n",
       "      <td>0.228758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104838</td>\n",
       "      <td>0.308772</td>\n",
       "      <td>0.239957</td>\n",
       "      <td>-0.800578</td>\n",
       "      <td>0.268137</td>\n",
       "      <td>0.084958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992204</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.316733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <td>-0.671854</td>\n",
       "      <td>-0.364426</td>\n",
       "      <td>-0.067041</td>\n",
       "      <td>0.278435</td>\n",
       "      <td>0.258257</td>\n",
       "      <td>0.612482</td>\n",
       "      <td>-0.290065</td>\n",
       "      <td>-0.093021</td>\n",
       "      <td>0.246246</td>\n",
       "      <td>0.231840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109829</td>\n",
       "      <td>0.299090</td>\n",
       "      <td>0.225877</td>\n",
       "      <td>-0.813157</td>\n",
       "      <td>0.260242</td>\n",
       "      <td>0.069959</td>\n",
       "      <td>0.992204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003696</td>\n",
       "      <td>0.311847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8</th>\n",
       "      <td>-0.004103</td>\n",
       "      <td>-0.004738</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-0.002057</td>\n",
       "      <td>-0.004548</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>-0.024828</td>\n",
       "      <td>-0.014202</td>\n",
       "      <td>-0.011628</td>\n",
       "      <td>0.217408</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>-0.003696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.378180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x9</th>\n",
       "      <td>-0.167770</td>\n",
       "      <td>-0.095444</td>\n",
       "      <td>-0.009251</td>\n",
       "      <td>0.058152</td>\n",
       "      <td>0.077809</td>\n",
       "      <td>0.173651</td>\n",
       "      <td>-0.076955</td>\n",
       "      <td>-0.005776</td>\n",
       "      <td>0.048313</td>\n",
       "      <td>0.054518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027312</td>\n",
       "      <td>-0.012717</td>\n",
       "      <td>-0.007551</td>\n",
       "      <td>-0.267772</td>\n",
       "      <td>0.908049</td>\n",
       "      <td>0.044709</td>\n",
       "      <td>0.316733</td>\n",
       "      <td>0.311847</td>\n",
       "      <td>0.378180</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     y     Delta     Theta     Alpha      Beta     Gamma  \\\n",
       "y             1.000000  0.237751  0.199109 -0.231032 -0.317460 -0.622888   \n",
       "Delta         0.237751  1.000000 -0.401326 -0.526869 -0.421306 -0.465146   \n",
       "Theta         0.199109 -0.401326  1.000000 -0.454961 -0.120266  0.011905   \n",
       "Alpha        -0.231032 -0.526869 -0.454961  1.000000  0.098135  0.141579   \n",
       "Beta         -0.317460 -0.421306 -0.120266  0.098135  1.000000  0.518205   \n",
       "Gamma        -0.622888 -0.465146  0.011905  0.141579  0.518205  1.000000   \n",
       "Delta2        0.145964  0.833979 -0.339174 -0.459464 -0.310798 -0.346971   \n",
       "Theta2        0.243162 -0.267251  0.825450 -0.461018 -0.071866 -0.000216   \n",
       "Alpha2       -0.188634 -0.476656 -0.433043  0.929158  0.089228  0.107003   \n",
       "Beta2        -0.317625 -0.380655 -0.079128  0.158225  0.694898  0.413496   \n",
       "Gamma2       -0.632349 -0.437206  0.008968  0.198670  0.403377  0.781208   \n",
       "Mean         -0.002944  0.016586  0.010186 -0.013342 -0.031425 -0.016031   \n",
       "Median       -0.140687 -0.061527  0.075839 -0.022918 -0.002664  0.128668   \n",
       "Std           0.577428  0.553044 -0.134107 -0.208142 -0.450922 -0.693343   \n",
       "Max           0.463881  0.462369 -0.135950 -0.206702 -0.262139 -0.539296   \n",
       "Min          -0.312266 -0.424623  0.101934  0.231723  0.250368  0.360433   \n",
       "Kurtosis     -0.098621  0.134666 -0.063393 -0.201244  0.186784  0.141414   \n",
       "Skew          0.227270  0.113801 -0.093924  0.018645 -0.034675 -0.264854   \n",
       "Mean2        -0.003938  0.022215  0.005757 -0.013993 -0.033520 -0.020422   \n",
       "Median2      -0.184405 -0.083125  0.052402 -0.013111  0.065983  0.182131   \n",
       "Std2          0.457796  0.521398 -0.091540 -0.244764 -0.426433 -0.568063   \n",
       "Max2          0.422406  0.485795 -0.094059 -0.242961 -0.342121 -0.529425   \n",
       "Min2         -0.213375 -0.399799  0.068267  0.241244  0.261775  0.298940   \n",
       "Kurtosis2    -0.070741  0.134388 -0.034506 -0.167424  0.083544  0.039917   \n",
       "Skew2         0.296265  0.145934 -0.063188 -0.000533 -0.121521 -0.332304   \n",
       "Mean_emg      0.016546  0.012863  0.007134 -0.000223 -0.037666 -0.033649   \n",
       "Median_emg    0.088772  0.060735  0.018715 -0.053970 -0.052508 -0.077930   \n",
       "Std_emg      -0.590729 -0.317637 -0.050476  0.235910  0.221528  0.536805   \n",
       "Max_emg      -0.634006 -0.331344 -0.051766  0.246141  0.226315  0.566329   \n",
       "Min_emg       0.613324  0.317283  0.041462 -0.214246 -0.236491 -0.571429   \n",
       "Kurtosis_emg -0.029162 -0.074353  0.066858 -0.004713  0.027172  0.088676   \n",
       "Skew_emg     -0.136050 -0.050828 -0.020549  0.078632 -0.024971  0.069029   \n",
       "x1           -0.345841 -0.102096 -0.066416  0.095525  0.100771  0.268454   \n",
       "x2           -0.244870 -0.070040 -0.056101  0.058331  0.099809  0.209522   \n",
       "x3            0.682687  0.375448  0.075205 -0.320558 -0.227107 -0.567523   \n",
       "x4           -0.107671 -0.063770 -0.000753  0.026960  0.061542  0.130408   \n",
       "x5           -0.166074  0.126314 -0.076689 -0.061224 -0.044534  0.034931   \n",
       "x6           -0.682439 -0.362203 -0.059121  0.266313  0.258455  0.622030   \n",
       "x7           -0.671854 -0.364426 -0.067041  0.278435  0.258257  0.612482   \n",
       "x8           -0.004103 -0.004738 -0.000167  0.004550  0.002975 -0.000351   \n",
       "x9           -0.167770 -0.095444 -0.009251  0.058152  0.077809  0.173651   \n",
       "\n",
       "                Delta2    Theta2    Alpha2     Beta2  ...  Skew_emg        x1  \\\n",
       "y             0.145964  0.243162 -0.188634 -0.317625  ... -0.136050 -0.345841   \n",
       "Delta         0.833979 -0.267251 -0.476656 -0.380655  ... -0.050828 -0.102096   \n",
       "Theta        -0.339174  0.825450 -0.433043 -0.079128  ... -0.020549 -0.066416   \n",
       "Alpha        -0.459464 -0.461018  0.929158  0.158225  ...  0.078632  0.095525   \n",
       "Beta         -0.310798 -0.071866  0.089228  0.694898  ... -0.024971  0.100771   \n",
       "Gamma        -0.346971 -0.000216  0.107003  0.413496  ...  0.069029  0.268454   \n",
       "Delta2        1.000000 -0.420585 -0.511523 -0.410763  ... -0.025211 -0.140893   \n",
       "Theta2       -0.420585  1.000000 -0.465863 -0.166457  ... -0.080298  0.005538   \n",
       "Alpha2       -0.511523 -0.465863  1.000000  0.164288  ...  0.066171  0.104476   \n",
       "Beta2        -0.410763 -0.166457  0.164288  1.000000  ...  0.064247  0.036342   \n",
       "Gamma2       -0.372030 -0.095139  0.160886  0.505202  ...  0.125091  0.242075   \n",
       "Mean          0.000055  0.008581 -0.002379 -0.011162  ...  0.010327  0.055586   \n",
       "Median       -0.069882  0.057520 -0.016107  0.037279  ...  0.039828  0.165691   \n",
       "Std           0.454618 -0.107762 -0.172760 -0.351739  ... -0.042934 -0.385469   \n",
       "Max           0.396329 -0.098226 -0.181542 -0.236267  ... -0.064269 -0.366865   \n",
       "Min          -0.349814  0.062627  0.206183  0.198684  ...  0.025406  0.236715   \n",
       "Kurtosis      0.137844 -0.000177 -0.204106  0.077316  ... -0.037378 -0.020643   \n",
       "Skew          0.109302 -0.074277  0.020371 -0.071796  ... -0.053605 -0.187950   \n",
       "Mean2         0.002400  0.005615 -0.002927 -0.007791  ...  0.013784  0.067622   \n",
       "Median2      -0.078379  0.050234 -0.015342  0.064267  ...  0.020961  0.179761   \n",
       "Std2          0.394854 -0.000634 -0.194141 -0.415650  ... -0.074030  0.108729   \n",
       "Max2          0.376898 -0.028286 -0.198814 -0.308529  ... -0.059768 -0.026104   \n",
       "Min2         -0.304166  0.002522  0.208567  0.236590  ...  0.038205 -0.181804   \n",
       "Kurtosis2     0.149364 -0.062164 -0.180303  0.127182  ...  0.031193 -0.158315   \n",
       "Skew2         0.119439 -0.060380  0.016478 -0.098192  ... -0.025852 -0.268445   \n",
       "Mean_emg      0.013295 -0.017315  0.000346  0.005327  ...  0.118580 -0.040189   \n",
       "Median_emg    0.042059  0.028479 -0.041599 -0.053762  ... -0.073055  0.014546   \n",
       "Std_emg      -0.236542 -0.091462  0.199670  0.211922  ...  0.121589  0.094285   \n",
       "Max_emg      -0.251864 -0.095736  0.210578  0.223661  ...  0.280416  0.213715   \n",
       "Min_emg       0.248560  0.056965 -0.185202 -0.193531  ...  0.076394 -0.222163   \n",
       "Kurtosis_emg -0.082249  0.087217  0.000956 -0.016105  ... -0.041282  0.146473   \n",
       "Skew_emg     -0.025211 -0.080298  0.066171  0.064247  ...  1.000000  0.008604   \n",
       "x1           -0.140893  0.005538  0.104476  0.036342  ...  0.008604  1.000000   \n",
       "x2           -0.129974  0.045501  0.077530 -0.000308  ... -0.063255  0.896590   \n",
       "x3            0.251577  0.182887 -0.265490 -0.290108  ... -0.191600  0.092946   \n",
       "x4           -0.053139  0.011053  0.022441  0.028885  ...  0.010813 -0.030140   \n",
       "x5            0.079973 -0.030901 -0.045099 -0.037331  ...  0.023130  0.340787   \n",
       "x6           -0.286949 -0.084675  0.233797  0.228758  ...  0.104838  0.308772   \n",
       "x7           -0.290065 -0.093021  0.246246  0.231840  ...  0.109829  0.299090   \n",
       "x8           -0.002057 -0.004548  0.002985  0.005675  ...  0.045833 -0.024828   \n",
       "x9           -0.076955 -0.005776  0.048313  0.054518  ...  0.027312 -0.012717   \n",
       "\n",
       "                    x2        x3        x4        x5        x6        x7  \\\n",
       "y            -0.244870  0.682687 -0.107671 -0.166074 -0.682439 -0.671854   \n",
       "Delta        -0.070040  0.375448 -0.063770  0.126314 -0.362203 -0.364426   \n",
       "Theta        -0.056101  0.075205 -0.000753 -0.076689 -0.059121 -0.067041   \n",
       "Alpha         0.058331 -0.320558  0.026960 -0.061224  0.266313  0.278435   \n",
       "Beta          0.099809 -0.227107  0.061542 -0.044534  0.258455  0.258257   \n",
       "Gamma         0.209522 -0.567523  0.130408  0.034931  0.622030  0.612482   \n",
       "Delta2       -0.129974  0.251577 -0.053139  0.079973 -0.286949 -0.290065   \n",
       "Theta2        0.045501  0.182887  0.011053 -0.030901 -0.084675 -0.093021   \n",
       "Alpha2        0.077530 -0.265490  0.022441 -0.045099  0.233797  0.246246   \n",
       "Beta2        -0.000308 -0.290108  0.028885 -0.037331  0.228758  0.231840   \n",
       "Gamma2        0.167443 -0.611465  0.099021 -0.011480  0.586827  0.579518   \n",
       "Mean          0.053180  0.030361 -0.012903  0.041837 -0.004983 -0.006523   \n",
       "Median        0.147229 -0.061074  0.004422  0.088587  0.113621  0.105754   \n",
       "Std          -0.342562  0.448347 -0.106825 -0.003803 -0.543506 -0.528753   \n",
       "Max          -0.325281  0.366073 -0.081484 -0.036952 -0.457027 -0.445924   \n",
       "Min           0.212938 -0.270827  0.071917 -0.055279  0.315051  0.309671   \n",
       "Kurtosis     -0.016968  0.004420  0.002579  0.043977  0.006290 -0.000706   \n",
       "Skew         -0.160384  0.152014 -0.017905 -0.102036 -0.209266 -0.199297   \n",
       "Mean2         0.067512  0.037745 -0.016887  0.051882 -0.007101 -0.008553   \n",
       "Median2       0.171937 -0.085826  0.018500  0.076085  0.150185  0.141877   \n",
       "Std2          0.192854  0.588187 -0.072617  0.239093 -0.405544 -0.401365   \n",
       "Max2          0.037888  0.500459 -0.069384  0.173676 -0.401427 -0.396903   \n",
       "Min2         -0.236051 -0.385783  0.047416 -0.249714  0.212861  0.216112   \n",
       "Kurtosis2    -0.188366 -0.065451 -0.009716 -0.004179 -0.036379 -0.040324   \n",
       "Skew2        -0.261488  0.172389 -0.043054 -0.088816 -0.266905 -0.254843   \n",
       "Mean_emg     -0.049743  0.014825  0.192521  0.003234 -0.051951 -0.052589   \n",
       "Median_emg    0.010772  0.158683 -0.204841  0.057133 -0.097587 -0.100792   \n",
       "Std_emg       0.022110 -0.797080  0.654940  0.045000  0.857627  0.851795   \n",
       "Max_emg       0.141074 -0.753813  0.391415  0.071759  0.886947  0.857806   \n",
       "Min_emg      -0.164774  0.721190 -0.400038 -0.091201 -0.900255 -0.870296   \n",
       "Kurtosis_emg  0.201988  0.086685  0.003772 -0.004723  0.063213  0.012921   \n",
       "Skew_emg     -0.063255 -0.191600  0.010813  0.023130  0.104838  0.109829   \n",
       "x1            0.896590  0.092946 -0.030140  0.340787  0.308772  0.299090   \n",
       "x2            1.000000  0.229093 -0.019028  0.304628  0.239957  0.225877   \n",
       "x3            0.229093  1.000000 -0.200244  0.098742 -0.800578 -0.813157   \n",
       "x4           -0.019028 -0.200244  1.000000  0.048415  0.268137  0.260242   \n",
       "x5            0.304628  0.098742  0.048415  1.000000  0.084958  0.069959   \n",
       "x6            0.239957 -0.800578  0.268137  0.084958  1.000000  0.992204   \n",
       "x7            0.225877 -0.813157  0.260242  0.069959  0.992204  1.000000   \n",
       "x8           -0.014202 -0.011628  0.217408  0.009587  0.001568 -0.003696   \n",
       "x9           -0.007551 -0.267772  0.908049  0.044709  0.316733  0.311847   \n",
       "\n",
       "                    x8        x9  \n",
       "y            -0.004103 -0.167770  \n",
       "Delta        -0.004738 -0.095444  \n",
       "Theta        -0.000167 -0.009251  \n",
       "Alpha         0.004550  0.058152  \n",
       "Beta          0.002975  0.077809  \n",
       "Gamma        -0.000351  0.173651  \n",
       "Delta2       -0.002057 -0.076955  \n",
       "Theta2       -0.004548 -0.005776  \n",
       "Alpha2        0.002985  0.048313  \n",
       "Beta2         0.005675  0.054518  \n",
       "Gamma2        0.010983  0.154043  \n",
       "Mean          0.000251 -0.010557  \n",
       "Median        0.001065  0.015543  \n",
       "Std          -0.002626 -0.147944  \n",
       "Max          -0.001886 -0.116875  \n",
       "Min           0.005827  0.098893  \n",
       "Kurtosis     -0.002242 -0.001406  \n",
       "Skew          0.002429 -0.033746  \n",
       "Mean2         0.010403 -0.012037  \n",
       "Median2       0.006736  0.032830  \n",
       "Std2         -0.006464 -0.114838  \n",
       "Max2         -0.000918 -0.109166  \n",
       "Min2          0.008272  0.071701  \n",
       "Kurtosis2     0.008767 -0.010514  \n",
       "Skew2         0.005004 -0.063393  \n",
       "Mean_emg      0.258028  0.298477  \n",
       "Median_emg   -0.184653 -0.163503  \n",
       "Std_emg       0.139517  0.694185  \n",
       "Max_emg       0.086102  0.422729  \n",
       "Min_emg       0.009326 -0.420981  \n",
       "Kurtosis_emg -0.001734 -0.004474  \n",
       "Skew_emg      0.045833  0.027312  \n",
       "x1           -0.024828 -0.012717  \n",
       "x2           -0.014202 -0.007551  \n",
       "x3           -0.011628 -0.267772  \n",
       "x4            0.217408  0.908049  \n",
       "x5            0.009587  0.044709  \n",
       "x6            0.001568  0.316733  \n",
       "x7           -0.003696  0.311847  \n",
       "x8            1.000000  0.378180  \n",
       "x9            0.378180  1.000000  \n",
       "\n",
       "[41 rows x 41 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df = ytrain.join(xtrain_scaled)\n",
    "corr_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.74165545e-01, 7.99237935e-02, 7.15225315e-02, 8.10671827e-02,\n",
       "       4.58329582e-01, 1.39871628e-01, 8.30667569e-02, 5.43084588e-02,\n",
       "       7.89312636e-02, 4.82115185e-01, 8.73990898e-03, 3.76429737e-02,\n",
       "       4.56881338e-01, 3.05479095e-01, 1.80246811e-01, 4.26501134e-02,\n",
       "       4.88062371e-02, 1.37189286e-02, 4.93786307e-02, 2.57993109e-01,\n",
       "       2.39000068e-01, 8.33751164e-02, 5.63293350e-02, 7.84169313e-02,\n",
       "       2.18036879e-01, 1.60975223e-01, 4.70600841e-01, 5.15050578e-01,\n",
       "       5.05110400e-01, 1.64293936e-01, 6.30753976e-02, 1.16970776e-01,\n",
       "       1.66043079e-01, 3.45643682e-01, 1.07820896e-01, 1.44400152e-01,\n",
       "       5.70936519e-01, 5.69448147e-01, 1.07867469e-04, 4.64127459e-01])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_info = mutual_info_classif(xtrain_eeg.values, ytrain.values.ravel())\n",
    "mu_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x8              0.000108\n",
       "Mean            0.008740\n",
       "Mean2           0.013719\n",
       "Median          0.037643\n",
       "Kurtosis        0.042650\n",
       "Skew            0.048806\n",
       "Median2         0.049379\n",
       "Alpha2          0.054308\n",
       "Kurtosis2       0.056329\n",
       "Skew_emg        0.063075\n",
       "Alpha           0.071523\n",
       "Skew2           0.078417\n",
       "Beta2           0.078931\n",
       "Theta           0.079924\n",
       "Beta            0.081067\n",
       "Theta2          0.083067\n",
       "Min2            0.083375\n",
       "x4              0.107821\n",
       "x1              0.116971\n",
       "Delta2          0.139872\n",
       "x5              0.144400\n",
       "Median_emg      0.160975\n",
       "Kurtosis_emg    0.164294\n",
       "x2              0.166043\n",
       "Delta           0.174166\n",
       "Min             0.180247\n",
       "Mean_emg        0.218037\n",
       "Max2            0.239000\n",
       "Std2            0.257993\n",
       "Max             0.305479\n",
       "x3              0.345644\n",
       "Std             0.456881\n",
       "Gamma           0.458330\n",
       "x9              0.464127\n",
       "Std_emg         0.470601\n",
       "Gamma2          0.482115\n",
       "Min_emg         0.505110\n",
       "Max_emg         0.515051\n",
       "x7              0.569448\n",
       "x6              0.570937\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mu_info, index = xtrain_eeg.columns).sort_values(ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200, score=0.813, total= 2.4min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200, score=0.925, total= 2.2min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200, score=0.757, total= 2.3min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200, score=0.813, total= 2.2min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200, score=0.925, total= 2.4min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200, score=0.757, total= 2.2min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200, score=0.813, total= 2.1min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200, score=0.925, total= 2.3min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200, score=0.757, total= 2.2min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200, score=0.805, total= 3.8min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200, score=0.928, total= 3.8min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200, score=0.761, total= 3.6min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200, score=0.805, total= 3.7min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200, score=0.928, total= 4.1min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200, score=0.761, total= 3.8min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200, score=0.805, total= 3.6min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200, score=0.928, total= 3.8min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200, score=0.761, total= 3.6min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200, score=0.807, total= 4.4min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200, score=0.929, total= 4.7min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200, score=0.763, total= 5.0min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200, score=0.807, total= 4.6min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200, score=0.929, total= 4.9min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200, score=0.763, total= 4.6min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200, score=0.807, total= 4.4min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200, score=0.929, total= 4.8min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200, score=0.763, total= 4.8min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200, score=0.807, total= 5.1min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200, score=0.929, total= 5.3min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200, score=0.765, total= 5.0min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200, score=0.807, total= 4.7min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200, score=0.929, total= 5.2min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200, score=0.765, total= 5.0min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200, score=0.807, total= 4.7min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200, score=0.929, total= 5.2min\n",
      "[CV] classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.05, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200, score=0.765, total= 5.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200, score=0.803, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200, score=0.927, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200, score=0.758, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200, score=0.803, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200, score=0.927, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200, score=0.758, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200, score=0.803, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200, score=0.927, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200, score=0.758, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200, score=0.806, total= 3.5min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200, score=0.929, total= 3.7min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200, score=0.763, total= 3.6min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200, score=0.806, total= 3.5min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200, score=0.929, total= 3.7min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200, score=0.763, total= 3.6min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200, score=0.806, total= 3.5min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200, score=0.929, total= 3.7min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200, score=0.763, total= 3.6min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200, score=0.807, total= 4.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200, score=0.930, total= 4.3min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200, score=0.766, total= 4.1min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200, score=0.807, total= 3.9min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200, score=0.930, total= 4.3min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200, score=0.766, total= 4.1min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200, score=0.807, total= 3.9min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200, score=0.930, total= 4.4min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200, score=0.766, total= 4.1min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200, score=0.807, total= 4.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200, score=0.930, total= 4.5min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200, score=0.765, total= 4.3min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200, score=0.807, total= 4.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200, score=0.930, total= 4.5min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200, score=0.765, total= 4.4min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200, score=0.807, total= 4.0min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200, score=0.930, total= 4.5min\n",
      "[CV] classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.1, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200, score=0.765, total= 4.3min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200, score=0.807, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200, score=0.929, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200, score=0.757, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200, score=0.807, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200, score=0.929, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200, score=0.757, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200, score=0.807, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200, score=0.929, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200, score=0.757, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200, score=0.807, total= 3.3min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200, score=0.930, total= 3.5min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200, score=0.768, total= 3.5min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200, score=0.807, total= 3.3min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200, score=0.930, total= 3.6min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200, score=0.768, total= 3.5min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200, score=0.807, total= 3.3min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200, score=0.930, total= 3.5min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200, score=0.768, total= 3.5min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200, score=0.807, total= 3.6min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200, score=0.930, total= 3.9min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200, score=0.767, total= 3.8min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200, score=0.807, total= 3.6min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200, score=0.930, total= 3.9min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200, score=0.767, total= 3.8min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200, score=0.807, total= 3.6min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200, score=0.930, total= 4.0min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200, score=0.767, total= 3.8min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200, score=0.810, total= 3.7min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200, score=0.930, total= 4.1min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200, score=0.767, total= 3.9min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200, score=0.810, total= 3.7min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200, score=0.930, total= 4.1min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200, score=0.767, total= 4.0min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200, score=0.810, total= 3.7min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200, score=0.930, total= 4.1min\n",
      "[CV] classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.15, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200, score=0.767, total= 3.9min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200, score=0.808, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200, score=0.931, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=20, classifier__n_estimators=200, score=0.757, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200, score=0.808, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200, score=0.931, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=40, classifier__n_estimators=200, score=0.757, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200, score=0.808, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200, score=0.931, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=5, classifier__max_features=60, classifier__n_estimators=200, score=0.757, total= 2.0min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200, score=0.807, total= 3.2min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200, score=0.931, total= 3.4min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=20, classifier__n_estimators=200, score=0.771, total= 3.3min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200, score=0.807, total= 3.2min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200, score=0.931, total= 3.4min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=40, classifier__n_estimators=200, score=0.771, total= 3.3min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200, score=0.807, total= 3.2min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200, score=0.931, total= 3.4min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=10, classifier__max_features=60, classifier__n_estimators=200, score=0.771, total= 3.3min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200, score=0.806, total= 3.4min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200, score=0.931, total= 3.7min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=20, classifier__n_estimators=200, score=0.770, total= 3.6min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200, score=0.806, total= 3.3min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200, score=0.931, total= 3.7min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=40, classifier__n_estimators=200, score=0.770, total= 3.6min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200, score=0.806, total= 3.3min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200, score=0.931, total= 3.7min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=15, classifier__max_features=60, classifier__n_estimators=200, score=0.770, total= 3.7min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200, score=0.807, total= 3.4min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200, score=0.932, total= 3.8min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=20, classifier__n_estimators=200, score=0.766, total= 3.7min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200, score=0.807, total= 3.4min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200, score=0.932, total= 3.8min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=40, classifier__n_estimators=200, score=0.766, total= 3.7min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200, score=0.807, total= 3.4min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200, score=0.932, total= 3.9min\n",
      "[CV] classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200 \n",
      "[CV]  classifier__learning_rate=0.2, classifier__max_depth=20, classifier__max_features=60, classifier__n_estimators=200, score=0.766, total= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 144 out of 144 | elapsed: 497.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8362331538349184\n",
      "{'classifier__learning_rate': 0.2, 'classifier__max_depth': 10, 'classifier__max_features': 20, 'classifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "## SVC APPROACH -- GRID-SEARCH CV\n",
    "'''\n",
    "steps = [(\"scaler\", StandardScaler()), (\"classifier\", SVC())]\n",
    "pipeline = Pipeline(steps = steps)\n",
    "\n",
    "parameters = {\"classifier__kernel\": [\"rbf\"],\n",
    "              \"classifier__gamma\": [\"auto\"],\n",
    "              \"classifier__C\": [0.1, 0.2, 0.3, 0.4, 0.5],  \n",
    "              \"classifier__class_weight\": [\"balanced\"],\n",
    "              \"classifier__degree\": [1,3,5]\n",
    "             }\n",
    "\n",
    "grid = GridSearchCV(pipeline, parameters, cv = 3, scoring = 'balanced_accuracy', verbose = 3)\n",
    "\n",
    "grid.fit(xtrain_eeg.values, ytrain.values.ravel())\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "'''\n",
    "\n",
    "## XGB APPROACH -- GRID-SEARCH CV\n",
    "\n",
    "steps = [(\"scaler\", StandardScaler()), (\"classifier\", xgb.XGBClassifier())]\n",
    "pipeline = Pipeline(steps = steps)\n",
    "\n",
    "parameters = {\"classifier__max_depth\": [5,10,15,20],\n",
    "              \"classifier__n_estimators\": [200],\n",
    "              \"classifier__learning_rate\": [0.05,0.1,0.15,0.2],\n",
    "              \"classifier__max_features\": [20,40,60]\n",
    "             }\n",
    "\n",
    "grid = GridSearchCV(pipeline, parameters, cv = 3, scoring = 'balanced_accuracy', verbose = 3)\n",
    "\n",
    "grid.fit(xtrain_eeg.values, ytrain.values.ravel())\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Compared performance with and without summary statistics. Marginally better with, 0.8596 vs 0.8541  \n",
    "Update: Even better with summary statistics of emg added: 0.9066\n",
    "\n",
    "With advanced stats  \n",
    "EMG processing no absolute value: 0.90758 \n",
    "EMG processing absolute value: 0.89972\n",
    "EMG no processing: 0.90535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biosppy.signals import emg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Digital filter critical frequencies must be 0 < Wn < 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3ec5d12f0c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxtrain_emg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/biosppy/signals/emg.py\u001b[0m in \u001b[0;36memg\u001b[0;34m(signal, sampling_rate, show)\u001b[0m\n\u001b[1;32m     61\u001b[0m                                       \u001b[0mftype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'butter'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                                       \u001b[0mband\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'highpass'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                                       \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                                       \u001b[0mfrequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrequency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                                       sampling_rate=sampling_rate)\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/biosppy/signals/tools.py\u001b[0m in \u001b[0;36mfilter_signal\u001b[0;34m(signal, ftype, band, order, frequency, sampling_rate, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m                       \u001b[0mfrequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrequency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                       \u001b[0msampling_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                       band=band, **kwargs)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;31m# filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/biosppy/signals/tools.py\u001b[0m in \u001b[0;36mget_filter\u001b[0;34m(ftype, band, order, frequency, sampling_rate, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m                          \u001b[0mbtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                          \u001b[0manalog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                          output='ba', **kwargs)\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mftype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cheby1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# Chebyshev type I filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/scipy/signal/filter_design.py\u001b[0m in \u001b[0;36mbutter\u001b[0;34m(N, Wn, btype, analog, output, fs)\u001b[0m\n\u001b[1;32m   2856\u001b[0m     \"\"\"\n\u001b[1;32m   2857\u001b[0m     return iirfilter(N, Wn, btype=btype, analog=analog,\n\u001b[0;32m-> 2858\u001b[0;31m                      output=output, ftype='butter', fs=fs)\n\u001b[0m\u001b[1;32m   2859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/lib/python3.7/site-packages/scipy/signal/filter_design.py\u001b[0m in \u001b[0;36miirfilter\u001b[0;34m(N, Wn, rp, rs, btype, analog, ftype, output, fs)\u001b[0m\n\u001b[1;32m   2339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0manalog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWn\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWn\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2341\u001b[0;31m             raise ValueError(\"Digital filter critical frequencies \"\n\u001b[0m\u001b[1;32m   2342\u001b[0m                              \"must be 0 < Wn < 1\")\n\u001b[1;32m   2343\u001b[0m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Digital filter critical frequencies must be 0 < Wn < 1"
     ]
    }
   ],
   "source": [
    "emg.emg(signal = xtrain_emg.iloc[0,:], sampling_rate = 128, show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
