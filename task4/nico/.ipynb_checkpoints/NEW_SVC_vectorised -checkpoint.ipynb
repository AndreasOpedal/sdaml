{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import kurtosis,skew\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pyeeg\n",
    "from sklearn import svm\n",
    "\n",
    "import yasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_eeg1 = pd.read_csv(\"train_eeg1.csv\").drop(\"Id\", axis = 1)\n",
    "xtrain_eeg2 = pd.read_csv(\"train_eeg2.csv\").drop(\"Id\", axis = 1)\n",
    "xtrain_emg = pd.read_csv(\"train_emg.csv\").drop(\"Id\", axis = 1)\n",
    "\n",
    "ytrain = pd.read_csv(\"train_labels.csv\").drop(\"Id\", axis = 1)\n",
    "\n",
    "xtest_eeg1 = pd.read_csv(\"test_eeg1.csv\").drop(\"Id\", axis = 1)\n",
    "xtest_eeg2 = pd.read_csv(\"test_eeg2.csv\").drop(\"Id\", axis = 1)\n",
    "xtest_emg = pd.read_csv(\"test_emg.csv\").drop(\"Id\", axis = 1)\n",
    "\n",
    "xtrain_eeg1 = xtrain_eeg1.values\n",
    "xtrain_eeg2 = xtrain_eeg2.values\n",
    "xtrain_emg = xtrain_emg.values\n",
    "\n",
    "xtest_eeg1 = xtest_eeg1.values \n",
    "xtest_eeg2 = xtest_eeg2.values\n",
    "xtest_emg = xtest_emg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_dfa(x):\n",
    "    dfa_ = np.zeros((x.shape[0],), dtype=np.float64)\n",
    "    for i in (np.arange(x.shape[0])):\n",
    "        dfa_[i] = _dfa(np.asarray(x[i], dtype=np.float64))\n",
    "    return np.reshape(dfa_, (-1, 1))\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "def _embed(x, order=3, delay=1):\n",
    "    \"\"\" VECTORIZED!! Kind of TESTED. Time-delay embedding. x is an (nxd) matrix\n",
    "    \"\"\"\n",
    "    N = x.shape[1]\n",
    "    if order * delay > N:\n",
    "        raise ValueError(\"Error: order * delay should be lower than x.size\")\n",
    "    if delay < 1:\n",
    "        raise ValueError(\"Delay has to be at least 1.\")\n",
    "    if order < 2:\n",
    "        raise ValueError(\"Order has to be at least 2.\")\n",
    "    Y = np.zeros((x.shape[0], N - (order - 1) * delay, order))\n",
    "    for i in range(order):\n",
    "        Y[:, :, i] = x[:, i * delay:i * delay + Y.shape[1]]\n",
    "    return Y\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def hfd(X, Kmax):\n",
    "    \"\"\" VECTORIZED!!! TESTED: Matches the for loop output. Can test easily comparing\n",
    "    to the pyeeg.hfd() function. X now a (nxd) matrix.\n",
    "    Compute Higuchi Fractal Dimension of a time series X. kmax\n",
    "     is an HFD parameter\n",
    "    \"\"\"\n",
    "    L = []\n",
    "    x = []\n",
    "    N = X.shape[1]\n",
    "    for k in (range(1, Kmax)):\n",
    "        # Lk = np.empty(shape=[0, ])\n",
    "        Lk = np.empty(shape=[X.shape[0], 1])\n",
    "        for m in range(0, k):\n",
    "            Lmk = 0\n",
    "            for i in range(1, int(np.floor((N - m) / k))):\n",
    "                Lmk += np.abs(X[:, m + i * k] - X[:, m + i * k - k])\n",
    "            Lmk = Lmk * (N - 1) / np.floor((N - m) / float(k)) / k\n",
    "            Lmk = np.reshape(Lmk, (Lmk.shape[0], 1))\n",
    "            Lk = np.hstack((Lk, Lmk))\n",
    "\n",
    "        # Remove that first placeholder column of zeros in Lk:\n",
    "        Lk = Lk[:, 1:]\n",
    "        L.append(np.log(np.mean(Lk, axis=1)))\n",
    "        x.append([np.log(float(1) / k), 1]) # Fix this!!!\n",
    "\n",
    "    (p, _, _, _) = np.linalg.lstsq(x, L)\n",
    "    return p[0]\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def pfd(X):\n",
    "    \"\"\"VECTORIZED!!! TESTED, matches the 1d time series output. Now accepts (nxd) matrices as input\n",
    "    Compute Petrosian Fractal Dimension of a time series from either two\n",
    "    cases below:\n",
    "        1. X, the time series of type list (default)\n",
    "        2. D, the first order differential sequence of X (if D is provided,\n",
    "           recommended to speed up)\n",
    "    In case 1, D is computed using Numpy's difference function.\n",
    "    To speed up, it is recommended to compute D before calling this function\n",
    "    because D may also be used by other functions whereas computing it here\n",
    "    again will slow down.\n",
    "    \"\"\"\n",
    "    n = X.shape[1]\n",
    "    diff = np.diff(X, axis=1)\n",
    "    N_delta = np.sum(diff[:, 1:-1] * diff[:, 0:-2] < 0, axis=1)\n",
    "    return np.log10(n) / (np.log10(n) + np.log10(n / (n + 0.4 * N_delta)))\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "def fisher_info(X, Tau=3, DE=1, W=None):\n",
    "    \"\"\" VECTORIZED, TESTED, gives approximate results but not exact. Compute SVD Entropy from either two cases below:\n",
    "    \"\"\"\n",
    "    if W is None:\n",
    "        Y = _embed(X, Tau, DE)\n",
    "        W = np.linalg.svd(Y, compute_uv=0)\n",
    "        W = np.divide(W, np.reshape(np.sum(W, axis=1), (-1, 1)))  # normalize singular values\n",
    "    return -1 * np.sum(W * np.log(W), axis=1)\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "def extract_bandpower_eeg(signal, frequency = 128):\n",
    "    for i in (np.arange(signal.shape[0] / 100) + 1):\n",
    "        if i == 1:\n",
    "            df = yasa.bandpower(signal[0:int(100*i),:], sf=frequency)\n",
    "        else:\n",
    "            df = df.append(yasa.bandpower(signal[int(100*(i-1)):int(100*i),:], sf=frequency))\n",
    "    \n",
    "    df = df.set_index(np.arange(signal.shape[0]))\n",
    "    df = df.drop(columns = [\"FreqRes\",\"Relative\"], axis = 1)\n",
    "    return df\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "'''input must be np.ndarray'''\n",
    "\n",
    "def vectorized_adv_stat(signal, fs=128):\n",
    "    K_boundary = 10         # to be tuned\n",
    "    t_fisher = 12          # to be tuned\n",
    "    d_fisher = 40          # to be tuned\n",
    "    features_num = 11\n",
    "    threshold =  0.0009\n",
    "    advanced_stats = np.zeros((signal.shape[0],features_num))\n",
    "    # Missing fisher info and dfa\n",
    "    feat_array = np.array([\n",
    "                           fisher_info(signal, t_fisher, d_fisher),\n",
    "                           pfd(signal),\n",
    "                           hfd(signal, K_boundary),\n",
    "                           np.sum((np.power(np.abs(signal),(-0.3)) > 20), axis=1),\n",
    "                           np.sum((np.abs(signal)) > threshold, axis=1),\n",
    "                           np.std(np.power(np.abs(signal),(0.05)), axis=1),\n",
    "                           np.sqrt(np.mean(np.power(np.diff(signal, axis=1), 2), axis=1)),\n",
    "                           np.mean(np.abs(np.diff(signal, axis=1)), axis=1),\n",
    "                           np.mean(np.power(signal, 5), axis=1),\n",
    "                           np.sum(np.power(signal, 2), axis=1)\n",
    "                           ]).T\n",
    "    feat_array = np.concatenate((feat_array, matrix_dfa(signal)), axis=1) # Concatenate the lengthy dfa calculation\n",
    "\n",
    "    return feat_array\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "def simple_stats(signal, fs = 128):\n",
    "           \n",
    "    if (len(signal.shape) > 1) and (signal.shape[1]!=1):\n",
    "        simple_stats = np.array([np.mean(signal, axis=1), \n",
    "                        np.median(signal, axis=1),\n",
    "                        np.std(signal, axis=1), \n",
    "                        np.max(signal, axis=1),\n",
    "                        np.min(signal, axis=1), \n",
    "                        kurtosis(signal, axis=1),\n",
    "                        skew(signal, axis=1), \n",
    "                        np.sum(np.abs(signal), axis = 1)]).T\n",
    "                        \n",
    "    else:\n",
    "        print(\"Not Tested with this input!\")\n",
    "        simple_stats =  np.array([np.mean(signal), \n",
    "                        np.median(signal), \n",
    "                        np.std(sigal),\n",
    "                        np.max(signal), \n",
    "                        np.min(signal), \n",
    "                        float(kurtosis(signal)),\n",
    "                        float(skew(signal))])\n",
    "        \n",
    "    \n",
    "\n",
    "    return (simple_stats)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def EEG_feature_extraction(signal, fs = 128): \n",
    "    eeg_features = np.concatenate((extract_bandpower_eeg(signal, frequency = 128), vectorized_adv_stat(signal, fs=128),\n",
    "                                   simple_stats(signal, fs = 128)), axis = 1)\n",
    "    \n",
    "    return(eeg_features)\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "def EMG_feature_extraction(signal, fs = 128):\n",
    "    \n",
    "    features_num_emg = 6\n",
    "    \n",
    "    if (len(signal.shape) > 1) and (signal.shape[1]!=1):\n",
    "        simple_stats = np.array([np.mean(signal, axis=1), \n",
    "                        np.median(signal, axis=1),\n",
    "                        np.std(signal, axis=1), \n",
    "                        np.max(signal, axis=1),\n",
    "                        np.min(signal, axis=1), \n",
    "                        kurtosis(signal, axis=1),\n",
    "                        skew(signal, axis=1), \n",
    "                        pd.Series(np.sum(np.abs(signal), axis = 1))]).T\n",
    "                        \n",
    "    else:\n",
    "        print(\"Not Tested with this input!\")\n",
    "        simple_stats =  np.array([np.mean(signal), \n",
    "                        np.median(signal), \n",
    "                        np.std(sigal),\n",
    "                        np.max(signal), \n",
    "                        np.min(signal), \n",
    "                        float(kurtosis(signal)),\n",
    "                        float(skew(signal))])\n",
    "\n",
    "    advanced_stats = np.zeros((signal.shape[0],features_num_emg))\n",
    "    for i in tqdm((np.arange(signal.shape[0]))):\n",
    "        feat_array = np.array([\n",
    "                              np.median(signal[i,:] ** 2), \n",
    "                              np.median(np.abs(np.diff(signal[i,:]))), \n",
    "                              np.std(np.abs(np.diff(signal[i,:]))), \n",
    "                              np.sum(np.abs(np.diff(signal[i,:]))), \n",
    "                              np.mean(np.power(np.diff(signal[i,:]), 2)),\n",
    "                              np.std(abs(signal[i,:]))\n",
    "                            ])\n",
    "\n",
    "        advanced_stats[i, :] = feat_array \n",
    "        \n",
    "        union_smpl_adv = np.concatenate((simple_stats, advanced_stats), axis = 1)\n",
    "\n",
    "    return(union_smpl_adv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicolò Grometto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\Nicolò Grometto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:105: RuntimeWarning: divide by zero encountered in power\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad834f217ce24436a33b42ee93d651a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=64800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(64800, 60)\n"
     ]
    }
   ],
   "source": [
    "xtrain_eeg1_processed = EEG_feature_extraction(xtrain_eeg1, 128)\n",
    "xtrain_eeg2_processed = EEG_feature_extraction(xtrain_eeg2, 128)\n",
    "xtrain_emg_processed = EMG_feature_extraction(xtrain_emg, 128)\n",
    "xtrain = np.concatenate((xtrain_eeg1_processed, \n",
    "                         xtrain_eeg2_processed, \n",
    "                         xtrain_emg_processed), \n",
    "                         axis = 1)\n",
    "print(xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] classifier__C=0.1, classifier__class_weight=balanced, classifier__gamma=auto, classifier__kernel=rbf \n",
      "[CV]  classifier__C=0.1, classifier__class_weight=balanced, classifier__gamma=auto, classifier__kernel=rbf, total=  27.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   27.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] classifier__C=0.1, classifier__class_weight=balanced, classifier__gamma=auto, classifier__kernel=rbf \n",
      "[CV]  classifier__C=0.1, classifier__class_weight=balanced, classifier__gamma=auto, classifier__kernel=rbf, total=  37.5s\n",
      "[CV] classifier__C=0.1, classifier__class_weight=balanced, classifier__gamma=auto, classifier__kernel=rbf \n",
      "[CV]  classifier__C=0.1, classifier__class_weight=balanced, classifier__gamma=auto, classifier__kernel=rbf, total=  36.7s\n",
      "[CV] classifier__C=0.3, classifier__class_weight=balanced, classifier__gamma=auto, classifier__kernel=rbf \n",
      "[CV]  classifier__C=0.3, classifier__class_weight=balanced, classifier__gamma=auto, classifier__kernel=rbf, total=  21.5s\n",
      "[CV] classifier__C=0.3, classifier__class_weight=balanced, classifier__gamma=auto, classifier__kernel=rbf \n",
      "[CV]  classifier__C=0.3, classifier__class_weight=balanced, classifier__gamma=auto, classifier__kernel=rbf, total=  32.4s\n",
      "[CV] classifier__C=0.3, classifier__class_weight=balanced, classifier__gamma=auto, classifier__kernel=rbf \n",
      "[CV]  classifier__C=0.3, classifier__class_weight=balanced, classifier__gamma=auto, classifier__kernel=rbf, total=  33.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9200190564541171\n",
      "{'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "xtrain_grid = pd.DataFrame(xtrain)\n",
    "\n",
    "steps = [(\"scaler\", StandardScaler()), (\"classifier\", SVC())]\n",
    "pipeline = Pipeline(steps = steps)\n",
    "\n",
    "parameters = {\"classifier__kernel\": [\"rbf\"],\n",
    "              \"classifier__gamma\": [\"auto\"],\n",
    "              \"classifier__C\": [0.1, 0.3],  \n",
    "              \"classifier__class_weight\": [\"balanced\"]\n",
    "             }\n",
    "grid = GridSearchCV(pipeline, parameters, cv = 3, scoring = 'balanced_accuracy', verbose = 2)\n",
    "\n",
    "grid.fit(xtrain_grid, ytrain.values.ravel())\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicolò Grometto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "C:\\Users\\Nicolò Grometto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:105: RuntimeWarning: divide by zero encountered in power\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a99eabb3cb84ccc898e5ff19ddac0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=43200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtest_eeg1_processed = EEG_feature_extraction(xtest_eeg1, 128)\n",
    "xtest_eeg2_processed = EEG_feature_extraction(xtest_eeg2, 128)\n",
    "xtest_emg_processed = EMG_feature_extraction(xtest_emg, 128)\n",
    "xtest = np.concatenate((xtest_eeg1_processed, \n",
    "                         xtest_eeg2_processed, \n",
    "                         xtest_emg_processed), \n",
    "                         axis = 1)\n",
    "\n",
    "##############################################################################\n",
    "'''train and predict'''\n",
    "##############################################################################\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', C = 0.1, gamma = 'auto', class_weight = 'balanced')\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "xtrain_rescaled = scaler.fit_transform(xtrain_grid)\n",
    "xtest_rescaled = scaler.fit_transform(xtest)\n",
    "\n",
    "clf.fit(xtrain_rescaled, ytrain)\n",
    "ypred = clf.predict(xtest_rescaled)\n",
    "\n",
    "index = pd.read_csv(\"sample.csv\")\n",
    "index['y'] = ypred\n",
    "index.to_csv(\"trail_svc_feature_extraction_vectorised.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
