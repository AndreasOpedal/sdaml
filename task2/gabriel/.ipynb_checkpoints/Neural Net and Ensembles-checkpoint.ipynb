{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Do all necessary preprocessing, calling prepro.py\n",
    "import utils\n",
    "from utils import *\n",
    "importlib.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, X_test_original, y = load_data() \n",
    "y = y.ravel()\n",
    "scores = np.array([])\n",
    "xtrain = X  # For andreas cross validation\n",
    "ytrain = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Isolation Forest in case we need it: \n",
    "# # Fit an isolation forest\n",
    "# clf = IsolationForest(n_estimators=n_estimators)\n",
    "# clf.fit(X_new)\n",
    "# clf.decision_function(X_new)\n",
    "# inlier_indices = np.where(clf.predict(X_new) == 1)[0]\n",
    "# print(\"Size of inliers:\", inlier_indices.shape)\n",
    "# X_inliers = X_new[inlier_indices]\n",
    "# y_inliers = y_[inlier_indices]\n",
    "# X_test_inliers = X_test_new # Do not remove outliers from test dataset\n",
    "# y_test_inliers = y_test\n",
    "# print(\"Inliers shapes:\", X_inliers.shape, y_inliers.shape)\n",
    "\n",
    "# SMOTEClassifier(SMOTE(), xgb.XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andreas Optimal Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple pipeline with grid search\n",
    "\n",
    "steps = [(\"scaler\", preprocessing.StandardScaler()), (\"classifier\", svm.SVC())]\n",
    "\n",
    "pipeline = Pipeline(steps = steps)\n",
    "\n",
    "parameters = {\"classifier__kernel\": [\"rbf\"],\n",
    "              \"classifier__gamma\": [\"auto\"],\n",
    "              \"classifier__C\": [0.1, 0.5, 1, 5, 10, 50, 100],\n",
    "              \"classifier__degree\": [1, 2, 3, 4, 5, 6],\n",
    "              \"classifier__class_weight\": [\"balanced\"]\n",
    "             }\n",
    "\n",
    "grid = GridSearchCV(pipeline, parameters, cv = 5, scoring = 'balanced_accuracy')\n",
    "\n",
    "# grid.fit(xtrain.values, ytrain.values.ravel())\n",
    "\n",
    "# 0.7015740740740741\n",
    "# {'classifier__C': 0.5, 'classifier__class_weight': 'balanced', 'classifier__degree': 1, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras NN Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'IsolationForest(behaviour='old', bootstrap=False, contamination='legacy',\n                max_features=1.0, max_samples='auto', n_estimators=100,\n                n_jobs=None, random_state=None, verbose=0, warm_start=False)' (type <class 'sklearn.ensemble.iforest.IsolationForest'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-726222e1301e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outliers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mlp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mcw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m                                 \u001b[0;34m\"transformers and implement fit and transform \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                                 \u001b[0;34m\"or be the string 'passthrough' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                                 \"'%s' (type %s) doesn't\" % (t, type(t)))\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# We allow last estimator to be None as an identity transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'IsolationForest(behaviour='old', bootstrap=False, contamination='legacy',\n                max_features=1.0, max_samples='auto', n_estimators=100,\n                n_jobs=None, random_state=None, verbose=0, warm_start=False)' (type <class 'sklearn.ensemble.iforest.IsolationForest'>) doesn't"
     ]
    }
   ],
   "source": [
    "# dropout in hidden layers with weight constraint\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(, input_dim=1000, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(60, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(30, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    # Compile model\n",
    "#     sgd = SGD(lr=0.02, momentum=0.9)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "# One hot encode data\n",
    "# enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "# y_enc = enc.fit_transform(y)\n",
    "y_enc = np.zeros((y.shape[0], 3))\n",
    "y_enc[np.arange(y.shape[0]), y] = 1\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', preprocessing.StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_model, epochs=20, batch_size=32, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "cw = sklearn.utils.class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "class_weight = {0: cw[0], 1: cw[1], 2: cw[2]}\n",
    "def score(estimator, X_, y_):\n",
    "    pred = estimator.predict(X_)\n",
    "    y_normal = np.argmax(y_, axis=1)\n",
    "    BMAC = balanced_accuracy_score(y_normal, pred)\n",
    "    return BMAC\n",
    "results = cross_val_score(pipeline, X, y_enc, cv=kfold, verbose=2, scoring=score, \n",
    "                          fit_params={'mlp__class_weight': class_weight})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800/4800 [==============================] - 0s 67us/step\n",
      "[0 0 2 ... 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "pred = pipeline.predict(X)\n",
    "BMAC = balanced_accuracy_score(y, pred)\n",
    "# print(BMAC)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "[1 0 2 ... 1 1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, ..., 1, 1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_enc = np.zeros((y.shape[0], 3))\n",
    "y_enc[np.arange(y.shape[0]), y] = 1\n",
    "print(y_enc)\n",
    "print(y)\n",
    "np.argmax(y_enc, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn NN grid search (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [(\"scaler\", preprocessing.StandardScaler()), (\"classifier\", SMOTEClassifier(SMOTE(), MLPClassifier()))]\n",
    "pipeline = Pipeline(steps = steps)\n",
    "\n",
    "parameters = {\"classifier__solver\": ['lbfgs'],\n",
    "              \"classifier__alpha\": [1e-5, 1e-3, 0.1, 0.3, 0.5],\n",
    "              \"classifier__hidden_layer_sizes\": [(30, 30), (80, 80), (150, 150)],\n",
    "              \"classifier__activation\": ['relu', 'logistic'],\n",
    "              \"classifier__learning_rate\": [\"invscaling\", \"constant\"], \n",
    "              \"classifier__learning_rate_init\": [0.0005, 0.001, 0.005, 0.01], \n",
    "              \"classifier__beta_1\": [0.8, 0.9, 0.999], \n",
    "              \"classifier__beta_2\": [0.8, 0.9, 0.999], \n",
    "              \"classifier__early_stopping\": [True], \n",
    "             }\n",
    "\n",
    "grid = GridSearchCV(pipeline, parameters, cv = 5, scoring = 'balanced_accuracy', verbose=1)\n",
    "\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKlearn NN and Andreas Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                       hidden_layer_sizes=(150,150), random_state=1,\n",
    "                        activation='relu', learning_rate='invscaling', beta_1=0.9, \n",
    "                          beta_2=0.999, learning_rate_init=0.001, early_stopping=True,\n",
    "                          momentum=0.9, shuffle=True, epsilon=1e-08, \n",
    "\n",
    "                      )\n",
    "andreas_svm = svm.SVC(C=0.5, class_weight='balanced', degree=1, gamma='auto', kernel='rbf')\n",
    "eclf = VotingClassifier(estimators=[('svm', andreas_svm), ('mlp', mlp)], voting='hard')\n",
    "\n",
    "steps = [(\"scaler\", preprocessing.StandardScaler()), (\"classifier\", eclf)]\n",
    "pipeline = Pipeline(steps = steps)\n",
    "\n",
    "score = cross_val_score(pipeline, X, y, cv=kf, scoring=make_scorer(balanced_accuracy_score), verbose=2)\n",
    "print(\"Score:\", score)\n",
    "\n",
    "# Ensemble score: Score: [0.66481481 0.64861111 0.67824074 0.6462963  0.65231481]\n",
    "# Andreas SVM score: Score: [0.69907407 0.70740741 0.69583333 0.67962963 0.70416667]\n",
    "# Result: Ensemble MLP (no SMOTE) + SVM is bad, and no SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
