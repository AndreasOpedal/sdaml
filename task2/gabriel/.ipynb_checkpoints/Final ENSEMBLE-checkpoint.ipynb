{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all necessary preprocessing, calling prepro.py\n",
    "import utils\n",
    "from utils import *\n",
    "importlib.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, X_test_original, y = load_data() \n",
    "y = y.ravel()\n",
    "scores = np.array([])\n",
    "xtrain = X  # For andreas cross validation\n",
    "ytrain = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN1():\n",
    "    def __init__(self):\n",
    "        self.mlp = KerasClassifier(build_fn=self.create_model, \n",
    "                                   epochs=25, batch_size=35, \n",
    "                                   verbose=1)\n",
    "        return\n",
    "    \n",
    "    def score(self, X_, y_):\n",
    "        pred = self.predict(X_)\n",
    "        if y_.shape[1] < 2:\n",
    "            y_normal = y_\n",
    "        else:\n",
    "            y_normal = np.argmax(y_, axis=1)\n",
    "        BMAC = balanced_accuracy_score(y_normal, pred)\n",
    "        return BMAC\n",
    "    \n",
    "    def fit(self, X_, y_):\n",
    "        # One hot encode data\n",
    "        y_enc = np.zeros((y_.shape[0], 3))\n",
    "        y_enc[np.arange(y_.shape[0]), y_] = 1\n",
    "        \n",
    "        xscaled = preprocessing.StandardScaler().fit_transform(X_)\n",
    "        cw = sklearn.utils.class_weight.compute_class_weight('balanced', np.unique(y_), y_)\n",
    "        class_weight = {0: cw[0], 1: cw[1], 2: cw[2]}\n",
    "        self.mlp.fit(xscaled, y_enc, class_weight=class_weight)\n",
    "        return\n",
    "    \n",
    "    def predict(self, X_):\n",
    "        return self.mlp.predict(preprocessing.StandardScaler().fit_transform(X_))\n",
    "    \n",
    "    def create_model(self):\n",
    "        # create model\n",
    "        neurons = 30\n",
    "        dropout_rate = 0.7\n",
    "        weight_constraint = 4\n",
    "        model = Sequential()\n",
    "        model.add(Dense(neurons, input_dim=1000, activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(neurons, activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
    "        model.add(Dropout(dropout_rate*0.4))\n",
    "        model.add(Dense(int(neurons/2), activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
    "        model.add(Dropout(dropout_rate*0.2))\n",
    "        model.add(Dense(3, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def predict_proba(self, X_):\n",
    "        return self.mlp.predict_proba(preprocessing.StandardScaler().fit_transform(X_))\n",
    "\n",
    "# nn = NN1()\n",
    "# nn.fit(X[1:10], y[1:10])\n",
    "# ypredy = nn.predict(X[1:10])\n",
    "# probbb = nn.predict_proba(X[1:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble dei modelliiiii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ensemble voting classifier fn:\n",
    "\n",
    "def ensemby(y1_prob, y2_prob, voting='soft'):\n",
    "    # Return the argmax of the sum of the probabilities\n",
    "    return np.argmax(y1_prob + y2_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting SVM...\n",
      "Fitting NN...\n",
      "Epoch 1/25\n",
      "3840/3840 [==============================] - 2s 515us/step - loss: 0.7133 - acc: 0.5098\n",
      "Epoch 2/25\n",
      "3840/3840 [==============================] - 1s 168us/step - loss: 0.6211 - acc: 0.6533\n",
      "Epoch 3/25\n",
      "3840/3840 [==============================] - 1s 169us/step - loss: 0.5722 - acc: 0.7372\n",
      "Epoch 4/25\n",
      "3840/3840 [==============================] - 1s 200us/step - loss: 0.5507 - acc: 0.7553\n",
      "Epoch 5/25\n",
      "3840/3840 [==============================] - 1s 171us/step - loss: 0.5296 - acc: 0.7589\n",
      "Epoch 6/25\n",
      "3840/3840 [==============================] - 1s 170us/step - loss: 0.5044 - acc: 0.7712\n",
      "Epoch 7/25\n",
      "3840/3840 [==============================] - 1s 200us/step - loss: 0.4928 - acc: 0.7745\n",
      "Epoch 8/25\n",
      "3840/3840 [==============================] - 1s 171us/step - loss: 0.4934 - acc: 0.7780\n",
      "Epoch 9/25\n",
      "3840/3840 [==============================] - 1s 172us/step - loss: 0.4702 - acc: 0.7850\n",
      "Epoch 10/25\n",
      "3840/3840 [==============================] - 1s 205us/step - loss: 0.4643 - acc: 0.7787\n",
      "Epoch 11/25\n",
      "3840/3840 [==============================] - 1s 172us/step - loss: 0.4503 - acc: 0.7889\n",
      "Epoch 12/25\n",
      "3840/3840 [==============================] - 1s 175us/step - loss: 0.4459 - acc: 0.7928\n",
      "Epoch 13/25\n",
      "3840/3840 [==============================] - 1s 203us/step - loss: 0.4363 - acc: 0.7924\n",
      "Epoch 14/25\n",
      "3840/3840 [==============================] - 1s 174us/step - loss: 0.4409 - acc: 0.8105\n",
      "Epoch 15/25\n",
      "3840/3840 [==============================] - 1s 173us/step - loss: 0.4307 - acc: 0.7992\n",
      "Epoch 16/25\n",
      "3840/3840 [==============================] - 1s 196us/step - loss: 0.4117 - acc: 0.8125\n",
      "Epoch 17/25\n",
      "3840/3840 [==============================] - 1s 171us/step - loss: 0.3974 - acc: 0.8157\n",
      "Epoch 18/25\n",
      "3840/3840 [==============================] - 1s 175us/step - loss: 0.3972 - acc: 0.8135\n",
      "Epoch 19/25\n",
      "3840/3840 [==============================] - 1s 211us/step - loss: 0.4012 - acc: 0.8199\n",
      "Epoch 20/25\n",
      "3840/3840 [==============================] - 1s 172us/step - loss: 0.3779 - acc: 0.8252\n",
      "Epoch 21/25\n",
      "3840/3840 [==============================] - 1s 173us/step - loss: 0.3859 - acc: 0.8301\n",
      "Epoch 22/25\n",
      "3840/3840 [==============================] - 1s 205us/step - loss: 0.3847 - acc: 0.8248\n",
      "Epoch 23/25\n",
      "3840/3840 [==============================] - 1s 174us/step - loss: 0.3789 - acc: 0.8264\n",
      "Epoch 24/25\n",
      "3840/3840 [==============================] - 1s 173us/step - loss: 0.3690 - acc: 0.8321\n",
      "Epoch 25/25\n",
      "3840/3840 [==============================] - 1s 204us/step - loss: 0.3704 - acc: 0.8305\n",
      "960/960 [==============================] - 0s 177us/step\n",
      "960/960 [==============================] - 0s 21us/step\n",
      "BMAC Ensemble Scores:  0.6906987136388287\n",
      "BMAC SVM Scores:  0.7280387367594172\n",
      "BMAC NN Scores:  0.7257387246217902\n",
      "Fitting SVM...\n",
      "Fitting NN...\n",
      "Epoch 1/25\n",
      "3840/3840 [==============================] - 2s 484us/step - loss: 0.6434 - acc: 0.6747\n",
      "Epoch 2/25\n",
      "3840/3840 [==============================] - 1s 151us/step - loss: 0.5621 - acc: 0.7605\n",
      "Epoch 3/25\n",
      "3840/3840 [==============================] - 1s 158us/step - loss: 0.5428 - acc: 0.7728\n",
      "Epoch 4/25\n",
      "3840/3840 [==============================] - 1s 186us/step - loss: 0.5217 - acc: 0.7843\n",
      "Epoch 5/25\n",
      "3840/3840 [==============================] - 1s 152us/step - loss: 0.5027 - acc: 0.7945\n",
      "Epoch 6/25\n",
      "3840/3840 [==============================] - 1s 152us/step - loss: 0.4847 - acc: 0.8013\n",
      "Epoch 7/25\n",
      "3840/3840 [==============================] - 1s 181us/step - loss: 0.4799 - acc: 0.8076\n",
      "Epoch 8/25\n",
      "3840/3840 [==============================] - 1s 151us/step - loss: 0.4734 - acc: 0.8097\n",
      "Epoch 9/25\n",
      "3840/3840 [==============================] - 1s 152us/step - loss: 0.4643 - acc: 0.8109\n",
      "Epoch 10/25\n",
      "3840/3840 [==============================] - 1s 151us/step - loss: 0.4509 - acc: 0.8187\n",
      "Epoch 11/25\n",
      "3840/3840 [==============================] - 1s 177us/step - loss: 0.4515 - acc: 0.8203\n",
      "Epoch 12/25\n",
      "3840/3840 [==============================] - 1s 152us/step - loss: 0.4412 - acc: 0.8229\n",
      "Epoch 13/25\n",
      "3840/3840 [==============================] - 1s 151us/step - loss: 0.4443 - acc: 0.8194\n",
      "Epoch 14/25\n",
      "3840/3840 [==============================] - 1s 177us/step - loss: 0.4330 - acc: 0.8224\n",
      "Epoch 15/25\n",
      "3840/3840 [==============================] - 1s 151us/step - loss: 0.4254 - acc: 0.8242\n",
      "Epoch 16/25\n",
      "3840/3840 [==============================] - 1s 151us/step - loss: 0.4160 - acc: 0.8244\n",
      "Epoch 17/25\n",
      "3840/3840 [==============================] - 1s 168us/step - loss: 0.4096 - acc: 0.8226\n",
      "Epoch 18/25\n",
      "3840/3840 [==============================] - 1s 156us/step - loss: 0.4040 - acc: 0.8165\n",
      "Epoch 19/25\n",
      "3840/3840 [==============================] - 1s 151us/step - loss: 0.3966 - acc: 0.8210\n",
      "Epoch 20/25\n",
      "3840/3840 [==============================] - 1s 152us/step - loss: 0.3815 - acc: 0.8185\n",
      "Epoch 21/25\n",
      "3840/3840 [==============================] - 1s 180us/step - loss: 0.3757 - acc: 0.8201\n",
      "Epoch 22/25\n",
      "3840/3840 [==============================] - 1s 151us/step - loss: 0.3960 - acc: 0.8179\n",
      "Epoch 23/25\n",
      "3840/3840 [==============================] - 1s 152us/step - loss: 0.3793 - acc: 0.8225\n",
      "Epoch 24/25\n",
      "3840/3840 [==============================] - 1s 180us/step - loss: 0.3603 - acc: 0.8286\n",
      "Epoch 25/25\n",
      "3840/3840 [==============================] - 1s 158us/step - loss: 0.3547 - acc: 0.8321\n",
      "960/960 [==============================] - 0s 202us/step\n",
      "960/960 [==============================] - 0s 21us/step\n",
      "BMAC Ensemble Scores:  0.6791680288948049\n",
      "BMAC SVM Scores:  0.6814239473754099\n",
      "BMAC NN Scores:  0.6579552749594537\n",
      "Fitting SVM...\n",
      "Fitting NN...\n",
      "Epoch 1/25\n",
      "3840/3840 [==============================] - 2s 514us/step - loss: 0.6991 - acc: 0.6164\n",
      "Epoch 2/25\n",
      "3840/3840 [==============================] - 1s 168us/step - loss: 0.5681 - acc: 0.7482\n",
      "Epoch 3/25\n",
      "3840/3840 [==============================] - 1s 156us/step - loss: 0.5421 - acc: 0.7648\n",
      "Epoch 4/25\n",
      "3840/3840 [==============================] - 1s 157us/step - loss: 0.5219 - acc: 0.7731\n",
      "Epoch 5/25\n",
      "3840/3840 [==============================] - 1s 183us/step - loss: 0.5047 - acc: 0.7860\n",
      "Epoch 6/25\n",
      "3840/3840 [==============================] - 1s 159us/step - loss: 0.4811 - acc: 0.7931\n",
      "Epoch 7/25\n",
      "3840/3840 [==============================] - 1s 157us/step - loss: 0.4765 - acc: 0.7930\n",
      "Epoch 8/25\n",
      "3840/3840 [==============================] - 1s 180us/step - loss: 0.4627 - acc: 0.7939\n",
      "Epoch 9/25\n",
      "3840/3840 [==============================] - 1s 158us/step - loss: 0.4519 - acc: 0.7998\n",
      "Epoch 10/25\n",
      "3840/3840 [==============================] - 1s 159us/step - loss: 0.4520 - acc: 0.7891\n",
      "Epoch 11/25\n",
      "3840/3840 [==============================] - 1s 188us/step - loss: 0.4491 - acc: 0.7893\n",
      "Epoch 12/25\n",
      "3840/3840 [==============================] - 1s 158us/step - loss: 0.4347 - acc: 0.7956\n",
      "Epoch 13/25\n",
      "3840/3840 [==============================] - 1s 159us/step - loss: 0.4347 - acc: 0.7899\n",
      "Epoch 14/25\n",
      "3840/3840 [==============================] - 1s 158us/step - loss: 0.4211 - acc: 0.7888\n",
      "Epoch 15/25\n",
      "3840/3840 [==============================] - 1s 184us/step - loss: 0.4089 - acc: 0.7960\n",
      "Epoch 16/25\n",
      "3840/3840 [==============================] - 1s 161us/step - loss: 0.4014 - acc: 0.7984\n",
      "Epoch 17/25\n",
      "3840/3840 [==============================] - 1s 159us/step - loss: 0.4017 - acc: 0.7937\n",
      "Epoch 18/25\n",
      "3840/3840 [==============================] - 1s 183us/step - loss: 0.3952 - acc: 0.7987\n",
      "Epoch 19/25\n",
      "3840/3840 [==============================] - 1s 159us/step - loss: 0.3939 - acc: 0.8051\n",
      "Epoch 20/25\n",
      "3840/3840 [==============================] - 1s 158us/step - loss: 0.3919 - acc: 0.8036\n",
      "Epoch 21/25\n",
      "3840/3840 [==============================] - 1s 182us/step - loss: 0.3878 - acc: 0.8080\n",
      "Epoch 22/25\n",
      "3840/3840 [==============================] - 1s 159us/step - loss: 0.3845 - acc: 0.8111\n",
      "Epoch 23/25\n",
      "3840/3840 [==============================] - 1s 160us/step - loss: 0.3819 - acc: 0.8153\n",
      "Epoch 24/25\n",
      "3840/3840 [==============================] - 1s 183us/step - loss: 0.3767 - acc: 0.8169\n",
      "Epoch 25/25\n",
      "3840/3840 [==============================] - 1s 166us/step - loss: 0.3589 - acc: 0.8215\n",
      "960/960 [==============================] - 0s 221us/step\n",
      "960/960 [==============================] - 0s 21us/step\n",
      "BMAC Ensemble Scores:  0.6582398956733962\n",
      "BMAC SVM Scores:  0.6749282463803977\n",
      "BMAC NN Scores:  0.6777816374179958\n",
      "Fitting SVM...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NN...\n",
      "Epoch 1/25\n",
      "3840/3840 [==============================] - 2s 505us/step - loss: 0.6548 - acc: 0.6669\n",
      "Epoch 2/25\n",
      "3840/3840 [==============================] - 1s 152us/step - loss: 0.5888 - acc: 0.7529\n",
      "Epoch 3/25\n",
      "3840/3840 [==============================] - 1s 178us/step - loss: 0.5468 - acc: 0.7691\n",
      "Epoch 4/25\n",
      "3840/3840 [==============================] - 1s 152us/step - loss: 0.5298 - acc: 0.7640\n",
      "Epoch 5/25\n",
      "3840/3840 [==============================] - 1s 166us/step - loss: 0.5151 - acc: 0.7653\n",
      "Epoch 6/25\n",
      "3840/3840 [==============================] - 1s 184us/step - loss: 0.4970 - acc: 0.7716\n",
      "Epoch 7/25\n",
      "3840/3840 [==============================] - 314s 82ms/step - loss: 0.4793 - acc: 0.7801\n",
      "Epoch 8/25\n",
      "3840/3840 [==============================] - 1s 216us/step - loss: 0.4755 - acc: 0.7824\n",
      "Epoch 9/25\n",
      "3840/3840 [==============================] - 1s 331us/step - loss: 0.4584 - acc: 0.7876\n",
      "Epoch 10/25\n",
      "3840/3840 [==============================] - 1s 194us/step - loss: 0.4533 - acc: 0.7922\n",
      "Epoch 11/25\n",
      "3840/3840 [==============================] - 2s 517us/step - loss: 0.4451 - acc: 0.7958\n",
      "Epoch 12/25\n",
      "3840/3840 [==============================] - 1s 202us/step - loss: 0.4355 - acc: 0.7988\n",
      "Epoch 13/25\n",
      "3840/3840 [==============================] - 1s 218us/step - loss: 0.4280 - acc: 0.8058\n",
      "Epoch 14/25\n",
      "3840/3840 [==============================] - 1s 180us/step - loss: 0.4237 - acc: 0.8028\n",
      "Epoch 15/25\n",
      "3840/3840 [==============================] - 1s 175us/step - loss: 0.4161 - acc: 0.8036\n",
      "Epoch 16/25\n",
      "3840/3840 [==============================] - 1s 212us/step - loss: 0.4233 - acc: 0.8023\n",
      "Epoch 17/25\n",
      "3840/3840 [==============================] - 2s 435us/step - loss: 0.4106 - acc: 0.8016\n",
      "Epoch 18/25\n",
      "3840/3840 [==============================] - 1s 172us/step - loss: 0.3885 - acc: 0.8083\n",
      "Epoch 19/25\n",
      "3840/3840 [==============================] - 1s 159us/step - loss: 0.3930 - acc: 0.8060\n",
      "Epoch 20/25\n",
      "3840/3840 [==============================] - 1s 191us/step - loss: 0.3816 - acc: 0.8155\n",
      "Epoch 21/25\n",
      "3840/3840 [==============================] - 1s 163us/step - loss: 0.3783 - acc: 0.8143\n",
      "Epoch 22/25\n",
      "3840/3840 [==============================] - 1s 181us/step - loss: 0.3781 - acc: 0.8203\n",
      "Epoch 23/25\n",
      "3840/3840 [==============================] - 1s 273us/step - loss: 0.3712 - acc: 0.8218\n",
      "Epoch 24/25\n",
      "3840/3840 [==============================] - 1s 181us/step - loss: 0.3670 - acc: 0.8268\n",
      "Epoch 25/25\n",
      "3840/3840 [==============================] - 1s 180us/step - loss: 0.3795 - acc: 0.8213\n",
      "960/960 [==============================] - 0s 278us/step\n",
      "960/960 [==============================] - 0s 40us/step\n",
      "BMAC Ensemble Scores:  0.6783089108939849\n",
      "BMAC SVM Scores:  0.7040392382236463\n",
      "BMAC NN Scores:  0.693546491350574\n",
      "Fitting SVM...\n",
      "Fitting NN...\n",
      "Epoch 1/25\n",
      "3840/3840 [==============================] - 2s 567us/step - loss: 0.6295 - acc: 0.7277\n",
      "Epoch 2/25\n",
      "3840/3840 [==============================] - 1s 207us/step - loss: 0.5721 - acc: 0.7565\n",
      "Epoch 3/25\n",
      "3840/3840 [==============================] - 1s 185us/step - loss: 0.5452 - acc: 0.7760\n",
      "Epoch 4/25\n",
      "3840/3840 [==============================] - 1s 187us/step - loss: 0.5319 - acc: 0.7847\n",
      "Epoch 5/25\n",
      "3840/3840 [==============================] - 1s 226us/step - loss: 0.5016 - acc: 0.7897\n",
      "Epoch 6/25\n",
      "3840/3840 [==============================] - 1s 189us/step - loss: 0.4934 - acc: 0.7903\n",
      "Epoch 7/25\n",
      "3840/3840 [==============================] - 1s 186us/step - loss: 0.4936 - acc: 0.7951\n",
      "Epoch 8/25\n",
      "3840/3840 [==============================] - 1s 226us/step - loss: 0.4851 - acc: 0.7953\n",
      "Epoch 9/25\n",
      "3840/3840 [==============================] - 1s 190us/step - loss: 0.4714 - acc: 0.7933\n",
      "Epoch 10/25\n",
      "3840/3840 [==============================] - 1s 220us/step - loss: 0.4662 - acc: 0.8001\n",
      "Epoch 11/25\n",
      "3840/3840 [==============================] - 1s 193us/step - loss: 0.4622 - acc: 0.7980\n",
      "Epoch 12/25\n",
      "3840/3840 [==============================] - 1s 208us/step - loss: 0.4512 - acc: 0.8081\n",
      "Epoch 13/25\n",
      "3840/3840 [==============================] - 1s 240us/step - loss: 0.4312 - acc: 0.8128\n",
      "Epoch 14/25\n",
      "3840/3840 [==============================] - 1s 201us/step - loss: 0.4375 - acc: 0.8041\n",
      "Epoch 15/25\n",
      "3840/3840 [==============================] - 1s 219us/step - loss: 0.4295 - acc: 0.8090\n",
      "Epoch 16/25\n",
      "3840/3840 [==============================] - 1s 207us/step - loss: 0.4167 - acc: 0.8186\n",
      "Epoch 17/25\n",
      "3840/3840 [==============================] - 1s 199us/step - loss: 0.4124 - acc: 0.8164\n",
      "Epoch 18/25\n",
      "3840/3840 [==============================] - 1s 220us/step - loss: 0.3998 - acc: 0.8240\n",
      "Epoch 19/25\n",
      "3840/3840 [==============================] - 1s 193us/step - loss: 0.3933 - acc: 0.8250\n",
      "Epoch 20/25\n",
      "3840/3840 [==============================] - 1s 204us/step - loss: 0.3952 - acc: 0.8198\n",
      "Epoch 21/25\n",
      "3840/3840 [==============================] - 1s 239us/step - loss: 0.3979 - acc: 0.8196\n",
      "Epoch 22/25\n",
      "3840/3840 [==============================] - 1s 194us/step - loss: 0.3882 - acc: 0.8241\n",
      "Epoch 23/25\n",
      "3840/3840 [==============================] - 1s 227us/step - loss: 0.3830 - acc: 0.8313\n",
      "Epoch 24/25\n",
      "3840/3840 [==============================] - 1s 201us/step - loss: 0.3753 - acc: 0.8257\n",
      "Epoch 25/25\n",
      "3840/3840 [==============================] - 1s 199us/step - loss: 0.3632 - acc: 0.8385\n",
      "960/960 [==============================] - 0s 298us/step\n",
      "960/960 [==============================] - 0s 35us/step\n",
      "BMAC Ensemble Scores:  0.6690707946592213\n",
      "BMAC SVM Scores:  0.6846335367805764\n",
      "BMAC NN Scores:  0.6623304277251998\n",
      "Scores: [0.69069871 0.67916803 0.6582399  0.67830891 0.66907079]\n",
      "SVM Scores: [0.72803874 0.68142395 0.67492825 0.70403924 0.68463354]\n",
      "NN Scores: [0.72573872 0.65795527 0.67778164 0.69354649 0.66233043]\n",
      "Mean Scores: [0.67509727]\n",
      "Std Scores: [0.01086996]\n"
     ]
    }
   ],
   "source": [
    "# Big cross val for loop\n",
    "\n",
    "# Try a nn Estimator with SMOTE\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle = True)\n",
    "\n",
    "BMAC_means = np.array([])\n",
    "BMAC_stds = np.array([])\n",
    "BMAC_scores = np.array([])\n",
    "svm_scores = np.array([])\n",
    "nn_scores = np.array([])\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "\n",
    "    # Prepare the data\n",
    "    x_train = xtrain[train_index]\n",
    "    x_test = xtrain[test_index]\n",
    "    y_train = ytrain[train_index]\n",
    "    y_test = ytrain[test_index]\n",
    "\n",
    "    # Prepare the SVM\n",
    "    andreas_svm = svm.SVC(C=0.5, class_weight='balanced', degree=1, gamma='auto', kernel='rbf', probability=True)\n",
    "    steps = [(\"scaler\", preprocessing.StandardScaler()), (\"classifier\", andreas_svm)]\n",
    "    svm_pipeline = Pipeline(steps = steps)\n",
    "    \n",
    "    # Prepare the NN1\n",
    "    nn = NN1()\n",
    "    \n",
    "    # Models to fit\n",
    "    print(\"Fitting SVM...\")\n",
    "    svm_pipeline.fit(x_train, y_train.ravel())\n",
    "    print(\"Fitting NN...\")\n",
    "    nn.fit(x_train, y_train.ravel())\n",
    "    \n",
    "    # Predict and join the predictions\n",
    "    svm_pred = svm_pipeline.predict(x_test)\n",
    "    nn_pred = nn.predict(x_test)\n",
    "    svm_prob = svm_pipeline.predict_proba(x_test)\n",
    "    nn_prob = nn.predict_proba(x_test)\n",
    "    ensemble_pred = ensemby(svm_prob, nn_prob)\n",
    "    \n",
    "    # Record scores\n",
    "    BMAC_ensemble = balanced_accuracy_score(y_test, ensemble_pred)\n",
    "    BMAC_svm = balanced_accuracy_score(y_test, svm_pred)\n",
    "    BMAC_nn = balanced_accuracy_score(y_test, nn_pred)\n",
    "    print(\"BMAC Ensemble Scores: \", BMAC_ensemble)\n",
    "    print(\"BMAC SVM Scores: \", BMAC_svm)\n",
    "    print(\"BMAC NN Scores: \", BMAC_nn)\n",
    "    BMAC_scores = np.append(BMAC_scores, BMAC_ensemble)\n",
    "    svm_scores = np.append(svm_scores, BMAC_svm)\n",
    "    nn_scores = np.append(nn_scores, BMAC_nn)\n",
    "    \n",
    "BMAC_means = np.append(BMAC_means, np.mean(BMAC_scores))\n",
    "BMAC_stds = np.append(BMAC_stds, np.std(BMAC_scores))\n",
    "\n",
    "print(\"Scores:\", BMAC_scores)\n",
    "print(\"SVM Scores:\", svm_scores)\n",
    "print(\"NN Scores:\", nn_scores)\n",
    "print(\"Mean Scores:\", BMAC_means)\n",
    "print(\"Std Scores:\", BMAC_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
