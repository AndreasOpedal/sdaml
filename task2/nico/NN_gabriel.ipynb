{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all necessary preprocessing, calling prepro.py\n",
    "import utils\n",
    "from utils import *\n",
    "importlib.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, X_test_original, y = load_data() \n",
    "y = y.ravel()\n",
    "scores = np.array([])\n",
    "xtrain = X  # For andreas cross validation\n",
    "ytrain = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN1():\n",
    "    def __init__(self):\n",
    "        self.mlp = KerasClassifier(build_fn=self.create_model, \n",
    "                                   epochs=25, batch_size=35, \n",
    "                                   verbose=1)\n",
    "        return\n",
    "    \n",
    "    def score(self, X_, y_):\n",
    "        pred = self.predict(X_)\n",
    "        if y_.shape[1] < 2:\n",
    "            y_normal = y_\n",
    "        else:\n",
    "            y_normal = np.argmax(y_, axis=1)\n",
    "        BMAC = balanced_accuracy_score(y_normal, pred)\n",
    "        return BMAC\n",
    "    \n",
    "    def fit(self, X_, y_):\n",
    "        # One hot encode data\n",
    "        y_enc = np.zeros((y_.shape[0], 3))\n",
    "        y_enc[np.arange(y_.shape[0]), y_] = 1\n",
    "        \n",
    "        xscaled = preprocessing.StandardScaler().fit_transform(X_)\n",
    "        cw = sklearn.utils.class_weight.compute_class_weight('balanced', np.unique(y_), y_)\n",
    "        class_weight = {0: cw[0], 1: cw[1], 2: cw[2]}\n",
    "        self.mlp.fit(xscaled, y_enc, class_weight=class_weight)\n",
    "        return\n",
    "    \n",
    "    def predict(self, X_):\n",
    "        return self.mlp.predict(preprocessing.StandardScaler().fit_transform(X_))\n",
    "    \n",
    "    def create_model(self):\n",
    "        # create model\n",
    "        neurons = 30\n",
    "        dropout_rate = 0.7\n",
    "        weight_constraint = 4\n",
    "        model = Sequential()\n",
    "        model.add(Dense(neurons, input_dim=1000, activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(neurons, activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
    "        model.add(Dropout(dropout_rate*0.4))\n",
    "        model.add(Dense(int(neurons/2), activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
    "        model.add(Dropout(dropout_rate*0.2))\n",
    "        model.add(Dense(3, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def predict_proba(self, X_):\n",
    "        return self.mlp.predict_proba(preprocessing.StandardScaler().fit_transform(X_))\n",
    "\n",
    "# nn = NN1()\n",
    "# nn.fit(X[1:10], y[1:10])\n",
    "# ypredy = nn.predict(X[1:10])\n",
    "# probbb = nn.predict_proba(X[1:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble dei modelliiiii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ensemble voting classifier fn:\n",
    "\n",
    "def ensemby(y1_prob, y2_prob, voting='soft'):\n",
    "    # Return the argmax of the sum of the probabilities\n",
    "    return np.argmax(y1_prob + y2_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big cross val for loop\n",
    "\n",
    "# Try a nn Estimator with SMOTE\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle = True)\n",
    "\n",
    "BMAC_means = np.array([])\n",
    "BMAC_stds = np.array([])\n",
    "BMAC_scores = np.array([])\n",
    "svm_scores = np.array([])\n",
    "nn_scores = np.array([])\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "\n",
    "    # Prepare the data\n",
    "    x_train = xtrain[train_index]\n",
    "    x_test = xtrain[test_index]\n",
    "    y_train = ytrain[train_index]\n",
    "    y_test = ytrain[test_index]\n",
    "\n",
    "    # Prepare the SVM\n",
    "    andreas_svm = svm.SVC(C=0.5, class_weight='balanced', degree=1, gamma='auto', kernel='rbf', probability=True)\n",
    "    steps = [(\"scaler\", preprocessing.StandardScaler()), (\"classifier\", andreas_svm)]\n",
    "    svm_pipeline = Pipeline(steps = steps)\n",
    "    \n",
    "    # Prepare the NN1\n",
    "    nn = NN1()\n",
    "    \n",
    "    # Models to fit\n",
    "    print(\"Fitting SVM...\")\n",
    "    svm_pipeline.fit(x_train, y_train.ravel())\n",
    "    print(\"Fitting NN...\")\n",
    "    nn.fit(x_train, y_train.ravel())\n",
    "    \n",
    "    # Predict and join the predictions\n",
    "    svm_pred = svm_pipeline.predict(x_test)\n",
    "    nn_pred = nn.predict(x_test)\n",
    "    svm_prob = svm_pipeline.predict_proba(x_test)\n",
    "    nn_prob = nn.predict_proba(x_test)\n",
    "    ensemble_pred = ensemby(svm_prob, nn_prob)\n",
    "    \n",
    "    # Record scores\n",
    "    BMAC_ensemble = balanced_accuracy_score(y_test, ensemble_pred)\n",
    "    BMAC_svm = balanced_accuracy_score(y_test, svm_pred)\n",
    "    BMAC_nn = balanced_accuracy_score(y_test, nn_pred)\n",
    "    print(\"BMAC Ensemble Scores: \", BMAC_ensemble)\n",
    "    print(\"BMAC SVM Scores: \", BMAC_svm)\n",
    "    print(\"BMAC NN Scores: \", BMAC_nn)\n",
    "    BMAC_scores = np.append(BMAC_scores, BMAC_ensemble)\n",
    "    svm_scores = np.append(svm_scores, BMAC_svm)\n",
    "    nn_scores = np.append(nn_scores, BMAC_nn)\n",
    "    \n",
    "BMAC_means = np.append(BMAC_means, np.mean(BMAC_scores))\n",
    "BMAC_stds = np.append(BMAC_stds, np.std(BMAC_scores))\n",
    "\n",
    "print(\"Scores:\", BMAC_scores)\n",
    "print(\"SVM Scores:\", svm_scores)\n",
    "print(\"NN Scores:\", nn_scores)\n",
    "print(\"Mean Scores:\", BMAC_means)\n",
    "print(\"Std Scores:\", BMAC_stds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
