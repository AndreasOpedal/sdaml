{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of inliers: (4320,)\n",
      "Inliers shapes: (4320, 300) (4320, 300)\n"
     ]
    }
   ],
   "source": [
    "## mutual information\n",
    "## zero varinace columns  \n",
    "## outlier detection (isolation forest)\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import IsolationForest \n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4320, 300)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap pipeline with bagging classifier\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle = True)\n",
    "\n",
    "c_values = np.array([0.8])\n",
    "bandwidth = np.array([0.001])\n",
    "BMAC_means_test = np.array([])\n",
    "BMAC_stds_test = np.array([])\n",
    "BMAC_means_train = np.array([])\n",
    "BMAC_stds_train = np.array([])\n",
    "\n",
    "\n",
    "for g in bandwidth:\n",
    "    for c in c_values:\n",
    "        BMAC_scores_test = np.array([])\n",
    "        BMAC_scores_train = np.array([])\n",
    "        for train_index, test_index in kf.split(xtrain.values):\n",
    "\n",
    "            \n",
    "            x_train = pd.read_csv(\"X_train.csv\")\n",
    "            x_train = x_train.iloc[:, 1:]\n",
    "            x_test = pd.read_csv(\"X_test.csv\")\n",
    "            x_test = x_test.iloc[:, 1:]\n",
    "            y_train = pd.read_csv(\"Y_train.csv\")\n",
    "\n",
    "            # Remove id from ytrain\n",
    "            y_train = y_train.drop('id', axis = 1)\n",
    "\n",
    "            #low variance \n",
    "            var = VarianceThreshold(threshold=0.3)\n",
    "            var.fit(x_train)\n",
    "            x_train = var.transform(x_train)\n",
    "            x_test = var.transform(x_test)\n",
    "\n",
    "            #standardise\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            x_train = scaler.fit_transform(x_train)\n",
    "            x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "            #mutual information\n",
    "            sel_mutual = SelectKBest(mutual_info_classif, k = 300)\n",
    "            sel_mutual.fit(x_train, y_train)\n",
    "            x_train = sel_mutual.transform(x_train)\n",
    "            x_test = sel_mutual.transform(x_test)\n",
    "\n",
    "            #outlier detection \n",
    "            clf = IsolationForest(n_estimators=200)\n",
    "            clf.fit(x_train)\n",
    "            clf.decision_function(x_train)\n",
    "            inlier_indices = np.where(clf.predict(x_train) == 1)[0]\n",
    "            print(\"Size of inliers:\", inlier_indices.shape)\n",
    "            x_train = pd.DataFrame(x_train).iloc[inlier_indices]\n",
    "            y_train = pd.DataFrame(y_train).iloc[inlier_indices]\n",
    "            print(\"Inliers shapes:\", x_train.shape, x_train.shape)\n",
    "            \n",
    "            x_train = x_train.loc[train_index, :]\n",
    "            x_test = x_train.loc[test_index, :]\n",
    "\n",
    "            y_train = y_train.loc[train_index, :]\n",
    "            y_test = y_train.loc[test_index, :]\n",
    "\n",
    "            # Handle class imbalance with smote function\n",
    "            sm = SMOTE(random_state=42)\n",
    "            x_train, y_train = sm.fit_resample(x_train.values, y_train.values) #x_train and y_train are now arrays\n",
    "\n",
    "        \n",
    "            # Model to fit\n",
    "            estimator = SVC(C=c, gamma = g)\n",
    "            #estimator = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=40)\n",
    "            '''\n",
    "            bagging = BaggingClassifier(base_estimator = estimator,\n",
    "                                       n_estimators = 20)\n",
    "            bagging.fit(x_train, y_train)\n",
    "            bagging_prediction = bagging.predict(x_test)\n",
    "            BMAC = balanced_accuracy_score(y_test, bagging_prediction)\n",
    "            '''\n",
    "            estimator.fit(x_train, y_train.ravel())\n",
    "            pred = estimator.predict(x_test)\n",
    "            BMAC_test = balanced_accuracy_score(y_test, pred)\n",
    "            BMAC_scores_test = np.append(BMAC_scores_test, BMAC_test)\n",
    "\n",
    "            pred = estimator.predict(x_train)\n",
    "            BMAC_train = balanced_accuracy_score(y_train, pred)\n",
    "            BMAC_scores_train = np.append(BMAC_scores_train, BMAC_train)\n",
    "\n",
    "        print('mean for current c=', c,'and g=', g, 'is, test:', np.mean(BMAC_scores_test), 'train:',  np.mean(BMAC_scores_train))\n",
    "    \n",
    "    \n",
    "        BMAC_means_test = np.append(BMAC_means_test, np.mean(BMAC_scores_test))\n",
    "        BMAC_stds_test = np.append(BMAC_stds_test, np.std(BMAC_scores_test))\n",
    "        BMAC_means_train = np.append(BMAC_means_train, np.mean(BMAC_scores_train))\n",
    "        BMAC_stds_train = np.append(BMAC_stds_train, np.std(BMAC_scores_train))\n",
    "    \n",
    "\n",
    "print(BMAC_means_test)\n",
    "print(BMAC_stds_test)\n",
    "print(BMAC_means_train)\n",
    "print(BMAC_stds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ba217f731618>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mproduce_solution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-ba217f731618>\u001b[0m in \u001b[0;36mproduce_solution\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mproduce_solution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'out.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlineterminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "      \n",
    "xtrain = pd.read_csv(\"X_train.csv\")\n",
    "xtrain = xtrain.iloc[:, 1:]\n",
    "xtest = pd.read_csv(\"X_test.csv\")\n",
    "xtest = xtest.iloc[:, 1:]\n",
    "ytrain = pd.read_csv(\"Y_train.csv\")\n",
    "\n",
    "# Remove id from ytrain\n",
    "ytrain = ytrain.drop('id', axis = 1)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "xtrain, ytrain = sm.fit_resample(xtrain.values, ytrain.values) #x_train and y_train are now arrays\n",
    "\n",
    "# Scale the data (should this be done for each bootstrap sample? in that case how)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "#x_train = pd.DataFrame(xtrain_scaled, columns = x_train.columns)\n",
    "xtest = scaler.fit_transform(xtest)\n",
    "#x_test = pd.DataFrame(xtest_scaled, columns = x_test.columns)\n",
    "\n",
    "    \n",
    "    \n",
    "model = SVC(C=0.8, gamma = 0.001)\n",
    "model.fit(xtrain, ytrain)\n",
    "pred = model.predict(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.read_csv(\"sample.csv\")\n",
    "index['y'] = pred\n",
    "\n",
    "index.to_csv(\"svm_tuned_for_loops.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
