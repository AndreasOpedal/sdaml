{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import csv \n",
    "import seaborn as sb\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "\n",
    "'''\n",
    "LSTM\n",
    "'''\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import f1_score\n",
    "from keras import backend as K\n",
    "\n",
    "'''\n",
    "CNN\n",
    "'''\n",
    "from keras.layers import Conv1D, Dense, Dropout, Input, Concatenate, GlobalMaxPooling1D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X_train = pd.read_csv(\"X_train.csv\")\n",
    "    X_test = pd.read_csv(\"X_test.csv\")\n",
    "    y_train = pd.read_csv(\"y_train.csv\")\n",
    "\n",
    "    #dropping id column\n",
    "    X_train = X_train.drop('id', axis = 1)\n",
    "    X_test = X_test.drop('id', axis = 1)\n",
    "    y_train = y_train.drop('id', axis = 1)\n",
    "    \n",
    "    #reshuffling data\n",
    "    X_train['y'] = y_train\n",
    "    X_train = X_train.sample(frac=1).reset_index(drop=True)\n",
    "    y_train = X_train['y']\n",
    "    X_train = X_train.drop('y', axis = 1)\n",
    "    \n",
    "    return X_train, X_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "for each row in xtrain, find indices of last non NaN values\n",
    "'''\n",
    "#renaming columns into 0,1,2,...\n",
    "xtrain = xtrain.rename(columns={x:y for x,y in zip(xtrain.columns,range(0,len(xtrain.columns)))})\n",
    "\n",
    "'''\n",
    "last_valid_idx contains the column index for last non-NaN value in the rows of xtrain\n",
    "'''\n",
    "last_valid_idx = []\n",
    "\n",
    "for i in range(0,xtrain.shape[0]):\n",
    "    row = xtrain.iloc[i,:]\n",
    "    idx = row.last_valid_index()\n",
    "    last_valid_idx = np.append(last_valid_idx, idx)\n",
    "    \n",
    "'''\n",
    "plotting kernel density of last_valid_idx\n",
    "'''\n",
    "ax = sb.kdeplot(last_valid_idx, shade=True, color=\"r\")\n",
    "\n",
    "'''\n",
    "from the kernel density plot, we notice that the majority of series \n",
    "starts to show NaN's after the ~8500 index point. We will then first \n",
    "attempt classification by truncating all the series at the 7500\n",
    "column. We will then pad the series which present NaNs before the 7500\n",
    "columns with the median of the other series. This is just a first trial.\n",
    "'''\n",
    "\n",
    "'''\n",
    "truncate xtrain at 7500 columns -- this prevents us from wasting too much data in truncating\n",
    "'''\n",
    "#note to self: load_data() reshiffles the data\n",
    "xtrain_tr = xtrain.iloc[:,0:7500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfrom now on, we operate on xtrain_tr_filled -- shape (5117, 7500)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pad shorter series\n",
    "'''\n",
    "\n",
    "#consider all rows of xtrain_tr with no NaN's\n",
    "#Note: we only need to drop all rows with NaN at the last column entry \n",
    "\n",
    "#entry i is True if entry is last column in row i of xtrain_tr is NaN \n",
    "is_nan = np.isnan(xtrain_tr.iloc[:,-1].values) \n",
    "xtrain_tr1 = xtrain_tr[is_nan == False]  #shape = (4565, 7500)\n",
    "xtrain_tr2 = xtrain_tr[is_nan == True]\n",
    "\n",
    "#calculate column medians \n",
    "medians = np.array(xtrain_tr1.median(axis=0))\n",
    "\n",
    "for j in xtrain_tr2.columns:\n",
    "    xtrain_tr2.iloc[:,j] = xtrain_tr2.iloc[:,j].fillna(value = medians[j], axis = 0)\n",
    "#   print(j)\n",
    "\n",
    "xtrain_tr_filled = pd.concat([xtrain_tr1, xtrain_tr2])\n",
    "\n",
    "'''\n",
    "final dataset: xtrain_tr_filled\n",
    "dimension: (5117, 7500)\n",
    "shorter series padded\n",
    "'''\n",
    "\n",
    "print(xtrain_tr_filled.isnull().values.any())\n",
    "\n",
    "'''\n",
    "from now on, we operate on xtrain_tr_filled -- shape (5117, 7500)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models - (andiamooo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "AVOID THIS BOI FOR NOW --- SEE CODE BELOW\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "create train, validation, test splits\n",
    "xtrain_nn, xval_nn, xtest_nn\n",
    "\n",
    "\n",
    "xtrain_provisional_nn, xtest_nn, ytrain_provisional_nn, ytest_nn = train_test_split(xtrain_tr_filled, \n",
    "                                                          ytrain, test_size=0.1, random_state=42)\n",
    "\n",
    "xtrain_nn, xval_nn, ytrain_nn, yval_nn = train_test_split(xtrain_provisional_nn,   # test set = val set \n",
    "                                                          ytrain_provisional_nn, test_size=0.3, random_state=42)\n",
    "\n",
    "xtrain_nn = xtrain_nn.values.reshape((xtrain_nn.shape[0], xtrain_nn.shape[1], 1))\n",
    "xval_nn = xval_nn.values.reshape((xval_nn.shape[0], xval_nn.shape[1], 1))\n",
    "xtest_nn = xtest_nn.values.reshape((xtest_nn.shape[0], xtest_nn.shape[1], 1))\n",
    "\n",
    "'''\n",
    "'''\n",
    "use now: xtrain_nn, xval_nn, xtest_nn\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dataset reduced to 101 rows to see whether nn's train correctly\n",
    "\n",
    "### code above is the original one ###\n",
    "'''\n",
    "\n",
    "xtrain_tr_filled_trial = xtrain_tr_filled.iloc[0:100, ]\n",
    "ytrain = ytrain.iloc[0:100,]\n",
    "\n",
    "xtrain_provisional_nn, xtest_nn, ytrain_provisional_nn, ytest_nn = train_test_split(xtrain_tr_filled_trial, \n",
    "                                                          ytrain, test_size=0.1, random_state=42)\n",
    "\n",
    "xtrain_nn, xval_nn, ytrain_nn, yval_nn = train_test_split(xtrain_provisional_nn,   # test set = val set \n",
    "                                                          ytrain_provisional_nn, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "xtrain_nn = xtrain_nn.values.reshape((xtrain_nn.shape[0], xtrain_nn.shape[1], 1))\n",
    "xval_nn = xval_nn.values.reshape((xval_nn.shape[0], xval_nn.shape[1], 1))\n",
    "xtest_nn = xtest_nn.values.reshape((xtest_nn.shape[0], xtest_nn.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for Time Series\n",
    "\n",
    "based on: https://www.analyticsvidhya.com/blog/2019/01/introduction-time-series-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape = (xtrain_nn.shape[1],1)))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 64)                16896     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 16,961\n",
      "Trainable params: 16,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63 samples, validate on 27 samples\n",
      "Epoch 1/200\n",
      "63/63 [==============================] - 36s 577ms/step - loss: 0.8344 - accuracy: 0.3651 - val_loss: 0.6952 - val_accuracy: 0.0741\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 34s 536ms/step - loss: 0.8521 - accuracy: 0.1746 - val_loss: 0.7522 - val_accuracy: 0.0741\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 33s 529ms/step - loss: 0.6157 - accuracy: 0.1905 - val_loss: 1.0138 - val_accuracy: 0.0741\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 35s 552ms/step - loss: 0.3052 - accuracy: 0.3016 - val_loss: 0.8695 - val_accuracy: 0.1852\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 36s 570ms/step - loss: 0.3320 - accuracy: 0.3175 - val_loss: 0.8867 - val_accuracy: 0.1852\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 36s 572ms/step - loss: 0.2311 - accuracy: 0.3016 - val_loss: 1.0850 - val_accuracy: 0.2593\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 40s 634ms/step - loss: 0.1898 - accuracy: 0.4127 - val_loss: 0.7630 - val_accuracy: 0.1481\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 37s 582ms/step - loss: 0.0938 - accuracy: 0.2698 - val_loss: 1.0729 - val_accuracy: 0.1852\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 34s 542ms/step - loss: -0.0848 - accuracy: 0.3968 - val_loss: 1.3449 - val_accuracy: 0.4074\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 37s 591ms/step - loss: 0.0373 - accuracy: 0.4921 - val_loss: 0.7771 - val_accuracy: 0.2222\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 39s 612ms/step - loss: -0.0407 - accuracy: 0.3016 - val_loss: 0.9322 - val_accuracy: 0.1481\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 34s 538ms/step - loss: -0.1933 - accuracy: 0.2857 - val_loss: 1.4749 - val_accuracy: 0.1852\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 34s 536ms/step - loss: -0.4596 - accuracy: 0.3968 - val_loss: 1.9308 - val_accuracy: 0.3333\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 35s 551ms/step - loss: -0.3130 - accuracy: 0.4603 - val_loss: 1.3404 - val_accuracy: 0.1111\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 34s 540ms/step - loss: -0.5099 - accuracy: 0.4762 - val_loss: 0.9626 - val_accuracy: 0.4074\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 34s 545ms/step - loss: -0.7456 - accuracy: 0.5556 - val_loss: 1.2586 - val_accuracy: 0.2593\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 35s 551ms/step - loss: -0.7202 - accuracy: 0.3175 - val_loss: 1.1678 - val_accuracy: 0.1481\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 35s 554ms/step - loss: -1.1370 - accuracy: 0.3651 - val_loss: 1.2465 - val_accuracy: 0.1481\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 34s 542ms/step - loss: -0.9551 - accuracy: 0.3810 - val_loss: 2.1330 - val_accuracy: 0.1852\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 35s 555ms/step - loss: -1.3832 - accuracy: 0.4127 - val_loss: 1.9800 - val_accuracy: 0.2222\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 33s 525ms/step - loss: -1.5797 - accuracy: 0.4286 - val_loss: 2.2461 - val_accuracy: 0.3333\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 34s 537ms/step - loss: -0.9206 - accuracy: 0.4603 - val_loss: 3.4542 - val_accuracy: 0.3333\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 35s 552ms/step - loss: -1.3881 - accuracy: 0.4127 - val_loss: 2.0707 - val_accuracy: 0.0741\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 34s 546ms/step - loss: -1.1924 - accuracy: 0.3175 - val_loss: 2.2207 - val_accuracy: 0.0741\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 33s 530ms/step - loss: -1.3925 - accuracy: 0.2857 - val_loss: 0.1917 - val_accuracy: 0.1852\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 36s 570ms/step - loss: -0.8998 - accuracy: 0.4286 - val_loss: 0.6094 - val_accuracy: 0.4815\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 34s 546ms/step - loss: -0.7554 - accuracy: 0.4603 - val_loss: 0.9469 - val_accuracy: 0.1852\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 35s 554ms/step - loss: -0.9003 - accuracy: 0.3968 - val_loss: 1.4588 - val_accuracy: 0.2593\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 35s 549ms/step - loss: -0.4744 - accuracy: 0.3968 - val_loss: 1.7285 - val_accuracy: 0.1111\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 35s 559ms/step - loss: -0.9692 - accuracy: 0.3968 - val_loss: 1.7679 - val_accuracy: 0.1852\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 39s 619ms/step - loss: -0.8587 - accuracy: 0.3492 - val_loss: 2.1249 - val_accuracy: 0.2222\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 35s 552ms/step - loss: -1.1940 - accuracy: 0.3651 - val_loss: 1.9820 - val_accuracy: 0.2593\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 35s 558ms/step - loss: -1.5080 - accuracy: 0.3810 - val_loss: 1.8717 - val_accuracy: 0.3704\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 39s 612ms/step - loss: -1.0105 - accuracy: 0.3968 - val_loss: 2.3387 - val_accuracy: 0.2222\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 35s 552ms/step - loss: -1.2544 - accuracy: 0.3333 - val_loss: 1.8650 - val_accuracy: 0.3333\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 38s 600ms/step - loss: -1.1653 - accuracy: 0.4762 - val_loss: 1.7965 - val_accuracy: 0.2593\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 34s 546ms/step - loss: -1.6468 - accuracy: 0.3175 - val_loss: 2.3062 - val_accuracy: 0.0370\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 36s 564ms/step - loss: -1.7672 - accuracy: 0.2698 - val_loss: 2.0960 - val_accuracy: 0.0370\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 34s 545ms/step - loss: -1.8951 - accuracy: 0.3651 - val_loss: 2.6135 - val_accuracy: 0.2593\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 37s 583ms/step - loss: -2.1188 - accuracy: 0.4127 - val_loss: 2.3333 - val_accuracy: 0.2593\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 35s 563ms/step - loss: -2.2674 - accuracy: 0.4762 - val_loss: 2.1470 - val_accuracy: 0.2963\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 35s 558ms/step - loss: -2.7019 - accuracy: 0.4127 - val_loss: 1.2562 - val_accuracy: 0.0370\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 36s 578ms/step - loss: -2.4092 - accuracy: 0.2857 - val_loss: 1.9198 - val_accuracy: 0.2222\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 35s 557ms/step - loss: -2.6032 - accuracy: 0.3333 - val_loss: 1.8359 - val_accuracy: 0.2222\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 34s 539ms/step - loss: -1.8916 - accuracy: 0.3492 - val_loss: 1.6833 - val_accuracy: 0.2963\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 35s 559ms/step - loss: -2.1910 - accuracy: 0.4762 - val_loss: 2.2866 - val_accuracy: 0.4074\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 36s 572ms/step - loss: -1.9002 - accuracy: 0.4127 - val_loss: 2.2403 - val_accuracy: 0.1111\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 39s 615ms/step - loss: -2.2190 - accuracy: 0.2857 - val_loss: 1.3778 - val_accuracy: 0.1111\n",
      "Epoch 49/200\n",
      "60/63 [===========================>..] - ETA: 1s - loss: -2.5650 - accuracy: 0.3167 "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train the model and monitor the validation accuracy\n",
    "'''\n",
    "\n",
    "adam = Adam(lr=0.1) ## to be tuned\n",
    "chk = ModelCheckpoint('best_model.pkl', monitor='val_acc', save_best_only=True, mode='max', verbose=1)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.fit(xtrain_nn, ytrain_nn, epochs=200, batch_size=20, callbacks=[chk], validation_data=(xval_nn,yval_nn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Net -- Type I\n",
    "\n",
    "based on: https://towardsdatascience.com/how-to-use-convolutional-neural-networks-for-time-series-classification-56b1b0a07a57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this base model is one branch of the main model\n",
    "it takes a time series as an input, performs 1-D convolution, \n",
    "and returns it as an output ready for concatenation\n",
    "'''\n",
    "\n",
    "\n",
    "def get_base_model(input_len, fsize):\n",
    "    #the input is a time series of length n and width 1\n",
    "    input_seq = Input(shape = (input_len, 1))\n",
    "    #choose the number of convolution filters\n",
    "    nb_filters = 10\n",
    "    #1-D convolution and global max-pooling\n",
    "    convolved = Conv1D(nb_filters, fsize, padding=\"same\", activation=\"tanh\")(input_seq)\n",
    "    processed = GlobalMaxPooling1D()(convolved)\n",
    "    #dense layer with dropout regularization\n",
    "    compressed = Dense(50, activation=\"tanh\")(processed)\n",
    "    compressed = Dropout(0.3)(compressed)\n",
    "    model = Model(inputs=input_seq, outputs=compressed)\n",
    "    return model\n",
    "\n",
    "'''\n",
    "this is the main model\n",
    "it takes the original time series and its down-sampled versions as an input, and returns the result of classification as an output\n",
    "'''\n",
    "\n",
    "# convolution filter sizes: fsizes = [8,16,24]\n",
    "\n",
    "def main_model(inputs_lens = [512, 1024, xtrain_tr_filled.shape[1]], fsizes = [8,16,24]):\n",
    "    \n",
    "    #the inputs to the branches are the original time series, and its down-sampled versions\n",
    "    input_smallseq = Input(shape = (inputs_lens[0], 1)) # 1 = width of time series\n",
    "    input_medseq = Input(shape = (inputs_lens[1] , 1))\n",
    "    input_origseq = Input(shape = (inputs_lens[2], 1))\n",
    "    \n",
    "    #the more down-sampled the time series, the shorter the corresponding filter\n",
    "    base_net_small = get_base_model(inputs_lens[0], fsizes[0])\n",
    "    base_net_med = get_base_model(inputs_lens[1], fsizes[1])\n",
    "    base_net_original = get_base_model(inputs_lens[2], fsizes[2])\n",
    "    embedding_small = base_net_small(input_smallseq)\n",
    "    embedding_med = base_net_med(input_medseq)\n",
    "    embedding_original = base_net_original(input_origseq)\n",
    "    \n",
    "    #concatenate all the outputs\n",
    "    merged = Concatenate()([embedding_small, embedding_med, embedding_original])\n",
    "    out = Dense(1, activation='sigmoid')(merged)\n",
    "    model = Model(inputs=[input_smallseq, input_medseq, input_origseq], outputs=out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "63/63 [==============================] - 18s 284ms/step - loss: -0.1082 - accuracy: 0.4127\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 22s 350ms/step - loss: -0.1790 - accuracy: 0.4127\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 20s 315ms/step - loss: -0.2132 - accuracy: 0.4127\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 20s 311ms/step - loss: -0.2535 - accuracy: 0.3968\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 20s 322ms/step - loss: -0.3174 - accuracy: 0.4127\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 20s 313ms/step - loss: -0.3754 - accuracy: 0.4286\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 20s 320ms/step - loss: -0.4272 - accuracy: 0.4444\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 21s 338ms/step - loss: -0.4355 - accuracy: 0.4762\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 20s 318ms/step - loss: -0.4801 - accuracy: 0.4762\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 19s 309ms/step - loss: -0.5503 - accuracy: 0.4921\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 20s 324ms/step - loss: -0.6106 - accuracy: 0.5079\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 21s 333ms/step - loss: -0.6627 - accuracy: 0.5238\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 20s 315ms/step - loss: -0.7178 - accuracy: 0.5079\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 20s 313ms/step - loss: -0.7915 - accuracy: 0.4762\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 20s 325ms/step - loss: -0.8025 - accuracy: 0.4762\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 20s 325ms/step - loss: -0.8861 - accuracy: 0.4762\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 20s 321ms/step - loss: -0.9301 - accuracy: 0.4921\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 20s 321ms/step - loss: -0.9528 - accuracy: 0.4603\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 21s 326ms/step - loss: -0.8645 - accuracy: 0.5079\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 22s 351ms/step - loss: -0.9836 - accuracy: 0.5238\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 22s 349ms/step - loss: -1.0278 - accuracy: 0.4762\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 22s 342ms/step - loss: -0.9691 - accuracy: 0.4762\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 21s 333ms/step - loss: -1.0421 - accuracy: 0.4762\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 22s 341ms/step - loss: -1.1561 - accuracy: 0.5397\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 24s 386ms/step - loss: -1.2117 - accuracy: 0.5397\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 23s 373ms/step - loss: -1.3153 - accuracy: 0.5079\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 23s 367ms/step - loss: -1.4044 - accuracy: 0.5079\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 24s 381ms/step - loss: -1.4467 - accuracy: 0.5238\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 23s 360ms/step - loss: -1.5216 - accuracy: 0.5238\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 23s 360ms/step - loss: -1.6199 - accuracy: 0.5238\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 24s 386ms/step - loss: -1.6435 - accuracy: 0.5079\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 24s 379ms/step - loss: -1.7061 - accuracy: 0.5397\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 23s 357ms/step - loss: -1.7656 - accuracy: 0.4921\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 22s 342ms/step - loss: -1.7166 - accuracy: 0.5873\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 23s 365ms/step - loss: -1.7566 - accuracy: 0.5873\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 22s 349ms/step - loss: -1.7638 - accuracy: 0.5714\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 22s 356ms/step - loss: -1.9419 - accuracy: 0.5397\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 22s 346ms/step - loss: -1.8921 - accuracy: 0.4921\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 21s 339ms/step - loss: -1.6913 - accuracy: 0.4762\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 22s 354ms/step - loss: -2.1047 - accuracy: 0.5238\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 21s 336ms/step - loss: -2.1851 - accuracy: 0.5873\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 21s 339ms/step - loss: -2.2100 - accuracy: 0.5873\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 22s 345ms/step - loss: -2.2892 - accuracy: 0.5873\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 23s 357ms/step - loss: -2.3539 - accuracy: 0.5714\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 25s 393ms/step - loss: -2.4209 - accuracy: 0.6032\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 22s 356ms/step - loss: -2.4852 - accuracy: 0.6032\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 22s 349ms/step - loss: -2.5413 - accuracy: 0.6032\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 23s 363ms/step - loss: -2.6084 - accuracy: 0.6032\n",
      "Epoch 49/200\n",
      "63/63 [==============================] - 22s 354ms/step - loss: -2.6893 - accuracy: 0.6032\n",
      "Epoch 50/200\n",
      "63/63 [==============================] - 23s 362ms/step - loss: -2.7664 - accuracy: 0.6032\n",
      "Epoch 51/200\n",
      "63/63 [==============================] - 22s 342ms/step - loss: -2.5981 - accuracy: 0.6032\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - 22s 344ms/step - loss: -2.6068 - accuracy: 0.6190\n",
      "Epoch 53/200\n",
      "63/63 [==============================] - 21s 328ms/step - loss: -2.5862 - accuracy: 0.5714\n",
      "Epoch 54/200\n",
      "63/63 [==============================] - 20s 320ms/step - loss: -1.2389 - accuracy: 0.5714\n",
      "Epoch 55/200\n",
      "63/63 [==============================] - 21s 326ms/step - loss: -0.5347 - accuracy: 0.6032\n",
      "Epoch 56/200\n",
      "63/63 [==============================] - 20s 324ms/step - loss: -0.3986 - accuracy: 0.5873\n",
      "Epoch 57/200\n",
      "63/63 [==============================] - 21s 334ms/step - loss: -0.4002 - accuracy: 0.5556\n",
      "Epoch 58/200\n",
      "63/63 [==============================] - 22s 348ms/step - loss: -0.4337 - accuracy: 0.5079\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - 21s 340ms/step - loss: -0.4809 - accuracy: 0.5238\n",
      "Epoch 60/200\n",
      "63/63 [==============================] - 22s 343ms/step - loss: -0.5482 - accuracy: 0.5079\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-20c5ad2bb70a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_lens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxtrain_tr_filled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfsizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main_model(inputs_lens = [512, 1024, xtrain_tr_filled.shape[1]], fsizes = [8,16,24])\n",
    "model.fit(xtrain_nn, ytrain_nn, epochs=200, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Net -- Type II\n",
    "\n",
    "based on: https://blog.goodaudience.com/introduction-to-1d-convolutional-neural-networks-in-keras-for-time-sequences-3a7ff801a2cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "continue from here\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
