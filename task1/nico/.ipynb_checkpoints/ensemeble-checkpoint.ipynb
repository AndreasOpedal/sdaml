{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Load the proper csvs\n",
    "\n",
    "xtrain = pd.read_csv(\"X_train.csv\")\n",
    "xtrain = xtrain.iloc[:, 1:]\n",
    "xtest = pd.read_csv(\"X_test.csv\")\n",
    "xtest = xtest.iloc[:, 1:]\n",
    "ytrain = pd.read_csv(\"Y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Treat missing values\n",
    "# Treat missing values as column medians. Important (apparently) to use the medians from the training set in the test set\n",
    "\n",
    "xtrain = xtrain.fillna(xtrain.median())\n",
    "xtest = xtest.fillna(xtrain.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Scale the training and test data\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "xtrain_scaled = scaler.fit_transform(xtrain)\n",
    "xtrain = pd.DataFrame(xtrain_scaled, columns = xtrain.columns)\n",
    "xtest_scaled = scaler.fit_transform(xtest)\n",
    "xtest = pd.DataFrame(xtest_scaled, columns = xtest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove unnecessary id column from ytrain that just ***** things up\n",
    "\n",
    "ytrain1 = ytrain.loc[:, \"y\"]\n",
    "ytrain2 = pd.DataFrame(data = ytrain1.values, columns= ['y'])\n",
    "ytrain = ytrain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1090\n"
     ]
    }
   ],
   "source": [
    "# Outlier detection with local outlier factor\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=700, contamination=0.1)\n",
    "outliers = clf.fit_predict(xtrain)\n",
    "\n",
    "# Remove outliers from xtrain and ytrain\n",
    "\n",
    "\n",
    "outliers = outliers == 1\n",
    "print(np.count_nonzero(outliers))\n",
    "xtrain = xtrain[outliers]\n",
    "ytrain = ytrain[outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# option 2\\nsel = SelectFromModel(RandomForestClassifier(n_estimators = 200))\\nsel.fit(xtrain, ytrain)\\nselected_feat = xtrain.columns[(sel.get_support())]\\nxtrain = xtrain.loc[:,selected_feat]\\nxtest = xtest.loc[:,selected_feat]\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature selection\n",
    "\n",
    "# option 1  \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "k_best = 500\n",
    "xtrain = SelectKBest(mutual_info_regression, k=k_best).fit_transform(xtrain, ytrain)\n",
    "\n",
    "'''\n",
    "# option 2\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 200))\n",
    "sel.fit(xtrain, ytrain)\n",
    "selected_feat = xtrain.columns[(sel.get_support())]\n",
    "xtrain = xtrain.loc[:,selected_feat]\n",
    "xtest = xtest.loc[:,selected_feat]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.001809</td>\n",
       "      <td>-0.652740</td>\n",
       "      <td>-1.881312</td>\n",
       "      <td>0.917417</td>\n",
       "      <td>-0.388651</td>\n",
       "      <td>1.845923</td>\n",
       "      <td>-1.112274</td>\n",
       "      <td>0.275672</td>\n",
       "      <td>1.405990</td>\n",
       "      <td>-0.720986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002819</td>\n",
       "      <td>-0.381793</td>\n",
       "      <td>-0.897460</td>\n",
       "      <td>1.480634</td>\n",
       "      <td>-0.008390</td>\n",
       "      <td>0.249939</td>\n",
       "      <td>0.312998</td>\n",
       "      <td>-0.945093</td>\n",
       "      <td>0.925679</td>\n",
       "      <td>0.149058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.555346</td>\n",
       "      <td>-0.460321</td>\n",
       "      <td>2.108910</td>\n",
       "      <td>1.206184</td>\n",
       "      <td>-0.070530</td>\n",
       "      <td>0.464995</td>\n",
       "      <td>1.754254</td>\n",
       "      <td>1.231450</td>\n",
       "      <td>-0.700342</td>\n",
       "      <td>-0.342019</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.609892</td>\n",
       "      <td>-0.622497</td>\n",
       "      <td>-0.014061</td>\n",
       "      <td>-0.112038</td>\n",
       "      <td>0.454378</td>\n",
       "      <td>1.251713</td>\n",
       "      <td>-1.442390</td>\n",
       "      <td>-0.207605</td>\n",
       "      <td>0.265215</td>\n",
       "      <td>1.292065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.110118</td>\n",
       "      <td>0.526563</td>\n",
       "      <td>-0.286194</td>\n",
       "      <td>0.523945</td>\n",
       "      <td>0.225598</td>\n",
       "      <td>-0.843648</td>\n",
       "      <td>-0.569341</td>\n",
       "      <td>0.210957</td>\n",
       "      <td>-0.870321</td>\n",
       "      <td>1.267598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193833</td>\n",
       "      <td>0.810331</td>\n",
       "      <td>0.472682</td>\n",
       "      <td>-1.637788</td>\n",
       "      <td>1.091439</td>\n",
       "      <td>-1.411038</td>\n",
       "      <td>0.415870</td>\n",
       "      <td>-1.072406</td>\n",
       "      <td>-0.031837</td>\n",
       "      <td>-2.122182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.572714</td>\n",
       "      <td>1.801777</td>\n",
       "      <td>1.736020</td>\n",
       "      <td>1.073601</td>\n",
       "      <td>-1.513891</td>\n",
       "      <td>-0.542565</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>-0.611077</td>\n",
       "      <td>-1.751880</td>\n",
       "      <td>0.916094</td>\n",
       "      <td>...</td>\n",
       "      <td>1.718758</td>\n",
       "      <td>-0.626668</td>\n",
       "      <td>-0.634381</td>\n",
       "      <td>1.645562</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>-0.192713</td>\n",
       "      <td>-0.335371</td>\n",
       "      <td>-1.156034</td>\n",
       "      <td>0.304935</td>\n",
       "      <td>-1.064809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.319577</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>-1.195911</td>\n",
       "      <td>-0.288568</td>\n",
       "      <td>0.364310</td>\n",
       "      <td>-1.150942</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>0.629295</td>\n",
       "      <td>1.409429</td>\n",
       "      <td>1.033598</td>\n",
       "      <td>...</td>\n",
       "      <td>1.368602</td>\n",
       "      <td>-0.519776</td>\n",
       "      <td>-0.330124</td>\n",
       "      <td>-1.303248</td>\n",
       "      <td>-0.762968</td>\n",
       "      <td>-0.617725</td>\n",
       "      <td>-1.020345</td>\n",
       "      <td>0.277899</td>\n",
       "      <td>0.431110</td>\n",
       "      <td>0.585331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  2.001809 -0.652740 -1.881312  0.917417 -0.388651  1.845923 -1.112274   \n",
       "1  0.555346 -0.460321  2.108910  1.206184 -0.070530  0.464995  1.754254   \n",
       "2 -0.110118  0.526563 -0.286194  0.523945  0.225598 -0.843648 -0.569341   \n",
       "3  0.572714  1.801777  1.736020  1.073601 -1.513891 -0.542565 -0.000429   \n",
       "4 -0.319577  0.148305 -1.195911 -0.288568  0.364310 -1.150942 -0.000429   \n",
       "\n",
       "        7         8         9    ...       490       491       492       493  \\\n",
       "0  0.275672  1.405990 -0.720986  ... -0.002819 -0.381793 -0.897460  1.480634   \n",
       "1  1.231450 -0.700342 -0.342019  ... -1.609892 -0.622497 -0.014061 -0.112038   \n",
       "2  0.210957 -0.870321  1.267598  ... -0.193833  0.810331  0.472682 -1.637788   \n",
       "3 -0.611077 -1.751880  0.916094  ...  1.718758 -0.626668 -0.634381  1.645562   \n",
       "4  0.629295  1.409429  1.033598  ...  1.368602 -0.519776 -0.330124 -1.303248   \n",
       "\n",
       "        494       495       496       497       498       499  \n",
       "0 -0.008390  0.249939  0.312998 -0.945093  0.925679  0.149058  \n",
       "1  0.454378  1.251713 -1.442390 -0.207605  0.265215  1.292065  \n",
       "2  1.091439 -1.411038  0.415870 -1.072406 -0.031837 -2.122182  \n",
       "3  0.691200 -0.192713 -0.335371 -1.156034  0.304935 -1.064809  \n",
       "4 -0.762968 -0.617725 -1.020345  0.277899  0.431110  0.585331  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(xtrain).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\voting.py:43: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5180449838447956\n",
      "0.06730404190831796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "folds = 10\n",
    "\n",
    "cv_means = \n",
    "cv_stds = []\n",
    "estimators = np.array([100, 200, 300, 400])\n",
    "alphas = np.array([0.01, 0.03, 0.1, 0.3, 1, 3])\n",
    "mutual_features = np.array([50, 100, 200, 300, 400])\n",
    "max_depth = np.array([5, 10, 20, 30])\n",
    "\n",
    "\n",
    "for n in estimators:\n",
    "    for best in mutual_features:\n",
    "        for a in alphas: \n",
    "            for depth in max_depth: \n",
    "                \n",
    "                xtrain = SelectKBest(mutual_info_regression, k=best).fit_transform(xtrain, ytrain)\n",
    "                r1 = RandomForestRegressor(n_estimators= n, random_state=42, max_depth= depth, bootstrap = True)\n",
    "                r2 = linear_model.Lasso(alpha= a\n",
    "                r3 = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42, n_estimators=200)\n",
    "                er = VotingRegressor([('rf', r1), ('lasso', r2), ('xgb', r3)])\n",
    "                scores = cross_val_score(estimator = er, X = xtrain,\n",
    "                                   y = ytrain, scoring = 'r2', cv = folds)\n",
    "    \n",
    "print(np.mean(scores))\n",
    "print(np.std(scores))\n",
    "print(n_Es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
