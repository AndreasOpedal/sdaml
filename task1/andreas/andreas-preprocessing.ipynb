{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118345.392781</td>\n",
       "      <td>3104.010883</td>\n",
       "      <td>82378.542430</td>\n",
       "      <td>1086.678601</td>\n",
       "      <td>11395.883550</td>\n",
       "      <td>10.455601</td>\n",
       "      <td>109886.476608</td>\n",
       "      <td>1.054926e+06</td>\n",
       "      <td>101877.946528</td>\n",
       "      <td>2.550290</td>\n",
       "      <td>...</td>\n",
       "      <td>10.769524</td>\n",
       "      <td>10.245068</td>\n",
       "      <td>1021.907543</td>\n",
       "      <td>1031.645762</td>\n",
       "      <td>107440.039766</td>\n",
       "      <td>107083.296966</td>\n",
       "      <td>5559.203921</td>\n",
       "      <td>10.861464</td>\n",
       "      <td>107548.413675</td>\n",
       "      <td>2.299202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5889.055991</td>\n",
       "      <td>97932.067482</td>\n",
       "      <td>1116.564363</td>\n",
       "      <td>12172.212426</td>\n",
       "      <td>10.502997</td>\n",
       "      <td>100372.504488</td>\n",
       "      <td>1.011783e+06</td>\n",
       "      <td>108852.296962</td>\n",
       "      <td>2.579040</td>\n",
       "      <td>...</td>\n",
       "      <td>10.859822</td>\n",
       "      <td>10.088023</td>\n",
       "      <td>988.135968</td>\n",
       "      <td>999.044639</td>\n",
       "      <td>105238.779040</td>\n",
       "      <td>106365.468525</td>\n",
       "      <td>10334.091649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107841.227180</td>\n",
       "      <td>2.472763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95373.022035</td>\n",
       "      <td>6293.442455</td>\n",
       "      <td>93371.369288</td>\n",
       "      <td>1034.722073</td>\n",
       "      <td>11618.142107</td>\n",
       "      <td>10.947611</td>\n",
       "      <td>109337.757279</td>\n",
       "      <td>1.006491e+06</td>\n",
       "      <td>104540.883376</td>\n",
       "      <td>2.573247</td>\n",
       "      <td>...</td>\n",
       "      <td>10.356015</td>\n",
       "      <td>10.514234</td>\n",
       "      <td>995.480813</td>\n",
       "      <td>898.329758</td>\n",
       "      <td>107044.005199</td>\n",
       "      <td>102704.104686</td>\n",
       "      <td>7697.875887</td>\n",
       "      <td>10.277760</td>\n",
       "      <td>103414.594212</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105066.272301</td>\n",
       "      <td>3279.162164</td>\n",
       "      <td>119554.079514</td>\n",
       "      <td>1114.014483</td>\n",
       "      <td>12127.235755</td>\n",
       "      <td>10.540204</td>\n",
       "      <td>106215.391332</td>\n",
       "      <td>1.022381e+06</td>\n",
       "      <td>109597.474506</td>\n",
       "      <td>2.693256</td>\n",
       "      <td>...</td>\n",
       "      <td>10.609811</td>\n",
       "      <td>10.991861</td>\n",
       "      <td>1117.179063</td>\n",
       "      <td>867.267810</td>\n",
       "      <td>100617.082858</td>\n",
       "      <td>108893.304959</td>\n",
       "      <td>6549.131099</td>\n",
       "      <td>9.337688</td>\n",
       "      <td>105722.857008</td>\n",
       "      <td>2.484935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98957.033333</td>\n",
       "      <td>4177.482190</td>\n",
       "      <td>97239.708338</td>\n",
       "      <td>1049.430921</td>\n",
       "      <td>10417.250336</td>\n",
       "      <td>10.618957</td>\n",
       "      <td>102736.470171</td>\n",
       "      <td>1.086871e+06</td>\n",
       "      <td>103340.057448</td>\n",
       "      <td>2.540610</td>\n",
       "      <td>...</td>\n",
       "      <td>10.397777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>863.943966</td>\n",
       "      <td>1041.278922</td>\n",
       "      <td>105352.672454</td>\n",
       "      <td>101705.692839</td>\n",
       "      <td>5388.312773</td>\n",
       "      <td>12.196382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.930136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x0           x1             x2           x3            x4  \\\n",
       "0  118345.392781  3104.010883   82378.542430  1086.678601  11395.883550   \n",
       "1            NaN  5889.055991   97932.067482  1116.564363  12172.212426   \n",
       "2   95373.022035  6293.442455   93371.369288  1034.722073  11618.142107   \n",
       "3  105066.272301  3279.162164  119554.079514  1114.014483  12127.235755   \n",
       "4   98957.033333  4177.482190   97239.708338  1049.430921  10417.250336   \n",
       "\n",
       "          x5             x6            x7             x8        x9  ...  \\\n",
       "0  10.455601  109886.476608  1.054926e+06  101877.946528  2.550290  ...   \n",
       "1  10.502997  100372.504488  1.011783e+06  108852.296962  2.579040  ...   \n",
       "2  10.947611  109337.757279  1.006491e+06  104540.883376  2.573247  ...   \n",
       "3  10.540204  106215.391332  1.022381e+06  109597.474506  2.693256  ...   \n",
       "4  10.618957  102736.470171  1.086871e+06  103340.057448  2.540610  ...   \n",
       "\n",
       "        x822       x823         x824         x825           x826  \\\n",
       "0  10.769524  10.245068  1021.907543  1031.645762  107440.039766   \n",
       "1  10.859822  10.088023   988.135968   999.044639  105238.779040   \n",
       "2  10.356015  10.514234   995.480813   898.329758  107044.005199   \n",
       "3  10.609811  10.991861  1117.179063   867.267810  100617.082858   \n",
       "4  10.397777        NaN   863.943966  1041.278922  105352.672454   \n",
       "\n",
       "            x827          x828       x829           x830      x831  \n",
       "0  107083.296966   5559.203921  10.861464  107548.413675  2.299202  \n",
       "1  106365.468525  10334.091649        NaN  107841.227180  2.472763  \n",
       "2  102704.104686   7697.875887  10.277760  103414.594212       NaN  \n",
       "3  108893.304959   6549.131099   9.337688  105722.857008  2.484935  \n",
       "4  101705.692839   5388.312773  12.196382            NaN  1.930136  \n",
       "\n",
       "[5 rows x 832 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = pd.read_csv(\"X_train.csv\")\n",
    "xtrain = xtrain.iloc[:, 1:]\n",
    "xtest = pd.read_csv(\"X_test.csv\")\n",
    "xtest = xtest.iloc[:, 1:]\n",
    "ytrain = pd.read_csv(\"Y_train.csv\")\n",
    "\n",
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1212, 832)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1212 entries, 0 to 1211\n",
      "Data columns (total 10 columns):\n",
      "x0    1131 non-null float64\n",
      "x1    1109 non-null float64\n",
      "x2    1120 non-null float64\n",
      "x3    1121 non-null float64\n",
      "x4    1120 non-null float64\n",
      "x5    1109 non-null float64\n",
      "x6    1115 non-null float64\n",
      "x7    1141 non-null float64\n",
      "x8    1107 non-null float64\n",
      "x9    1115 non-null float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 94.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Get a feeling for amount of missing values\n",
    "xtrain.iloc[:,0:10].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118345.392781</td>\n",
       "      <td>3104.010883</td>\n",
       "      <td>82378.542430</td>\n",
       "      <td>1086.678601</td>\n",
       "      <td>11395.883550</td>\n",
       "      <td>10.455601</td>\n",
       "      <td>109886.476608</td>\n",
       "      <td>1.054926e+06</td>\n",
       "      <td>101877.946528</td>\n",
       "      <td>2.550290</td>\n",
       "      <td>...</td>\n",
       "      <td>10.769524</td>\n",
       "      <td>10.245068</td>\n",
       "      <td>1021.907543</td>\n",
       "      <td>1031.645762</td>\n",
       "      <td>107440.039766</td>\n",
       "      <td>107083.296966</td>\n",
       "      <td>5559.203921</td>\n",
       "      <td>10.861464</td>\n",
       "      <td>107548.413675</td>\n",
       "      <td>2.299202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99950.259599</td>\n",
       "      <td>5889.055991</td>\n",
       "      <td>97932.067482</td>\n",
       "      <td>1116.564363</td>\n",
       "      <td>12172.212426</td>\n",
       "      <td>10.502997</td>\n",
       "      <td>100372.504488</td>\n",
       "      <td>1.011783e+06</td>\n",
       "      <td>108852.296962</td>\n",
       "      <td>2.579040</td>\n",
       "      <td>...</td>\n",
       "      <td>10.859822</td>\n",
       "      <td>10.088023</td>\n",
       "      <td>988.135968</td>\n",
       "      <td>999.044639</td>\n",
       "      <td>105238.779040</td>\n",
       "      <td>106365.468525</td>\n",
       "      <td>10334.091649</td>\n",
       "      <td>10.018963</td>\n",
       "      <td>107841.227180</td>\n",
       "      <td>2.472763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95373.022035</td>\n",
       "      <td>6293.442455</td>\n",
       "      <td>93371.369288</td>\n",
       "      <td>1034.722073</td>\n",
       "      <td>11618.142107</td>\n",
       "      <td>10.947611</td>\n",
       "      <td>109337.757279</td>\n",
       "      <td>1.006491e+06</td>\n",
       "      <td>104540.883376</td>\n",
       "      <td>2.573247</td>\n",
       "      <td>...</td>\n",
       "      <td>10.356015</td>\n",
       "      <td>10.514234</td>\n",
       "      <td>995.480813</td>\n",
       "      <td>898.329758</td>\n",
       "      <td>107044.005199</td>\n",
       "      <td>102704.104686</td>\n",
       "      <td>7697.875887</td>\n",
       "      <td>10.277760</td>\n",
       "      <td>103414.594212</td>\n",
       "      <td>2.273542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105066.272301</td>\n",
       "      <td>3279.162164</td>\n",
       "      <td>119554.079514</td>\n",
       "      <td>1114.014483</td>\n",
       "      <td>12127.235755</td>\n",
       "      <td>10.540204</td>\n",
       "      <td>106215.391332</td>\n",
       "      <td>1.022381e+06</td>\n",
       "      <td>109597.474506</td>\n",
       "      <td>2.693256</td>\n",
       "      <td>...</td>\n",
       "      <td>10.609811</td>\n",
       "      <td>10.991861</td>\n",
       "      <td>1117.179063</td>\n",
       "      <td>867.267810</td>\n",
       "      <td>100617.082858</td>\n",
       "      <td>108893.304959</td>\n",
       "      <td>6549.131099</td>\n",
       "      <td>9.337688</td>\n",
       "      <td>105722.857008</td>\n",
       "      <td>2.484935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98957.033333</td>\n",
       "      <td>4177.482190</td>\n",
       "      <td>97239.708338</td>\n",
       "      <td>1049.430921</td>\n",
       "      <td>10417.250336</td>\n",
       "      <td>10.618957</td>\n",
       "      <td>102736.470171</td>\n",
       "      <td>1.086871e+06</td>\n",
       "      <td>103340.057448</td>\n",
       "      <td>2.540610</td>\n",
       "      <td>...</td>\n",
       "      <td>10.397777</td>\n",
       "      <td>10.549044</td>\n",
       "      <td>863.943966</td>\n",
       "      <td>1041.278922</td>\n",
       "      <td>105352.672454</td>\n",
       "      <td>101705.692839</td>\n",
       "      <td>5388.312773</td>\n",
       "      <td>12.196382</td>\n",
       "      <td>104996.343999</td>\n",
       "      <td>1.930136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x0           x1             x2           x3            x4  \\\n",
       "0  118345.392781  3104.010883   82378.542430  1086.678601  11395.883550   \n",
       "1   99950.259599  5889.055991   97932.067482  1116.564363  12172.212426   \n",
       "2   95373.022035  6293.442455   93371.369288  1034.722073  11618.142107   \n",
       "3  105066.272301  3279.162164  119554.079514  1114.014483  12127.235755   \n",
       "4   98957.033333  4177.482190   97239.708338  1049.430921  10417.250336   \n",
       "\n",
       "          x5             x6            x7             x8        x9  ...  \\\n",
       "0  10.455601  109886.476608  1.054926e+06  101877.946528  2.550290  ...   \n",
       "1  10.502997  100372.504488  1.011783e+06  108852.296962  2.579040  ...   \n",
       "2  10.947611  109337.757279  1.006491e+06  104540.883376  2.573247  ...   \n",
       "3  10.540204  106215.391332  1.022381e+06  109597.474506  2.693256  ...   \n",
       "4  10.618957  102736.470171  1.086871e+06  103340.057448  2.540610  ...   \n",
       "\n",
       "        x822       x823         x824         x825           x826  \\\n",
       "0  10.769524  10.245068  1021.907543  1031.645762  107440.039766   \n",
       "1  10.859822  10.088023   988.135968   999.044639  105238.779040   \n",
       "2  10.356015  10.514234   995.480813   898.329758  107044.005199   \n",
       "3  10.609811  10.991861  1117.179063   867.267810  100617.082858   \n",
       "4  10.397777  10.549044   863.943966  1041.278922  105352.672454   \n",
       "\n",
       "            x827          x828       x829           x830      x831  \n",
       "0  107083.296966   5559.203921  10.861464  107548.413675  2.299202  \n",
       "1  106365.468525  10334.091649  10.018963  107841.227180  2.472763  \n",
       "2  102704.104686   7697.875887  10.277760  103414.594212  2.273542  \n",
       "3  108893.304959   6549.131099   9.337688  105722.857008  2.484935  \n",
       "4  101705.692839   5388.312773  12.196382  104996.343999  1.930136  \n",
       "\n",
       "[5 rows x 832 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treat missing values as column means\n",
    "\n",
    "xtrain = xtrain.fillna(xtrain.mean())\n",
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scale the training and test data\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "xtrain_scaled = scaler.fit_transform(xtrain)\n",
    "xtrain = pd.DataFrame(xtrain_scaled, columns = xtrain.columns)\n",
    "xtrain.head()\n",
    "\n",
    "xtest_scaled = scaler.fit_transform(xtest)\n",
    "xtest = pd.DataFrame(xtest_scaled, columns = xtest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09869328 0.04271685]\n"
     ]
    }
   ],
   "source": [
    "# IGNORE\n",
    "# PCA with 2 remaining features/components\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(xtrain)\n",
    "xpca = pd.DataFrame(data = principal_components, columns = ['PC1', 'PC2'])\n",
    "\n",
    "plt.scatter(xpca['PC1'], xpca['PC2'], alpha=0.5)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.plot([-18, -18], [-30, 30], marker='o')\n",
    "plt.plot([22, 22], [-30, 30], marker='o')\n",
    "plt.plot([-45, 45], [-13, -13], marker='o')\n",
    "plt.plot([-45, 45], [12, 12], marker='o')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "per_var = np.round(pca.explained_variance_ratio_ * 100, decimals=1)\n",
    "labels = ['PC' + str(x) for x in range(1, len(per_var) + 1)]\n",
    "plt.bar(x=range(1, len(per_var)+1), height=per_var, tick_label=labels)\n",
    "plt.ylabel('percentange of explained variance')\n",
    "plt.xlabel('principal component')\n",
    "plt.title('scree plot')\n",
    "plt.show()\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.003789e+00</td>\n",
       "      <td>-0.655849</td>\n",
       "      <td>-1.886600</td>\n",
       "      <td>0.916929</td>\n",
       "      <td>1.455717</td>\n",
       "      <td>-0.393113</td>\n",
       "      <td>1.842526</td>\n",
       "      <td>0.207068</td>\n",
       "      <td>-1.112314</td>\n",
       "      <td>0.276588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>-1.110028e+00</td>\n",
       "      <td>0.251549</td>\n",
       "      <td>0.313682</td>\n",
       "      <td>0.905023</td>\n",
       "      <td>0.745790</td>\n",
       "      <td>-0.944838</td>\n",
       "      <td>8.892476e-01</td>\n",
       "      <td>9.233435e-01</td>\n",
       "      <td>1.579906e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.170291e-15</td>\n",
       "      <td>2.403925</td>\n",
       "      <td>-0.216914</td>\n",
       "      <td>1.232632</td>\n",
       "      <td>2.267203</td>\n",
       "      <td>-0.214877</td>\n",
       "      <td>-1.736539</td>\n",
       "      <td>-1.383793</td>\n",
       "      <td>1.477503</td>\n",
       "      <td>0.468797</td>\n",
       "      <td>...</td>\n",
       "      <td>1.152094</td>\n",
       "      <td>-1.683506e+00</td>\n",
       "      <td>-0.103563</td>\n",
       "      <td>-0.034465</td>\n",
       "      <td>0.101094</td>\n",
       "      <td>0.478006</td>\n",
       "      <td>2.612417</td>\n",
       "      <td>-7.499671e-15</td>\n",
       "      <td>1.029284e+00</td>\n",
       "      <td>1.226602e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.986002e-01</td>\n",
       "      <td>2.848202</td>\n",
       "      <td>-0.706509</td>\n",
       "      <td>0.368077</td>\n",
       "      <td>1.688041</td>\n",
       "      <td>1.457136</td>\n",
       "      <td>1.636103</td>\n",
       "      <td>-1.578900</td>\n",
       "      <td>-0.123474</td>\n",
       "      <td>0.430067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.701345</td>\n",
       "      <td>-1.271165e-01</td>\n",
       "      <td>-0.026331</td>\n",
       "      <td>-1.110000</td>\n",
       "      <td>0.760386</td>\n",
       "      <td>-0.887858</td>\n",
       "      <td>0.648457</td>\n",
       "      <td>2.731569e-01</td>\n",
       "      <td>-5.722800e-01</td>\n",
       "      <td>1.093697e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.572892e-01</td>\n",
       "      <td>-0.463420</td>\n",
       "      <td>2.104230</td>\n",
       "      <td>1.205696</td>\n",
       "      <td>2.220190</td>\n",
       "      <td>-0.074959</td>\n",
       "      <td>0.461499</td>\n",
       "      <td>-0.993009</td>\n",
       "      <td>1.754213</td>\n",
       "      <td>1.232371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232337</td>\n",
       "      <td>1.617028e+00</td>\n",
       "      <td>1.253338</td>\n",
       "      <td>-1.441711</td>\n",
       "      <td>-1.586810</td>\n",
       "      <td>1.421010</td>\n",
       "      <td>-0.207350</td>\n",
       "      <td>-7.190751e-01</td>\n",
       "      <td>2.628537e-01</td>\n",
       "      <td>1.301543e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.081925e-01</td>\n",
       "      <td>0.523514</td>\n",
       "      <td>-0.291240</td>\n",
       "      <td>0.523456</td>\n",
       "      <td>0.432765</td>\n",
       "      <td>0.221201</td>\n",
       "      <td>-0.847238</td>\n",
       "      <td>1.384981</td>\n",
       "      <td>-0.569382</td>\n",
       "      <td>0.211873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.547710</td>\n",
       "      <td>-7.135373e-14</td>\n",
       "      <td>-1.409453</td>\n",
       "      <td>0.416555</td>\n",
       "      <td>0.142690</td>\n",
       "      <td>-1.260314</td>\n",
       "      <td>-1.072150</td>\n",
       "      <td>2.298233e+00</td>\n",
       "      <td>-2.105964e-14</td>\n",
       "      <td>-2.114335e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  2.003789e+00 -0.655849 -1.886600  0.916929  1.455717 -0.393113  1.842526   \n",
       "1  3.170291e-15  2.403925 -0.216914  1.232632  2.267203 -0.214877 -1.736539   \n",
       "2 -4.986002e-01  2.848202 -0.706509  0.368077  1.688041  1.457136  1.636103   \n",
       "3  5.572892e-01 -0.463420  2.104230  1.205696  2.220190 -0.074959  0.461499   \n",
       "4 -1.081925e-01  0.523514 -0.291240  0.523456  0.432765  0.221201 -0.847238   \n",
       "\n",
       "         x7        x8        x9  ...      x822          x823      x824  \\\n",
       "0  0.207068 -1.112314  0.276588  ...  0.819901 -1.110028e+00  0.251549   \n",
       "1 -1.383793  1.477503  0.468797  ...  1.152094 -1.683506e+00 -0.103563   \n",
       "2 -1.578900 -0.123474  0.430067  ... -0.701345 -1.271165e-01 -0.026331   \n",
       "3 -0.993009  1.754213  1.232371  ...  0.232337  1.617028e+00  1.253338   \n",
       "4  1.384981 -0.569382  0.211873  ... -0.547710 -7.135373e-14 -1.409453   \n",
       "\n",
       "       x825      x826      x827      x828          x829          x830  \\\n",
       "0  0.313682  0.905023  0.745790 -0.944838  8.892476e-01  9.233435e-01   \n",
       "1 -0.034465  0.101094  0.478006  2.612417 -7.499671e-15  1.029284e+00   \n",
       "2 -1.110000  0.760386 -0.887858  0.648457  2.731569e-01 -5.722800e-01   \n",
       "3 -1.441711 -1.586810  1.421010 -0.207350 -7.190751e-01  2.628537e-01   \n",
       "4  0.416555  0.142690 -1.260314 -1.072150  2.298233e+00 -2.105964e-14   \n",
       "\n",
       "           x831  \n",
       "0  1.579906e-01  \n",
       "1  1.226602e+00  \n",
       "2  1.093697e-14  \n",
       "3  1.301543e+00  \n",
       "4 -2.114335e+00  \n",
       "\n",
       "[5 rows x 832 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highly ad hoc way of removing outliers based on PCA plot above\n",
    "\n",
    "outliers = (xpca['PC1'] <= 22) & (xpca['PC1'] >= -18) & (xpca['PC2'] <= 12) & (xpca['PC2'] >= -13)\n",
    "np.count_nonzero(outliers)\n",
    "xtrain_without_outliers = xtrain[outliers]\n",
    "ytrain_without_outliers = ytrain[outliers]\n",
    "xtrain_without_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True, False,  True,  True, False,  True,\n",
       "       False,  True,  True, False,  True,  True, False, False,  True,\n",
       "        True, False,  True,  True, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False, False,  True, False,\n",
       "       False,  True, False,  True, False,  True,  True,  True, False,\n",
       "       False,  True, False,  True, False,  True,  True, False,  True,\n",
       "        True, False, False, False,  True, False,  True, False,  True,\n",
       "        True,  True,  True, False, False, False,  True,  True, False,\n",
       "        True,  True,  True, False,  True,  True, False,  True,  True,\n",
       "       False,  True,  True,  True,  True, False,  True, False, False,\n",
       "       False,  True, False,  True,  True,  True, False,  True, False,\n",
       "       False,  True, False, False, False,  True,  True,  True, False,\n",
       "        True,  True, False,  True,  True,  True,  True, False, False,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "        True,  True,  True, False,  True, False, False, False,  True,\n",
       "        True,  True, False, False,  True,  True, False,  True, False,\n",
       "       False,  True, False,  True,  True, False,  True,  True,  True,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False,  True, False, False, False,  True,\n",
       "       False, False, False, False, False, False,  True, False,  True,\n",
       "       False,  True, False, False,  True,  True,  True, False,  True,\n",
       "        True,  True, False,  True, False,  True, False,  True, False,\n",
       "       False, False,  True,  True, False, False, False, False,  True,\n",
       "       False,  True, False, False, False,  True,  True,  True, False,\n",
       "       False, False,  True, False,  True, False, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "       False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "       False, False,  True, False,  True, False, False, False,  True,\n",
       "        True,  True,  True, False,  True, False, False,  True, False,\n",
       "       False, False, False,  True,  True, False, False,  True,  True,\n",
       "       False, False, False,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True, False, False,  True, False,  True, False,\n",
       "        True,  True,  True,  True, False, False, False,  True,  True,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "        True, False,  True, False,  True,  True, False,  True, False,\n",
       "       False, False, False, False,  True, False,  True, False, False,\n",
       "       False, False,  True,  True,  True, False, False, False, False,\n",
       "        True,  True, False, False,  True, False,  True,  True,  True,\n",
       "       False, False, False,  True,  True, False, False,  True,  True,\n",
       "       False, False,  True,  True,  True, False,  True, False,  True,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "       False, False, False,  True,  True,  True,  True, False,  True,\n",
       "       False,  True, False, False,  True,  True, False,  True,  True,\n",
       "        True, False, False, False,  True,  True,  True,  True, False,\n",
       "       False,  True,  True, False, False,  True, False,  True,  True,\n",
       "        True, False, False, False,  True, False, False, False,  True,\n",
       "        True,  True,  True, False,  True, False,  True, False, False,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "       False,  True,  True, False, False,  True,  True, False, False,\n",
       "       False, False, False, False, False,  True,  True,  True, False,\n",
       "       False, False,  True,  True,  True,  True,  True,  True, False,\n",
       "       False,  True, False,  True,  True,  True, False, False,  True,\n",
       "       False,  True,  True,  True,  True, False,  True, False, False,\n",
       "        True, False, False,  True,  True,  True, False,  True,  True,\n",
       "       False,  True,  True, False, False, False,  True, False,  True,\n",
       "       False,  True, False, False,  True,  True, False, False,  True,\n",
       "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "       False, False, False, False,  True, False, False,  True,  True,\n",
       "       False, False, False, False,  True,  True, False, False,  True,\n",
       "       False, False,  True,  True,  True, False, False, False, False,\n",
       "       False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "       False,  True,  True,  True, False,  True,  True, False, False,\n",
       "        True, False, False,  True,  True,  True,  True,  True, False,\n",
       "        True, False,  True, False,  True, False, False, False, False,\n",
       "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "       False,  True, False,  True, False, False, False,  True,  True,\n",
       "        True, False, False,  True,  True, False,  True,  True, False,\n",
       "       False,  True, False,  True, False,  True, False, False,  True,\n",
       "       False,  True, False, False, False, False,  True,  True, False,\n",
       "        True, False, False, False, False,  True, False,  True,  True,\n",
       "       False,  True, False, False, False, False, False,  True,  True,\n",
       "       False, False,  True,  True, False, False, False, False,  True,\n",
       "       False,  True, False,  True,  True, False,  True, False,  True,\n",
       "       False,  True, False, False, False,  True, False,  True, False,\n",
       "       False,  True,  True, False,  True, False,  True, False, False,\n",
       "       False,  True, False, False,  True,  True, False, False,  True,\n",
       "       False, False, False, False, False,  True, False,  True, False,\n",
       "        True, False, False,  True, False, False, False, False,  True,\n",
       "        True,  True, False,  True, False,  True,  True, False, False,\n",
       "        True, False,  True, False, False,  True, False,  True,  True,\n",
       "        True,  True, False, False,  True,  True, False, False,  True,\n",
       "       False, False,  True,  True, False, False,  True, False,  True,\n",
       "        True, False,  True, False, False, False, False, False,  True,\n",
       "       False,  True,  True, False,  True, False,  True, False,  True,\n",
       "       False, False,  True, False,  True, False,  True,  True,  True,\n",
       "       False,  True, False, False,  True, False, False, False,  True,\n",
       "       False, False, False, False,  True, False,  True, False,  True,\n",
       "       False, False,  True,  True,  True, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False,  True,\n",
       "        True,  True, False,  True,  True, False,  True, False,  True,\n",
       "        True, False,  True, False, False,  True,  True,  True,  True,\n",
       "       False,  True,  True, False])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run random forest to select features\n",
    "\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 500))\n",
    "sel.fit(xtrain_without_outliers, ytrain_without_outliers)\n",
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x8</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>...</th>\n",
       "      <th>x816</th>\n",
       "      <th>x818</th>\n",
       "      <th>x819</th>\n",
       "      <th>x821</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.003789e+00</td>\n",
       "      <td>-1.886600</td>\n",
       "      <td>0.916929</td>\n",
       "      <td>-0.393113</td>\n",
       "      <td>1.842526</td>\n",
       "      <td>-1.112314</td>\n",
       "      <td>1.408577</td>\n",
       "      <td>-0.736072</td>\n",
       "      <td>0.798808</td>\n",
       "      <td>4.711032e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380652</td>\n",
       "      <td>1.130230e+00</td>\n",
       "      <td>1.480129</td>\n",
       "      <td>-7.041406e-03</td>\n",
       "      <td>0.251549</td>\n",
       "      <td>0.313682</td>\n",
       "      <td>0.905023</td>\n",
       "      <td>0.745790</td>\n",
       "      <td>8.892476e-01</td>\n",
       "      <td>9.233435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.170291e-15</td>\n",
       "      <td>-0.216914</td>\n",
       "      <td>1.232632</td>\n",
       "      <td>-0.214877</td>\n",
       "      <td>-1.736539</td>\n",
       "      <td>1.477503</td>\n",
       "      <td>-1.018184</td>\n",
       "      <td>-0.384914</td>\n",
       "      <td>0.876085</td>\n",
       "      <td>-4.022581e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.594495</td>\n",
       "      <td>1.373773e-14</td>\n",
       "      <td>-1.314220</td>\n",
       "      <td>3.612492e-15</td>\n",
       "      <td>-0.103563</td>\n",
       "      <td>-0.034465</td>\n",
       "      <td>0.101094</td>\n",
       "      <td>0.478006</td>\n",
       "      <td>-7.499671e-15</td>\n",
       "      <td>1.029284e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.986002e-01</td>\n",
       "      <td>-0.706509</td>\n",
       "      <td>0.368077</td>\n",
       "      <td>1.457136</td>\n",
       "      <td>1.636103</td>\n",
       "      <td>-0.123474</td>\n",
       "      <td>0.428261</td>\n",
       "      <td>1.996995</td>\n",
       "      <td>-0.999857</td>\n",
       "      <td>-1.148263e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.532391</td>\n",
       "      <td>6.874894e-01</td>\n",
       "      <td>-0.115127</td>\n",
       "      <td>9.373678e-01</td>\n",
       "      <td>-0.026331</td>\n",
       "      <td>-1.110000</td>\n",
       "      <td>0.760386</td>\n",
       "      <td>-0.887858</td>\n",
       "      <td>2.731569e-01</td>\n",
       "      <td>-5.722800e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.572892e-01</td>\n",
       "      <td>2.104230</td>\n",
       "      <td>1.205696</td>\n",
       "      <td>-0.074959</td>\n",
       "      <td>0.461499</td>\n",
       "      <td>1.754213</td>\n",
       "      <td>-0.697834</td>\n",
       "      <td>-0.356636</td>\n",
       "      <td>0.939073</td>\n",
       "      <td>4.512638e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621358</td>\n",
       "      <td>4.664480e-01</td>\n",
       "      <td>-0.112546</td>\n",
       "      <td>4.557322e-01</td>\n",
       "      <td>1.253338</td>\n",
       "      <td>-1.441711</td>\n",
       "      <td>-1.586810</td>\n",
       "      <td>1.421010</td>\n",
       "      <td>-7.190751e-01</td>\n",
       "      <td>2.628537e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.081925e-01</td>\n",
       "      <td>-0.291240</td>\n",
       "      <td>0.523456</td>\n",
       "      <td>0.221201</td>\n",
       "      <td>-0.847238</td>\n",
       "      <td>-0.569382</td>\n",
       "      <td>-0.867819</td>\n",
       "      <td>1.254977</td>\n",
       "      <td>-0.725970</td>\n",
       "      <td>-8.662420e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811482</td>\n",
       "      <td>1.373773e-14</td>\n",
       "      <td>-1.638298</td>\n",
       "      <td>1.092801e+00</td>\n",
       "      <td>-1.409453</td>\n",
       "      <td>0.416555</td>\n",
       "      <td>0.142690</td>\n",
       "      <td>-1.260314</td>\n",
       "      <td>2.298233e+00</td>\n",
       "      <td>-2.105964e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x0        x2        x3        x5        x6        x8       x10  \\\n",
       "0  2.003789e+00 -1.886600  0.916929 -0.393113  1.842526 -1.112314  1.408577   \n",
       "1  3.170291e-15 -0.216914  1.232632 -0.214877 -1.736539  1.477503 -1.018184   \n",
       "2 -4.986002e-01 -0.706509  0.368077  1.457136  1.636103 -0.123474  0.428261   \n",
       "3  5.572892e-01  2.104230  1.205696 -0.074959  0.461499  1.754213 -0.697834   \n",
       "4 -1.081925e-01 -0.291240  0.523456  0.221201 -0.847238 -0.569382 -0.867819   \n",
       "\n",
       "        x11       x13           x14  ...      x816          x818      x819  \\\n",
       "0 -0.736072  0.798808  4.711032e-02  ... -0.380652  1.130230e+00  1.480129   \n",
       "1 -0.384914  0.876085 -4.022581e-01  ...  1.594495  1.373773e-14 -1.314220   \n",
       "2  1.996995 -0.999857 -1.148263e+00  ...  1.532391  6.874894e-01 -0.115127   \n",
       "3 -0.356636  0.939073  4.512638e-15  ... -0.621358  4.664480e-01 -0.112546   \n",
       "4  1.254977 -0.725970 -8.662420e-01  ...  0.811482  1.373773e-14 -1.638298   \n",
       "\n",
       "           x821      x824      x825      x826      x827          x829  \\\n",
       "0 -7.041406e-03  0.251549  0.313682  0.905023  0.745790  8.892476e-01   \n",
       "1  3.612492e-15 -0.103563 -0.034465  0.101094  0.478006 -7.499671e-15   \n",
       "2  9.373678e-01 -0.026331 -1.110000  0.760386 -0.887858  2.731569e-01   \n",
       "3  4.557322e-01  1.253338 -1.441711 -1.586810  1.421010 -7.190751e-01   \n",
       "4  1.092801e+00 -1.409453  0.416555  0.142690 -1.260314  2.298233e+00   \n",
       "\n",
       "           x830  \n",
       "0  9.233435e-01  \n",
       "1  1.029284e+00  \n",
       "2 -5.722800e-01  \n",
       "3  2.628537e-01  \n",
       "4 -2.105964e-14  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select appropriate features for new dataframe\n",
    "\n",
    "# np.count_nonzero(sel.get_support())\n",
    "\n",
    "selected_feat = xtrain_without_outliers.columns[(sel.get_support())]\n",
    "xtrain_without_outliers_RF = xtrain_without_outliers.loc[:,selected_feat]\n",
    "xtest_RF = xtest.loc[:,selected_feat]\n",
    "xtrain_without_outliers_RF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a linear regression on these features with outliers removed with PCA method\n",
    "\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(xtrain_without_outliers_RF, ytrain_without_outliers)\n",
    "\n",
    "# Fill in missing values as mean\n",
    "xtest_RF = xtest_RF.fillna(xtest_RF.mean())\n",
    "\n",
    "y_pred = reg_model.predict(xtest_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.read_csv(\"sample.csv\")\n",
    "index.head()\n",
    "index['y'] = y_pred[:,1]\n",
    "index.head()\n",
    "index.to_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False, False,  True,  True, False,\n",
       "        True, False,  True, False, False,  True, False, False,  True,\n",
       "        True,  True,  True, False, False, False, False, False, False,\n",
       "        True, False,  True,  True,  True, False, False, False, False,\n",
       "        True,  True, False, False,  True, False, False,  True, False,\n",
       "       False,  True, False, False,  True, False,  True,  True,  True,\n",
       "       False,  True, False, False, False, False,  True, False,  True,\n",
       "        True, False, False, False,  True,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "        True,  True, False, False, False,  True, False,  True, False,\n",
       "        True,  True,  True,  True,  True, False,  True, False, False,\n",
       "       False,  True, False, False, False,  True,  True,  True, False,\n",
       "       False,  True,  True, False, False,  True,  True, False,  True,\n",
       "       False,  True,  True,  True, False, False, False, False, False,\n",
       "        True,  True,  True,  True, False, False, False,  True, False,\n",
       "       False,  True, False,  True, False, False, False,  True,  True,\n",
       "       False, False, False,  True,  True, False, False, False,  True,\n",
       "       False, False,  True, False,  True,  True, False, False,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        True, False,  True, False, False,  True,  True,  True,  True,\n",
       "       False, False, False,  True,  True,  True,  True, False,  True,\n",
       "       False,  True,  True,  True, False, False,  True, False, False,\n",
       "       False, False,  True, False,  True,  True, False, False,  True,\n",
       "       False, False,  True, False,  True, False, False, False,  True,\n",
       "       False, False, False,  True, False,  True,  True,  True, False,\n",
       "       False,  True, False, False,  True, False, False, False,  True,\n",
       "       False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True, False, False, False, False,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True, False, False, False,  True, False,  True,  True, False,\n",
       "        True, False, False, False, False,  True,  True,  True, False,\n",
       "        True, False, False,  True,  True, False,  True, False,  True,\n",
       "        True,  True,  True, False, False, False,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True, False, False, False, False, False,  True, False,\n",
       "        True, False, False, False,  True,  True,  True,  True, False,\n",
       "       False, False, False,  True, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False,  True, False, False,  True,  True,\n",
       "        True, False, False,  True,  True, False,  True, False,  True,\n",
       "       False, False,  True, False,  True,  True,  True, False, False,\n",
       "        True,  True, False,  True,  True, False, False,  True,  True,\n",
       "       False, False, False,  True,  True, False, False, False, False,\n",
       "        True, False, False, False, False])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest again\n",
    "\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
    "sel.fit(xtrain_without_outliers_RF, ytrain_without_outliers)\n",
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x2</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x14</th>\n",
       "      <th>x18</th>\n",
       "      <th>x24</th>\n",
       "      <th>x37</th>\n",
       "      <th>x39</th>\n",
       "      <th>x41</th>\n",
       "      <th>...</th>\n",
       "      <th>x773</th>\n",
       "      <th>x782</th>\n",
       "      <th>x787</th>\n",
       "      <th>x791</th>\n",
       "      <th>x794</th>\n",
       "      <th>x801</th>\n",
       "      <th>x809</th>\n",
       "      <th>x814</th>\n",
       "      <th>x816</th>\n",
       "      <th>x825</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.003789e+00</td>\n",
       "      <td>-1.886600</td>\n",
       "      <td>1.408577</td>\n",
       "      <td>-0.736072</td>\n",
       "      <td>4.711032e-02</td>\n",
       "      <td>3.281678e-01</td>\n",
       "      <td>0.376055</td>\n",
       "      <td>-1.026995</td>\n",
       "      <td>-0.560090</td>\n",
       "      <td>-0.080355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633884</td>\n",
       "      <td>0.651819</td>\n",
       "      <td>1.539246</td>\n",
       "      <td>0.163994</td>\n",
       "      <td>-0.762699</td>\n",
       "      <td>0.415885</td>\n",
       "      <td>5.489406e-16</td>\n",
       "      <td>0.167924</td>\n",
       "      <td>-0.380652</td>\n",
       "      <td>0.313682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.170291e-15</td>\n",
       "      <td>-0.216914</td>\n",
       "      <td>-1.018184</td>\n",
       "      <td>-0.384914</td>\n",
       "      <td>-4.022581e-01</td>\n",
       "      <td>-6.116587e-15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061051</td>\n",
       "      <td>1.292454</td>\n",
       "      <td>-1.122602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104768</td>\n",
       "      <td>0.989155</td>\n",
       "      <td>0.555404</td>\n",
       "      <td>0.649498</td>\n",
       "      <td>0.367144</td>\n",
       "      <td>-0.655561</td>\n",
       "      <td>5.489406e-16</td>\n",
       "      <td>-1.427364</td>\n",
       "      <td>1.594495</td>\n",
       "      <td>-0.034465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.986002e-01</td>\n",
       "      <td>-0.706509</td>\n",
       "      <td>0.428261</td>\n",
       "      <td>1.996995</td>\n",
       "      <td>-1.148263e+00</td>\n",
       "      <td>-2.101050e-01</td>\n",
       "      <td>-1.972749</td>\n",
       "      <td>0.360240</td>\n",
       "      <td>-1.248835</td>\n",
       "      <td>0.045547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140288</td>\n",
       "      <td>0.584193</td>\n",
       "      <td>1.101161</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.396022</td>\n",
       "      <td>1.776119</td>\n",
       "      <td>6.952155e+00</td>\n",
       "      <td>1.746492</td>\n",
       "      <td>1.532391</td>\n",
       "      <td>-1.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.572892e-01</td>\n",
       "      <td>2.104230</td>\n",
       "      <td>-0.697834</td>\n",
       "      <td>-0.356636</td>\n",
       "      <td>4.512638e-15</td>\n",
       "      <td>3.128715e-01</td>\n",
       "      <td>2.000645</td>\n",
       "      <td>1.000766</td>\n",
       "      <td>0.709561</td>\n",
       "      <td>0.736116</td>\n",
       "      <td>...</td>\n",
       "      <td>1.239880</td>\n",
       "      <td>0.898630</td>\n",
       "      <td>0.055772</td>\n",
       "      <td>0.388562</td>\n",
       "      <td>0.781972</td>\n",
       "      <td>0.152103</td>\n",
       "      <td>1.308535e-01</td>\n",
       "      <td>0.133475</td>\n",
       "      <td>-0.621358</td>\n",
       "      <td>-1.441711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.081925e-01</td>\n",
       "      <td>-0.291240</td>\n",
       "      <td>-0.867819</td>\n",
       "      <td>1.254977</td>\n",
       "      <td>-8.662420e-01</td>\n",
       "      <td>1.826061e-01</td>\n",
       "      <td>-1.175665</td>\n",
       "      <td>0.047107</td>\n",
       "      <td>-0.627111</td>\n",
       "      <td>1.718358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715285</td>\n",
       "      <td>-0.451640</td>\n",
       "      <td>1.154679</td>\n",
       "      <td>-0.305866</td>\n",
       "      <td>1.422301</td>\n",
       "      <td>-1.035144</td>\n",
       "      <td>1.556122e+00</td>\n",
       "      <td>0.303210</td>\n",
       "      <td>0.811482</td>\n",
       "      <td>0.416555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x0        x2       x10       x11           x14           x18  \\\n",
       "0  2.003789e+00 -1.886600  1.408577 -0.736072  4.711032e-02  3.281678e-01   \n",
       "1  3.170291e-15 -0.216914 -1.018184 -0.384914 -4.022581e-01 -6.116587e-15   \n",
       "2 -4.986002e-01 -0.706509  0.428261  1.996995 -1.148263e+00 -2.101050e-01   \n",
       "3  5.572892e-01  2.104230 -0.697834 -0.356636  4.512638e-15  3.128715e-01   \n",
       "4 -1.081925e-01 -0.291240 -0.867819  1.254977 -8.662420e-01  1.826061e-01   \n",
       "\n",
       "        x24       x37       x39       x41  ...      x773      x782      x787  \\\n",
       "0  0.376055 -1.026995 -0.560090 -0.080355  ...  0.633884  0.651819  1.539246   \n",
       "1  0.000000  0.061051  1.292454 -1.122602  ... -0.104768  0.989155  0.555404   \n",
       "2 -1.972749  0.360240 -1.248835  0.045547  ...  0.140288  0.584193  1.101161   \n",
       "3  2.000645  1.000766  0.709561  0.736116  ...  1.239880  0.898630  0.055772   \n",
       "4 -1.175665  0.047107 -0.627111  1.718358  ...  0.715285 -0.451640  1.154679   \n",
       "\n",
       "       x791      x794      x801          x809      x814      x816      x825  \n",
       "0  0.163994 -0.762699  0.415885  5.489406e-16  0.167924 -0.380652  0.313682  \n",
       "1  0.649498  0.367144 -0.655561  5.489406e-16 -1.427364  1.594495 -0.034465  \n",
       "2  0.173387  0.396022  1.776119  6.952155e+00  1.746492  1.532391 -1.110000  \n",
       "3  0.388562  0.781972  0.152103  1.308535e-01  0.133475 -0.621358 -1.441711  \n",
       "4 -0.305866  1.422301 -1.035144  1.556122e+00  0.303210  0.811482  0.416555  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features for df again\n",
    "\n",
    "selected_feat = xtrain_without_outliers_RF.columns[(sel.get_support())]\n",
    "xtrain_without_outliers_RF2 = xtrain_without_outliers_RF.loc[:,selected_feat]\n",
    "xtest_RF2 = xtest_RF.loc[:,selected_feat]\n",
    "xtrain_without_outliers_RF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1139, 196)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_without_outliers_RF2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[675.58955349,  67.6342441 ],\n",
       "       [869.50040595,  76.34641447],\n",
       "       [569.39681958,  86.22371938],\n",
       "       ...,\n",
       "       [601.53001501,  78.47546386],\n",
       "       [723.80184063,  66.85009264],\n",
       "       [675.01999484,  66.60895593]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a linear regression on these features with outliers removed with PCA method (AGAIN)\n",
    "\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(xtrain_without_outliers_RF2, ytrain_without_outliers)\n",
    "\n",
    "y_pred = reg_model.predict(xtest_RF2)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.read_csv(\"sample.csv\")\n",
    "index.head()\n",
    "index['y'] = y_pred[:,1]\n",
    "index.head()\n",
    "index.to_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09678430863980143,\n",
       " 0.11514872364922273,\n",
       " 0.1345197674752714,\n",
       " 0.12530447364016772,\n",
       " 0.09964260067864354,\n",
       " 0.1152423036597698,\n",
       " 0.12005443393809787,\n",
       " 0.11486675699427111,\n",
       " 0.11761893511698684,\n",
       " 0.12757964610259634,\n",
       " 0.13305007929276425,\n",
       " 0.17651338065409822,\n",
       " 0.19694058046865587,\n",
       " 0.24039481637697238,\n",
       " 0.22993533444439967,\n",
       " 0.18705719715103436]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to array\n",
    "xtrain_without_outliers_RF2_arr = xtrain_without_outliers_RF2.values\n",
    "ytrain_without_outliers_arr = ytrain_without_outliers.values\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "alphas = np.array([0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000, 3000, 10000])\n",
    "meanscores = []\n",
    "for i in alphas:\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(xtrain_without_outliers_RF2_arr):\n",
    "        X_train = xtrain_without_outliers_RF2_arr[train_index]\n",
    "        X_test = xtrain_without_outliers_RF2_arr[test_index]\n",
    "        y_train = ytrain_without_outliers_arr[train_index]\n",
    "        y_test = ytrain_without_outliers_arr[test_index]\n",
    "        \n",
    "        clf = Ridge(alpha=i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        Y_pred = clf.predict(X_test)\n",
    "        scores.append(r2_score(y_test, Y_pred))\n",
    "        \n",
    "    meanscores.append(np.mean(scores))\n",
    "\n",
    "meanscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-081f1e1829c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mytrain_without_outliers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxtrain_without_outliers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m scores = cross_val_score(estimator = model, X = xtrain_without_outliers, y = ytrain_without_outliers,\n\u001b[0m\u001b[1;32m      3\u001b[0m                          scoring = 'r2', cv = 10) \n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Validation score {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Std Validation score {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators = 500).fit(y = ytrain_without_outliers, X = xtrain_without_outliers)\n",
    "scores = cross_val_score(estimator = model, X = xtrain_without_outliers, y = ytrain_without_outliers,\n",
    "                         scoring = 'r2', cv = 10) \n",
    "print(\"Mean Validation score {}\".format(np.mean(scores)))\n",
    "print(\"Std Validation score {}\".format(np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09869328 0.04271685 0.01002965 0.00832936 0.00676061 0.00610477\n",
      " 0.00572094 0.00478307 0.00458512 0.00410277 0.00389032 0.00370189\n",
      " 0.00358116 0.00355205 0.00353074 0.00345958 0.00344656 0.00341194\n",
      " 0.00338798 0.00336516 0.00335068 0.00332545 0.00330704 0.00329179\n",
      " 0.00325972 0.00323451 0.00321422 0.00319979 0.00318385 0.00316625\n",
      " 0.00315776 0.00312593 0.00310481 0.0030889  0.0030684  0.00304852\n",
      " 0.00303571 0.00301466 0.00298921 0.00298126 0.00297036 0.00296219\n",
      " 0.00293459 0.00292703 0.00291045 0.00288832 0.00287955 0.00285896\n",
      " 0.00284865 0.00282904 0.00282211 0.00281752 0.00278729 0.00277112\n",
      " 0.00275815 0.00274447 0.00274044 0.00271808 0.00270057 0.00268437\n",
      " 0.00267871 0.00266346 0.0026527  0.00263163 0.00261803 0.00260673\n",
      " 0.00259161 0.00258961 0.00257873 0.00256672 0.0025495  0.00254265\n",
      " 0.00253481 0.00252258 0.00249778 0.00248679 0.00246584 0.00244785\n",
      " 0.0024358  0.00243263 0.00241796 0.0024055  0.00238077 0.0023673\n",
      " 0.00235606 0.00233918 0.00233195 0.00231122 0.00229754 0.00229122\n",
      " 0.00227288 0.00226089 0.00223903 0.00222665 0.00221573 0.00220594\n",
      " 0.00219117 0.00219013 0.00217012 0.00213667]\n"
     ]
    }
   ],
   "source": [
    "# IGNORE\n",
    "# PCA with more PC's\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "principal_components = pca.fit_transform(xtrain_scaled)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1212"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tried another outlier detection technique but difficult to tune parameters\n",
    "\n",
    "clustering = DBSCAN(eps=1, min_samples=10).fit(xtrain_scaled)\n",
    "np.count_nonzero(clustering.labels_ == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEW TRY, RUN FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118345.392781</td>\n",
       "      <td>3104.010883</td>\n",
       "      <td>82378.542430</td>\n",
       "      <td>1086.678601</td>\n",
       "      <td>11395.883550</td>\n",
       "      <td>10.455601</td>\n",
       "      <td>109886.476608</td>\n",
       "      <td>1.054926e+06</td>\n",
       "      <td>101877.946528</td>\n",
       "      <td>2.550290</td>\n",
       "      <td>...</td>\n",
       "      <td>10.769524</td>\n",
       "      <td>10.245068</td>\n",
       "      <td>1021.907543</td>\n",
       "      <td>1031.645762</td>\n",
       "      <td>107440.039766</td>\n",
       "      <td>107083.296966</td>\n",
       "      <td>5559.203921</td>\n",
       "      <td>10.861464</td>\n",
       "      <td>107548.413675</td>\n",
       "      <td>2.299202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5889.055991</td>\n",
       "      <td>97932.067482</td>\n",
       "      <td>1116.564363</td>\n",
       "      <td>12172.212426</td>\n",
       "      <td>10.502997</td>\n",
       "      <td>100372.504488</td>\n",
       "      <td>1.011783e+06</td>\n",
       "      <td>108852.296962</td>\n",
       "      <td>2.579040</td>\n",
       "      <td>...</td>\n",
       "      <td>10.859822</td>\n",
       "      <td>10.088023</td>\n",
       "      <td>988.135968</td>\n",
       "      <td>999.044639</td>\n",
       "      <td>105238.779040</td>\n",
       "      <td>106365.468525</td>\n",
       "      <td>10334.091649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107841.227180</td>\n",
       "      <td>2.472763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95373.022035</td>\n",
       "      <td>6293.442455</td>\n",
       "      <td>93371.369288</td>\n",
       "      <td>1034.722073</td>\n",
       "      <td>11618.142107</td>\n",
       "      <td>10.947611</td>\n",
       "      <td>109337.757279</td>\n",
       "      <td>1.006491e+06</td>\n",
       "      <td>104540.883376</td>\n",
       "      <td>2.573247</td>\n",
       "      <td>...</td>\n",
       "      <td>10.356015</td>\n",
       "      <td>10.514234</td>\n",
       "      <td>995.480813</td>\n",
       "      <td>898.329758</td>\n",
       "      <td>107044.005199</td>\n",
       "      <td>102704.104686</td>\n",
       "      <td>7697.875887</td>\n",
       "      <td>10.277760</td>\n",
       "      <td>103414.594212</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105066.272301</td>\n",
       "      <td>3279.162164</td>\n",
       "      <td>119554.079514</td>\n",
       "      <td>1114.014483</td>\n",
       "      <td>12127.235755</td>\n",
       "      <td>10.540204</td>\n",
       "      <td>106215.391332</td>\n",
       "      <td>1.022381e+06</td>\n",
       "      <td>109597.474506</td>\n",
       "      <td>2.693256</td>\n",
       "      <td>...</td>\n",
       "      <td>10.609811</td>\n",
       "      <td>10.991861</td>\n",
       "      <td>1117.179063</td>\n",
       "      <td>867.267810</td>\n",
       "      <td>100617.082858</td>\n",
       "      <td>108893.304959</td>\n",
       "      <td>6549.131099</td>\n",
       "      <td>9.337688</td>\n",
       "      <td>105722.857008</td>\n",
       "      <td>2.484935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98957.033333</td>\n",
       "      <td>4177.482190</td>\n",
       "      <td>97239.708338</td>\n",
       "      <td>1049.430921</td>\n",
       "      <td>10417.250336</td>\n",
       "      <td>10.618957</td>\n",
       "      <td>102736.470171</td>\n",
       "      <td>1.086871e+06</td>\n",
       "      <td>103340.057448</td>\n",
       "      <td>2.540610</td>\n",
       "      <td>...</td>\n",
       "      <td>10.397777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>863.943966</td>\n",
       "      <td>1041.278922</td>\n",
       "      <td>105352.672454</td>\n",
       "      <td>101705.692839</td>\n",
       "      <td>5388.312773</td>\n",
       "      <td>12.196382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.930136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x0           x1             x2           x3            x4  \\\n",
       "0  118345.392781  3104.010883   82378.542430  1086.678601  11395.883550   \n",
       "1            NaN  5889.055991   97932.067482  1116.564363  12172.212426   \n",
       "2   95373.022035  6293.442455   93371.369288  1034.722073  11618.142107   \n",
       "3  105066.272301  3279.162164  119554.079514  1114.014483  12127.235755   \n",
       "4   98957.033333  4177.482190   97239.708338  1049.430921  10417.250336   \n",
       "\n",
       "          x5             x6            x7             x8        x9  ...  \\\n",
       "0  10.455601  109886.476608  1.054926e+06  101877.946528  2.550290  ...   \n",
       "1  10.502997  100372.504488  1.011783e+06  108852.296962  2.579040  ...   \n",
       "2  10.947611  109337.757279  1.006491e+06  104540.883376  2.573247  ...   \n",
       "3  10.540204  106215.391332  1.022381e+06  109597.474506  2.693256  ...   \n",
       "4  10.618957  102736.470171  1.086871e+06  103340.057448  2.540610  ...   \n",
       "\n",
       "        x822       x823         x824         x825           x826  \\\n",
       "0  10.769524  10.245068  1021.907543  1031.645762  107440.039766   \n",
       "1  10.859822  10.088023   988.135968   999.044639  105238.779040   \n",
       "2  10.356015  10.514234   995.480813   898.329758  107044.005199   \n",
       "3  10.609811  10.991861  1117.179063   867.267810  100617.082858   \n",
       "4  10.397777        NaN   863.943966  1041.278922  105352.672454   \n",
       "\n",
       "            x827          x828       x829           x830      x831  \n",
       "0  107083.296966   5559.203921  10.861464  107548.413675  2.299202  \n",
       "1  106365.468525  10334.091649        NaN  107841.227180  2.472763  \n",
       "2  102704.104686   7697.875887  10.277760  103414.594212       NaN  \n",
       "3  108893.304959   6549.131099   9.337688  105722.857008  2.484935  \n",
       "4  101705.692839   5388.312773  12.196382            NaN  1.930136  \n",
       "\n",
       "[5 rows x 832 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = pd.read_csv(\"X_train.csv\")\n",
    "xtrain = xtrain.iloc[:, 1:]\n",
    "xtest = pd.read_csv(\"X_test.csv\")\n",
    "xtest = xtest.iloc[:, 1:]\n",
    "ytrain = pd.read_csv(\"Y_train.csv\")\n",
    "\n",
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118345.392781</td>\n",
       "      <td>3104.010883</td>\n",
       "      <td>82378.542430</td>\n",
       "      <td>1086.678601</td>\n",
       "      <td>11395.883550</td>\n",
       "      <td>10.455601</td>\n",
       "      <td>109886.476608</td>\n",
       "      <td>1.054926e+06</td>\n",
       "      <td>101877.946528</td>\n",
       "      <td>2.550290</td>\n",
       "      <td>...</td>\n",
       "      <td>10.769524</td>\n",
       "      <td>10.245068</td>\n",
       "      <td>1021.907543</td>\n",
       "      <td>1031.645762</td>\n",
       "      <td>107440.039766</td>\n",
       "      <td>107083.296966</td>\n",
       "      <td>5559.203921</td>\n",
       "      <td>10.861464</td>\n",
       "      <td>107548.413675</td>\n",
       "      <td>2.299202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99950.259599</td>\n",
       "      <td>5889.055991</td>\n",
       "      <td>97932.067482</td>\n",
       "      <td>1116.564363</td>\n",
       "      <td>12172.212426</td>\n",
       "      <td>10.502997</td>\n",
       "      <td>100372.504488</td>\n",
       "      <td>1.011783e+06</td>\n",
       "      <td>108852.296962</td>\n",
       "      <td>2.579040</td>\n",
       "      <td>...</td>\n",
       "      <td>10.859822</td>\n",
       "      <td>10.088023</td>\n",
       "      <td>988.135968</td>\n",
       "      <td>999.044639</td>\n",
       "      <td>105238.779040</td>\n",
       "      <td>106365.468525</td>\n",
       "      <td>10334.091649</td>\n",
       "      <td>10.018963</td>\n",
       "      <td>107841.227180</td>\n",
       "      <td>2.472763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95373.022035</td>\n",
       "      <td>6293.442455</td>\n",
       "      <td>93371.369288</td>\n",
       "      <td>1034.722073</td>\n",
       "      <td>11618.142107</td>\n",
       "      <td>10.947611</td>\n",
       "      <td>109337.757279</td>\n",
       "      <td>1.006491e+06</td>\n",
       "      <td>104540.883376</td>\n",
       "      <td>2.573247</td>\n",
       "      <td>...</td>\n",
       "      <td>10.356015</td>\n",
       "      <td>10.514234</td>\n",
       "      <td>995.480813</td>\n",
       "      <td>898.329758</td>\n",
       "      <td>107044.005199</td>\n",
       "      <td>102704.104686</td>\n",
       "      <td>7697.875887</td>\n",
       "      <td>10.277760</td>\n",
       "      <td>103414.594212</td>\n",
       "      <td>2.273542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105066.272301</td>\n",
       "      <td>3279.162164</td>\n",
       "      <td>119554.079514</td>\n",
       "      <td>1114.014483</td>\n",
       "      <td>12127.235755</td>\n",
       "      <td>10.540204</td>\n",
       "      <td>106215.391332</td>\n",
       "      <td>1.022381e+06</td>\n",
       "      <td>109597.474506</td>\n",
       "      <td>2.693256</td>\n",
       "      <td>...</td>\n",
       "      <td>10.609811</td>\n",
       "      <td>10.991861</td>\n",
       "      <td>1117.179063</td>\n",
       "      <td>867.267810</td>\n",
       "      <td>100617.082858</td>\n",
       "      <td>108893.304959</td>\n",
       "      <td>6549.131099</td>\n",
       "      <td>9.337688</td>\n",
       "      <td>105722.857008</td>\n",
       "      <td>2.484935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98957.033333</td>\n",
       "      <td>4177.482190</td>\n",
       "      <td>97239.708338</td>\n",
       "      <td>1049.430921</td>\n",
       "      <td>10417.250336</td>\n",
       "      <td>10.618957</td>\n",
       "      <td>102736.470171</td>\n",
       "      <td>1.086871e+06</td>\n",
       "      <td>103340.057448</td>\n",
       "      <td>2.540610</td>\n",
       "      <td>...</td>\n",
       "      <td>10.397777</td>\n",
       "      <td>10.549044</td>\n",
       "      <td>863.943966</td>\n",
       "      <td>1041.278922</td>\n",
       "      <td>105352.672454</td>\n",
       "      <td>101705.692839</td>\n",
       "      <td>5388.312773</td>\n",
       "      <td>12.196382</td>\n",
       "      <td>104996.343999</td>\n",
       "      <td>1.930136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x0           x1             x2           x3            x4  \\\n",
       "0  118345.392781  3104.010883   82378.542430  1086.678601  11395.883550   \n",
       "1   99950.259599  5889.055991   97932.067482  1116.564363  12172.212426   \n",
       "2   95373.022035  6293.442455   93371.369288  1034.722073  11618.142107   \n",
       "3  105066.272301  3279.162164  119554.079514  1114.014483  12127.235755   \n",
       "4   98957.033333  4177.482190   97239.708338  1049.430921  10417.250336   \n",
       "\n",
       "          x5             x6            x7             x8        x9  ...  \\\n",
       "0  10.455601  109886.476608  1.054926e+06  101877.946528  2.550290  ...   \n",
       "1  10.502997  100372.504488  1.011783e+06  108852.296962  2.579040  ...   \n",
       "2  10.947611  109337.757279  1.006491e+06  104540.883376  2.573247  ...   \n",
       "3  10.540204  106215.391332  1.022381e+06  109597.474506  2.693256  ...   \n",
       "4  10.618957  102736.470171  1.086871e+06  103340.057448  2.540610  ...   \n",
       "\n",
       "        x822       x823         x824         x825           x826  \\\n",
       "0  10.769524  10.245068  1021.907543  1031.645762  107440.039766   \n",
       "1  10.859822  10.088023   988.135968   999.044639  105238.779040   \n",
       "2  10.356015  10.514234   995.480813   898.329758  107044.005199   \n",
       "3  10.609811  10.991861  1117.179063   867.267810  100617.082858   \n",
       "4  10.397777  10.549044   863.943966  1041.278922  105352.672454   \n",
       "\n",
       "            x827          x828       x829           x830      x831  \n",
       "0  107083.296966   5559.203921  10.861464  107548.413675  2.299202  \n",
       "1  106365.468525  10334.091649  10.018963  107841.227180  2.472763  \n",
       "2  102704.104686   7697.875887  10.277760  103414.594212  2.273542  \n",
       "3  108893.304959   6549.131099   9.337688  105722.857008  2.484935  \n",
       "4  101705.692839   5388.312773  12.196382  104996.343999  1.930136  \n",
       "\n",
       "[5 rows x 832 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treat missing values as column medians. Important (apparently) to use the medians from the training set in the test set\n",
    "\n",
    "xtrain = xtrain.fillna(xtrain.mean())\n",
    "xtest = xtest.fillna(xtrain.mean())\n",
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and test data\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "xtrain_scaled = scaler.fit_transform(xtrain)\n",
    "xtrain = pd.DataFrame(xtrain_scaled, columns = xtrain.columns)\n",
    "xtrain.head()\n",
    "\n",
    "xtest_scaled = scaler.fit_transform(xtest)\n",
    "xtest = pd.DataFrame(xtest_scaled, columns = xtest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y\n",
       "0  75.0\n",
       "1  53.0\n",
       "2  78.0\n",
       "3  65.0\n",
       "4  86.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove unnecessary id column from ytrain that just ***** things up\n",
    "\n",
    "ytrain1 = ytrain.loc[:, \"y\"]\n",
    "ytrain2 = pd.DataFrame(data = ytrain1.values, columns= ['y'])\n",
    "#ytrain2.head()\n",
    "ytrain = ytrain2\n",
    "ytrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09869328 0.04271685]\n"
     ]
    }
   ],
   "source": [
    "# PCA with 2 remaining features/components\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(xtrain)\n",
    "xpca = pd.DataFrame(data = principal_components, columns = ['PC1', 'PC2'])\n",
    "\n",
    "plt.scatter(xpca['PC1'], xpca['PC2'], alpha=0.5)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.plot([-18, -18], [-30, 30], marker='o')\n",
    "plt.plot([22, 22], [-30, 30], marker='o')\n",
    "plt.plot([-45, 45], [-13, -13], marker='o')\n",
    "plt.plot([-45, 45], [12, 12], marker='o')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "per_var = np.round(pca.explained_variance_ratio_ * 100, decimals=1)\n",
    "labels = ['PC' + str(x) for x in range(1, len(per_var) + 1)]\n",
    "plt.bar(x=range(1, len(per_var)+1), height=per_var, tick_label=labels)\n",
    "plt.ylabel('percentange of explained variance')\n",
    "plt.xlabel('principal component')\n",
    "plt.title('scree plot')\n",
    "plt.show()\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.003789e+00</td>\n",
       "      <td>-0.655849</td>\n",
       "      <td>-1.886600</td>\n",
       "      <td>0.916929</td>\n",
       "      <td>1.455717</td>\n",
       "      <td>-0.393113</td>\n",
       "      <td>1.842526</td>\n",
       "      <td>0.207068</td>\n",
       "      <td>-1.112314</td>\n",
       "      <td>0.276588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>-1.110028e+00</td>\n",
       "      <td>0.251549</td>\n",
       "      <td>0.313682</td>\n",
       "      <td>0.905023</td>\n",
       "      <td>0.745790</td>\n",
       "      <td>-0.944838</td>\n",
       "      <td>8.892476e-01</td>\n",
       "      <td>9.233435e-01</td>\n",
       "      <td>1.579906e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.170291e-15</td>\n",
       "      <td>2.403925</td>\n",
       "      <td>-0.216914</td>\n",
       "      <td>1.232632</td>\n",
       "      <td>2.267203</td>\n",
       "      <td>-0.214877</td>\n",
       "      <td>-1.736539</td>\n",
       "      <td>-1.383793</td>\n",
       "      <td>1.477503</td>\n",
       "      <td>0.468797</td>\n",
       "      <td>...</td>\n",
       "      <td>1.152094</td>\n",
       "      <td>-1.683506e+00</td>\n",
       "      <td>-0.103563</td>\n",
       "      <td>-0.034465</td>\n",
       "      <td>0.101094</td>\n",
       "      <td>0.478006</td>\n",
       "      <td>2.612417</td>\n",
       "      <td>-7.499671e-15</td>\n",
       "      <td>1.029284e+00</td>\n",
       "      <td>1.226602e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.986002e-01</td>\n",
       "      <td>2.848202</td>\n",
       "      <td>-0.706509</td>\n",
       "      <td>0.368077</td>\n",
       "      <td>1.688041</td>\n",
       "      <td>1.457136</td>\n",
       "      <td>1.636103</td>\n",
       "      <td>-1.578900</td>\n",
       "      <td>-0.123474</td>\n",
       "      <td>0.430067</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.701345</td>\n",
       "      <td>-1.271165e-01</td>\n",
       "      <td>-0.026331</td>\n",
       "      <td>-1.110000</td>\n",
       "      <td>0.760386</td>\n",
       "      <td>-0.887858</td>\n",
       "      <td>0.648457</td>\n",
       "      <td>2.731569e-01</td>\n",
       "      <td>-5.722800e-01</td>\n",
       "      <td>1.093697e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.572892e-01</td>\n",
       "      <td>-0.463420</td>\n",
       "      <td>2.104230</td>\n",
       "      <td>1.205696</td>\n",
       "      <td>2.220190</td>\n",
       "      <td>-0.074959</td>\n",
       "      <td>0.461499</td>\n",
       "      <td>-0.993009</td>\n",
       "      <td>1.754213</td>\n",
       "      <td>1.232371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232337</td>\n",
       "      <td>1.617028e+00</td>\n",
       "      <td>1.253338</td>\n",
       "      <td>-1.441711</td>\n",
       "      <td>-1.586810</td>\n",
       "      <td>1.421010</td>\n",
       "      <td>-0.207350</td>\n",
       "      <td>-7.190751e-01</td>\n",
       "      <td>2.628537e-01</td>\n",
       "      <td>1.301543e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.081925e-01</td>\n",
       "      <td>0.523514</td>\n",
       "      <td>-0.291240</td>\n",
       "      <td>0.523456</td>\n",
       "      <td>0.432765</td>\n",
       "      <td>0.221201</td>\n",
       "      <td>-0.847238</td>\n",
       "      <td>1.384981</td>\n",
       "      <td>-0.569382</td>\n",
       "      <td>0.211873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.547710</td>\n",
       "      <td>-7.135373e-14</td>\n",
       "      <td>-1.409453</td>\n",
       "      <td>0.416555</td>\n",
       "      <td>0.142690</td>\n",
       "      <td>-1.260314</td>\n",
       "      <td>-1.072150</td>\n",
       "      <td>2.298233e+00</td>\n",
       "      <td>-2.105964e-14</td>\n",
       "      <td>-2.114335e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  2.003789e+00 -0.655849 -1.886600  0.916929  1.455717 -0.393113  1.842526   \n",
       "1  3.170291e-15  2.403925 -0.216914  1.232632  2.267203 -0.214877 -1.736539   \n",
       "2 -4.986002e-01  2.848202 -0.706509  0.368077  1.688041  1.457136  1.636103   \n",
       "3  5.572892e-01 -0.463420  2.104230  1.205696  2.220190 -0.074959  0.461499   \n",
       "4 -1.081925e-01  0.523514 -0.291240  0.523456  0.432765  0.221201 -0.847238   \n",
       "\n",
       "         x7        x8        x9  ...      x822          x823      x824  \\\n",
       "0  0.207068 -1.112314  0.276588  ...  0.819901 -1.110028e+00  0.251549   \n",
       "1 -1.383793  1.477503  0.468797  ...  1.152094 -1.683506e+00 -0.103563   \n",
       "2 -1.578900 -0.123474  0.430067  ... -0.701345 -1.271165e-01 -0.026331   \n",
       "3 -0.993009  1.754213  1.232371  ...  0.232337  1.617028e+00  1.253338   \n",
       "4  1.384981 -0.569382  0.211873  ... -0.547710 -7.135373e-14 -1.409453   \n",
       "\n",
       "       x825      x826      x827      x828          x829          x830  \\\n",
       "0  0.313682  0.905023  0.745790 -0.944838  8.892476e-01  9.233435e-01   \n",
       "1 -0.034465  0.101094  0.478006  2.612417 -7.499671e-15  1.029284e+00   \n",
       "2 -1.110000  0.760386 -0.887858  0.648457  2.731569e-01 -5.722800e-01   \n",
       "3 -1.441711 -1.586810  1.421010 -0.207350 -7.190751e-01  2.628537e-01   \n",
       "4  0.416555  0.142690 -1.260314 -1.072150  2.298233e+00 -2.105964e-14   \n",
       "\n",
       "           x831  \n",
       "0  1.579906e-01  \n",
       "1  1.226602e+00  \n",
       "2  1.093697e-14  \n",
       "3  1.301543e+00  \n",
       "4 -2.114335e+00  \n",
       "\n",
       "[5 rows x 832 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highly ad hoc way of removing outliers based on PCA plot above\n",
    "\n",
    "outliers = (xpca['PC1'] <= 22) & (xpca['PC1'] >= -18) & (xpca['PC2'] <= 12) & (xpca['PC2'] >= -13)\n",
    "print(np.count_nonzero(outliers))\n",
    "xtrain_without_outliers = xtrain[outliers]\n",
    "ytrain_without_outliers = ytrain[outliers]\n",
    "xtrain_without_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreasopedaleriksson/Applications/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/from_model.py:196: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True, False,  True,  True, False,  True,\n",
       "       False,  True,  True, False,  True, False, False,  True, False,\n",
       "        True, False,  True,  True, False, False,  True, False,  True,\n",
       "        True, False, False, False,  True, False, False,  True,  True,\n",
       "        True, False,  True,  True, False,  True,  True,  True, False,\n",
       "        True,  True, False,  True, False, False,  True,  True, False,\n",
       "        True, False,  True, False, False, False,  True, False,  True,\n",
       "        True,  True, False, False, False,  True,  True,  True, False,\n",
       "       False, False,  True, False, False,  True,  True,  True, False,\n",
       "       False,  True,  True,  True,  True,  True, False, False,  True,\n",
       "        True, False,  True, False,  True,  True, False,  True,  True,\n",
       "       False,  True,  True, False,  True, False,  True, False,  True,\n",
       "       False, False, False, False,  True, False, False,  True, False,\n",
       "       False,  True,  True, False, False, False, False, False,  True,\n",
       "        True, False,  True, False,  True,  True, False, False, False,\n",
       "       False, False, False, False,  True, False,  True, False, False,\n",
       "       False, False, False,  True,  True, False, False,  True,  True,\n",
       "       False, False,  True,  True,  True, False,  True, False, False,\n",
       "       False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "       False, False, False, False,  True, False, False,  True,  True,\n",
       "       False,  True, False,  True,  True, False,  True,  True,  True,\n",
       "       False,  True, False,  True, False,  True, False,  True, False,\n",
       "        True, False,  True,  True, False, False, False, False, False,\n",
       "       False,  True,  True, False,  True, False,  True,  True, False,\n",
       "       False,  True,  True, False, False, False,  True,  True, False,\n",
       "       False,  True, False, False,  True, False,  True,  True,  True,\n",
       "       False, False, False, False,  True, False,  True, False,  True,\n",
       "       False, False,  True, False,  True, False,  True, False,  True,\n",
       "        True, False, False, False, False, False,  True,  True, False,\n",
       "        True, False, False, False, False,  True, False,  True,  True,\n",
       "        True, False, False, False,  True,  True,  True, False, False,\n",
       "       False, False, False,  True, False,  True, False,  True, False,\n",
       "       False, False,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True, False, False,  True,  True,\n",
       "       False,  True,  True, False,  True, False, False,  True, False,\n",
       "        True, False, False, False, False, False,  True, False,  True,\n",
       "       False,  True,  True,  True,  True,  True, False, False,  True,\n",
       "       False,  True, False, False,  True,  True,  True,  True, False,\n",
       "       False,  True, False, False,  True, False, False,  True,  True,\n",
       "       False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True, False, False,  True,  True, False, False,\n",
       "       False,  True,  True,  True, False, False,  True, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False,  True, False,  True, False, False,  True,\n",
       "       False, False,  True,  True,  True,  True,  True, False, False,\n",
       "        True, False, False,  True,  True,  True, False, False, False,\n",
       "       False,  True, False, False,  True, False,  True, False,  True,\n",
       "       False, False,  True,  True,  True,  True, False, False,  True,\n",
       "        True,  True,  True,  True, False,  True, False, False, False,\n",
       "        True, False,  True, False, False,  True,  True,  True, False,\n",
       "        True,  True,  True, False, False,  True, False, False, False,\n",
       "       False, False,  True, False,  True, False,  True, False,  True,\n",
       "        True,  True, False,  True, False,  True, False, False,  True,\n",
       "       False,  True, False,  True,  True,  True, False, False,  True,\n",
       "        True, False, False,  True,  True,  True,  True,  True, False,\n",
       "       False, False, False,  True,  True,  True, False, False,  True,\n",
       "        True, False, False, False, False,  True, False, False,  True,\n",
       "       False, False,  True,  True, False, False,  True,  True, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "        True, False, False, False,  True, False, False,  True,  True,\n",
       "       False, False, False,  True,  True, False, False, False, False,\n",
       "       False,  True,  True,  True,  True, False,  True,  True, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False,  True, False,  True,  True, False, False, False,\n",
       "        True, False,  True, False, False,  True, False, False, False,\n",
       "       False,  True,  True, False, False,  True, False,  True,  True,\n",
       "        True,  True,  True, False,  True,  True, False,  True,  True,\n",
       "        True, False,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True, False,  True, False,  True, False, False,  True,\n",
       "        True, False, False, False,  True,  True,  True,  True, False,\n",
       "        True, False, False,  True, False,  True, False, False,  True,\n",
       "       False, False,  True, False, False, False, False,  True, False,\n",
       "        True, False,  True, False, False,  True, False, False,  True,\n",
       "       False,  True, False, False,  True,  True, False, False,  True,\n",
       "        True,  True, False, False,  True, False, False,  True, False,\n",
       "       False, False,  True,  True,  True, False, False, False, False,\n",
       "        True, False, False, False,  True,  True, False,  True,  True,\n",
       "       False, False, False,  True,  True,  True, False, False, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "       False, False, False, False,  True,  True, False, False,  True,\n",
       "       False,  True,  True, False, False,  True,  True,  True,  True,\n",
       "       False,  True, False,  True,  True, False, False, False, False,\n",
       "        True,  True, False, False, False,  True, False, False, False,\n",
       "       False,  True,  True, False, False,  True,  True, False,  True,\n",
       "        True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        True, False, False, False,  True, False, False, False,  True,\n",
       "        True, False, False,  True,  True, False, False, False,  True,\n",
       "       False, False, False, False, False,  True, False, False,  True,\n",
       "       False, False, False, False,  True, False,  True, False,  True,\n",
       "       False,  True,  True, False,  True, False,  True, False,  True,\n",
       "        True, False, False,  True, False, False, False,  True, False,\n",
       "       False,  True, False, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run random forest to select features\n",
    "\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100, max_features = 210))\n",
    "sel.fit(xtrain_without_outliers, ytrain_without_outliers)\n",
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x8</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x13</th>\n",
       "      <th>x16</th>\n",
       "      <th>...</th>\n",
       "      <th>x809</th>\n",
       "      <th>x811</th>\n",
       "      <th>x812</th>\n",
       "      <th>x814</th>\n",
       "      <th>x816</th>\n",
       "      <th>x818</th>\n",
       "      <th>x819</th>\n",
       "      <th>x822</th>\n",
       "      <th>x826</th>\n",
       "      <th>x829</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.001809</td>\n",
       "      <td>-1.881312</td>\n",
       "      <td>0.917417</td>\n",
       "      <td>-0.388651</td>\n",
       "      <td>1.845923</td>\n",
       "      <td>-1.112274</td>\n",
       "      <td>1.405990</td>\n",
       "      <td>-0.720986</td>\n",
       "      <td>0.799013</td>\n",
       "      <td>-1.220463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275974</td>\n",
       "      <td>-0.711160</td>\n",
       "      <td>-0.907511</td>\n",
       "      <td>0.165042</td>\n",
       "      <td>-0.381793</td>\n",
       "      <td>1.129595</td>\n",
       "      <td>1.480634</td>\n",
       "      <td>0.821172</td>\n",
       "      <td>0.903668</td>\n",
       "      <td>0.892698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026926</td>\n",
       "      <td>-0.211880</td>\n",
       "      <td>1.233120</td>\n",
       "      <td>-0.210434</td>\n",
       "      <td>-1.732886</td>\n",
       "      <td>1.477544</td>\n",
       "      <td>-1.020680</td>\n",
       "      <td>-0.370262</td>\n",
       "      <td>0.876290</td>\n",
       "      <td>1.497348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275974</td>\n",
       "      <td>0.612322</td>\n",
       "      <td>1.279295</td>\n",
       "      <td>-1.430155</td>\n",
       "      <td>1.593337</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>-1.313709</td>\n",
       "      <td>1.153362</td>\n",
       "      <td>0.099747</td>\n",
       "      <td>-0.039934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.500516</td>\n",
       "      <td>-0.701401</td>\n",
       "      <td>0.368566</td>\n",
       "      <td>1.461403</td>\n",
       "      <td>1.639515</td>\n",
       "      <td>-0.123433</td>\n",
       "      <td>0.425710</td>\n",
       "      <td>2.008697</td>\n",
       "      <td>-0.999652</td>\n",
       "      <td>1.714937</td>\n",
       "      <td>...</td>\n",
       "      <td>6.953003</td>\n",
       "      <td>0.288377</td>\n",
       "      <td>0.705373</td>\n",
       "      <td>1.743518</td>\n",
       "      <td>1.531234</td>\n",
       "      <td>0.686855</td>\n",
       "      <td>-0.114619</td>\n",
       "      <td>-0.700058</td>\n",
       "      <td>0.759032</td>\n",
       "      <td>0.276651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.555346</td>\n",
       "      <td>2.108910</td>\n",
       "      <td>1.206184</td>\n",
       "      <td>-0.070530</td>\n",
       "      <td>0.464995</td>\n",
       "      <td>1.754254</td>\n",
       "      <td>-0.700342</td>\n",
       "      <td>-0.342019</td>\n",
       "      <td>0.939278</td>\n",
       "      <td>0.116234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152069</td>\n",
       "      <td>1.544023</td>\n",
       "      <td>0.756629</td>\n",
       "      <td>0.130594</td>\n",
       "      <td>-0.622497</td>\n",
       "      <td>0.465814</td>\n",
       "      <td>-0.112038</td>\n",
       "      <td>0.233614</td>\n",
       "      <td>-1.588138</td>\n",
       "      <td>-0.715512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.110118</td>\n",
       "      <td>-0.286194</td>\n",
       "      <td>0.523945</td>\n",
       "      <td>0.225598</td>\n",
       "      <td>-0.843648</td>\n",
       "      <td>-0.569341</td>\n",
       "      <td>-0.870321</td>\n",
       "      <td>1.267598</td>\n",
       "      <td>-0.725764</td>\n",
       "      <td>-0.691801</td>\n",
       "      <td>...</td>\n",
       "      <td>1.573082</td>\n",
       "      <td>-0.500319</td>\n",
       "      <td>1.410043</td>\n",
       "      <td>0.300320</td>\n",
       "      <td>0.810331</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>-1.637788</td>\n",
       "      <td>-0.546425</td>\n",
       "      <td>0.141342</td>\n",
       "      <td>2.301585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x2        x3        x5        x6        x8       x10  \\\n",
       "0  2.001809 -1.881312  0.917417 -0.388651  1.845923 -1.112274  1.405990   \n",
       "1  0.026926 -0.211880  1.233120 -0.210434 -1.732886  1.477544 -1.020680   \n",
       "2 -0.500516 -0.701401  0.368566  1.461403  1.639515 -0.123433  0.425710   \n",
       "3  0.555346  2.108910  1.206184 -0.070530  0.464995  1.754254 -0.700342   \n",
       "4 -0.110118 -0.286194  0.523945  0.225598 -0.843648 -0.569341 -0.870321   \n",
       "\n",
       "        x11       x13       x16  ...      x809      x811      x812      x814  \\\n",
       "0 -0.720986  0.799013 -1.220463  ... -0.275974 -0.711160 -0.907511  0.165042   \n",
       "1 -0.370262  0.876290  1.497348  ... -0.275974  0.612322  1.279295 -1.430155   \n",
       "2  2.008697 -0.999652  1.714937  ...  6.953003  0.288377  0.705373  1.743518   \n",
       "3 -0.342019  0.939278  0.116234  ...  0.152069  1.544023  0.756629  0.130594   \n",
       "4  1.267598 -0.725764 -0.691801  ...  1.573082 -0.500319  1.410043  0.300320   \n",
       "\n",
       "       x816      x818      x819      x822      x826      x829  \n",
       "0 -0.381793  1.129595  1.480634  0.821172  0.903668  0.892698  \n",
       "1  1.593337  0.007191 -1.313709  1.153362  0.099747 -0.039934  \n",
       "2  1.531234  0.686855 -0.114619 -0.700058  0.759032  0.276651  \n",
       "3 -0.622497  0.465814 -0.112038  0.233614 -1.588138 -0.715512  \n",
       "4  0.810331  0.007191 -1.637788 -0.546425  0.141342  2.301585  \n",
       "\n",
       "[5 rows x 389 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select appropriate features for new dataframe\n",
    "\n",
    "print(np.count_nonzero(sel.get_support()))\n",
    "\n",
    "selected_feat = xtrain_without_outliers.columns[(sel.get_support())]\n",
    "xtrain_without_outliers_RF = xtrain_without_outliers.loc[:,selected_feat]\n",
    "xtest_RF = xtest.loc[:,selected_feat]\n",
    "xtrain_without_outliers_RF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreasopedaleriksson/Applications/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/from_model.py:196: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True, False, False, False,  True, False,\n",
       "        True,  True,  True, False,  True,  True, False,  True, False,\n",
       "       False,  True,  True,  True, False,  True,  True, False,  True,\n",
       "        True, False,  True,  True, False, False, False,  True, False,\n",
       "       False,  True, False, False,  True,  True,  True,  True, False,\n",
       "       False, False, False,  True, False,  True,  True, False, False,\n",
       "        True, False, False, False,  True,  True, False,  True, False,\n",
       "       False, False,  True,  True, False, False, False,  True, False,\n",
       "        True,  True, False, False,  True, False, False,  True, False,\n",
       "        True, False, False, False,  True,  True, False, False, False,\n",
       "       False, False, False,  True,  True, False, False, False,  True,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "        True, False,  True,  True,  True, False, False,  True,  True,\n",
       "        True,  True, False, False,  True,  True, False, False, False,\n",
       "       False, False, False,  True,  True, False,  True,  True, False,\n",
       "       False, False, False,  True,  True, False, False,  True, False,\n",
       "        True, False, False, False,  True,  True, False,  True,  True,\n",
       "       False, False,  True])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest again (this and next cell can be runned iteratively)\n",
    "\n",
    "sel2 = SelectFromModel(RandomForestClassifier(n_estimators = 200))\n",
    "sel2.fit(xtrain_without_outliers_RF, ytrain_without_outliers)\n",
    "sel2.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x2</th>\n",
       "      <th>x11</th>\n",
       "      <th>x24</th>\n",
       "      <th>x34</th>\n",
       "      <th>x37</th>\n",
       "      <th>x39</th>\n",
       "      <th>x42</th>\n",
       "      <th>x48</th>\n",
       "      <th>x58</th>\n",
       "      <th>x83</th>\n",
       "      <th>...</th>\n",
       "      <th>x689</th>\n",
       "      <th>x733</th>\n",
       "      <th>x737</th>\n",
       "      <th>x757</th>\n",
       "      <th>x766</th>\n",
       "      <th>x791</th>\n",
       "      <th>x794</th>\n",
       "      <th>x809</th>\n",
       "      <th>x810</th>\n",
       "      <th>x829</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.881312</td>\n",
       "      <td>-0.720986</td>\n",
       "      <td>0.376934</td>\n",
       "      <td>-0.759511</td>\n",
       "      <td>-1.026824</td>\n",
       "      <td>-0.557535</td>\n",
       "      <td>-0.280053</td>\n",
       "      <td>-0.110225</td>\n",
       "      <td>-0.057891</td>\n",
       "      <td>0.349221</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.374944</td>\n",
       "      <td>-1.146355</td>\n",
       "      <td>-0.584850</td>\n",
       "      <td>0.869597</td>\n",
       "      <td>1.734303</td>\n",
       "      <td>0.165274</td>\n",
       "      <td>-0.764916</td>\n",
       "      <td>-0.275974</td>\n",
       "      <td>0.945736</td>\n",
       "      <td>0.892698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211880</td>\n",
       "      <td>-0.370262</td>\n",
       "      <td>-0.009793</td>\n",
       "      <td>-0.231349</td>\n",
       "      <td>0.061223</td>\n",
       "      <td>1.294940</td>\n",
       "      <td>0.626771</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>1.686668</td>\n",
       "      <td>-0.612149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112385</td>\n",
       "      <td>-0.024304</td>\n",
       "      <td>-0.721988</td>\n",
       "      <td>1.726109</td>\n",
       "      <td>-0.711604</td>\n",
       "      <td>0.650773</td>\n",
       "      <td>0.364889</td>\n",
       "      <td>-0.275974</td>\n",
       "      <td>-0.923542</td>\n",
       "      <td>-0.039934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.701401</td>\n",
       "      <td>2.008697</td>\n",
       "      <td>-1.971860</td>\n",
       "      <td>0.554831</td>\n",
       "      <td>0.360411</td>\n",
       "      <td>-1.246254</td>\n",
       "      <td>0.509121</td>\n",
       "      <td>-0.364214</td>\n",
       "      <td>1.081135</td>\n",
       "      <td>-0.476167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024637</td>\n",
       "      <td>-1.341559</td>\n",
       "      <td>0.426284</td>\n",
       "      <td>0.345276</td>\n",
       "      <td>0.278350</td>\n",
       "      <td>0.174667</td>\n",
       "      <td>0.393767</td>\n",
       "      <td>6.953003</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.276651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.108910</td>\n",
       "      <td>-0.342019</td>\n",
       "      <td>2.001517</td>\n",
       "      <td>-0.704625</td>\n",
       "      <td>1.000937</td>\n",
       "      <td>0.712068</td>\n",
       "      <td>-0.428696</td>\n",
       "      <td>0.085729</td>\n",
       "      <td>-0.134253</td>\n",
       "      <td>0.150277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024637</td>\n",
       "      <td>-0.409151</td>\n",
       "      <td>-0.559396</td>\n",
       "      <td>0.461303</td>\n",
       "      <td>-0.018393</td>\n",
       "      <td>0.389840</td>\n",
       "      <td>0.779703</td>\n",
       "      <td>0.152069</td>\n",
       "      <td>-0.018425</td>\n",
       "      <td>-0.715512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.286194</td>\n",
       "      <td>1.267598</td>\n",
       "      <td>-1.174779</td>\n",
       "      <td>0.517532</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>-0.624554</td>\n",
       "      <td>-0.644603</td>\n",
       "      <td>-1.776692</td>\n",
       "      <td>0.172920</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024637</td>\n",
       "      <td>-0.273530</td>\n",
       "      <td>3.993204</td>\n",
       "      <td>0.080972</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>-0.304581</td>\n",
       "      <td>1.420011</td>\n",
       "      <td>1.573082</td>\n",
       "      <td>-0.533493</td>\n",
       "      <td>2.301585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x2       x11       x24       x34       x37       x39       x42  \\\n",
       "0 -1.881312 -0.720986  0.376934 -0.759511 -1.026824 -0.557535 -0.280053   \n",
       "1 -0.211880 -0.370262 -0.009793 -0.231349  0.061223  1.294940  0.626771   \n",
       "2 -0.701401  2.008697 -1.971860  0.554831  0.360411 -1.246254  0.509121   \n",
       "3  2.108910 -0.342019  2.001517 -0.704625  1.000937  0.712068 -0.428696   \n",
       "4 -0.286194  1.267598 -1.174779  0.517532  0.047278 -0.624554 -0.644603   \n",
       "\n",
       "        x48       x58       x83  ...      x689      x733      x737      x757  \\\n",
       "0 -0.110225 -0.057891  0.349221  ... -1.374944 -1.146355 -0.584850  0.869597   \n",
       "1  0.999512  1.686668 -0.612149  ... -0.112385 -0.024304 -0.721988  1.726109   \n",
       "2 -0.364214  1.081135 -0.476167  ...  0.024637 -1.341559  0.426284  0.345276   \n",
       "3  0.085729 -0.134253  0.150277  ...  0.024637 -0.409151 -0.559396  0.461303   \n",
       "4 -1.776692  0.172920  0.399996  ...  0.024637 -0.273530  3.993204  0.080972   \n",
       "\n",
       "       x766      x791      x794      x809      x810      x829  \n",
       "0  1.734303  0.165274 -0.764916 -0.275974  0.945736  0.892698  \n",
       "1 -0.711604  0.650773  0.364889 -0.275974 -0.923542 -0.039934  \n",
       "2  0.278350  0.174667  0.393767  6.953003  0.000220  0.276651  \n",
       "3 -0.018393  0.389840  0.779703  0.152069 -0.018425 -0.715512  \n",
       "4  0.139201 -0.304581  1.420011  1.573082 -0.533493  2.301585  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features for df again\n",
    "\n",
    "print(np.count_nonzero(sel2.get_support()))\n",
    "\n",
    "selected_feat = xtrain_without_outliers_RF.columns[(sel2.get_support())]\n",
    "xtrain_without_outliers_RF = xtrain_without_outliers_RF.loc[:,selected_feat]\n",
    "xtest_RF = xtest_RF.loc[:,selected_feat]\n",
    "xtrain_without_outliers_RF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.47993416468648753,\n",
       " 0.48985915202254465,\n",
       " 0.4821221144363589,\n",
       " 0.4921545093076819,\n",
       " 0.4915155576160478,\n",
       " 0.5035911667851167,\n",
       " 0.4974133844103085,\n",
       " 0.5018537177914595,\n",
       " 0.4888663027228498,\n",
       " 0.500202534895094,\n",
       " 0.4971258035672966,\n",
       " 0.5214672122222368,\n",
       " 0.5372827305531092,\n",
       " 0.5227202578580395,\n",
       " 0.49850591003742906,\n",
       " 0.39664533161664195]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-fold CV with 10 splits on different values for lambda (Ridge)\n",
    "\n",
    "x = xtrain_without_outliers_RF.values\n",
    "y = ytrain_without_outliers.values\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "alphas = np.array([0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000, 3000, 10000])\n",
    "meanscores = []\n",
    "for i in alphas:\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        X_train = x[train_index]\n",
    "        X_test = x[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        clf = Ridge(alpha=i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        Y_pred = clf.predict(X_test)\n",
    "        scores.append(r2_score(y_test, Y_pred))\n",
    "    meanscores.append(np.mean(scores))\n",
    "    \n",
    "meanscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5739030188589622,\n",
       " 0.5784211617776825,\n",
       " 0.5760360266354808,\n",
       " 0.5864199169419086,\n",
       " 0.5728393436098014,\n",
       " 0.5676256820915788,\n",
       " 0.5785945447240378,\n",
       " 0.578336600028013,\n",
       " 0.572599568019428]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now trying Lasso\n",
    "\n",
    "x = xtrain_without_outliers.values\n",
    "y = ytrain_without_outliers.values\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "alphas = np.array([0.2, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.35, 0.4])\n",
    "meanscores = []\n",
    "for i in alphas:\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        X_train = x[train_index]\n",
    "        X_test = x[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        clf = Lasso(alpha=i, max_iter=5000)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        Y_pred = clf.predict(X_test)\n",
    "        scores.append(r2_score(y_test, Y_pred))\n",
    "    meanscores.append(np.mean(scores))\n",
    "    \n",
    "meanscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  7.83574608e-02  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  5.34214318e-01\n",
      " -1.73291963e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -1.03886862e-02 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -1.32271778e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  4.69047592e-02 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -5.37025778e-02 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  9.34723589e-02  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -6.52967220e-01 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -4.81284309e-02  0.00000000e+00  0.00000000e+00\n",
      " -7.45964097e-02 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  4.27933462e-01 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  2.42324772e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -1.52913583e-01 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -5.94923653e-02  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -1.81287168e-02  0.00000000e+00 -0.00000000e+00\n",
      " -2.73992449e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00 -7.20393731e-02\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -3.08367306e-02 -0.00000000e+00\n",
      " -1.48661480e-01  0.00000000e+00 -0.00000000e+00  7.37384099e-02\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  4.75210638e-02 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -8.68964600e-02\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.15341810e-01\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -3.95146915e-02 -0.00000000e+00  0.00000000e+00 -4.65811009e-01\n",
      "  4.81766574e-02 -4.53272885e-01 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  5.91614036e-01 -0.00000000e+00 -6.16965798e-01  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -7.49894625e-02 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  4.29386721e-01 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -1.69246211e-01 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  2.02883218e-01 -0.00000000e+00  0.00000000e+00  1.01476049e-01\n",
      " -4.88509410e-02 -0.00000000e+00  0.00000000e+00  1.81487055e-02\n",
      " -0.00000000e+00 -5.39139944e-04  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -1.13068991e-02\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  1.26905659e-01  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -9.01834356e-01 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00  1.10282964e-01\n",
      " -0.00000000e+00  1.21700593e-01  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -8.22714100e-02 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -2.06869417e-01 -0.00000000e+00 -0.00000000e+00  4.73806628e-02\n",
      "  0.00000000e+00  6.98767962e-02  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -3.50128965e-02  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -5.88738187e-03\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -4.83940586e-02 -0.00000000e+00 -4.53612379e-01\n",
      " -0.00000000e+00  3.31438104e-01 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -2.14800559e-02 -0.00000000e+00 -0.00000000e+00 -6.07721740e-02\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00  6.56325311e-02\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  3.95727869e-01 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  9.67693500e-02 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -2.49789926e-01  0.00000000e+00\n",
      " -1.29821960e-01 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  4.49347301e-02 -1.68085468e-01\n",
      " -1.06090039e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  1.70832837e-02 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  8.83220287e-02  0.00000000e+00\n",
      " -0.00000000e+00  1.83621476e-01 -0.00000000e+00  4.67665645e-01\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -3.52682868e-01  0.00000000e+00 -8.48734061e-02\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00  2.32355224e-02\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  1.07780356e+00 -0.00000000e+00\n",
      "  0.00000000e+00  1.52732256e+00 -0.00000000e+00  0.00000000e+00\n",
      " -5.83820300e-02 -0.00000000e+00  3.79494364e-02  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.17484251e-01\n",
      " -0.00000000e+00 -1.10461445e-03 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  1.16879431e-01 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -1.66635403e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -9.56160615e-02 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.95539761e-02\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.16602098e-03\n",
      "  0.00000000e+00 -1.15486032e-02  9.23062516e-02 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00  4.79733429e-02 -0.00000000e+00  2.16606073e-02\n",
      " -8.93016223e-02 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.81293051e-03\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.23311858e-01 -0.00000000e+00 -0.00000000e+00\n",
      " -1.49166153e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      "  8.86202746e-02  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -1.97793689e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -7.11342596e-02 -0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -5.39548516e-02  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00  9.82807854e-02 -0.00000000e+00 -2.74964328e-01\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.99314845e-02\n",
      " -0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00  1.17993961e+00  0.00000000e+00 -1.04715456e-01\n",
      "  0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -0.00000000e+00\n",
      "  0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.29610395e-02 -0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Create csv with best alpha\n",
    "\n",
    "clf = Lasso(alpha=0.3)\n",
    "clf.fit(xtrain_without_outliers, ytrain_without_outliers)\n",
    "\n",
    "y_pred = clf.predict(xtest)\n",
    "\n",
    "print(clf.coef_)\n",
    "\n",
    "index = pd.read_csv(\"sample.csv\")\n",
    "index['y'] = y_pred\n",
    "\n",
    "index.to_csv(\"predictions2Lasso.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a ridge regression with optimal value of lambda and write to csv\n",
    "\n",
    "clf = Ridge(alpha=100)\n",
    "clf.fit(xtrain_without_outliers_RF, ytrain_without_outliers)\n",
    "\n",
    "y_pred = clf.predict(xtest_RF)\n",
    "\n",
    "index = pd.read_csv(\"sample.csv\")\n",
    "index['y'] = y_pred\n",
    "\n",
    "index.to_csv(\"predictions1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New approach with Lassso first for feature selection, then outlier detection and then fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118345.392781</td>\n",
       "      <td>3104.010883</td>\n",
       "      <td>82378.542430</td>\n",
       "      <td>1086.678601</td>\n",
       "      <td>11395.883550</td>\n",
       "      <td>10.455601</td>\n",
       "      <td>109886.476608</td>\n",
       "      <td>1.054926e+06</td>\n",
       "      <td>101877.946528</td>\n",
       "      <td>2.550290</td>\n",
       "      <td>...</td>\n",
       "      <td>10.769524</td>\n",
       "      <td>10.245068</td>\n",
       "      <td>1021.907543</td>\n",
       "      <td>1031.645762</td>\n",
       "      <td>107440.039766</td>\n",
       "      <td>107083.296966</td>\n",
       "      <td>5559.203921</td>\n",
       "      <td>10.861464</td>\n",
       "      <td>107548.413675</td>\n",
       "      <td>2.299202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5889.055991</td>\n",
       "      <td>97932.067482</td>\n",
       "      <td>1116.564363</td>\n",
       "      <td>12172.212426</td>\n",
       "      <td>10.502997</td>\n",
       "      <td>100372.504488</td>\n",
       "      <td>1.011783e+06</td>\n",
       "      <td>108852.296962</td>\n",
       "      <td>2.579040</td>\n",
       "      <td>...</td>\n",
       "      <td>10.859822</td>\n",
       "      <td>10.088023</td>\n",
       "      <td>988.135968</td>\n",
       "      <td>999.044639</td>\n",
       "      <td>105238.779040</td>\n",
       "      <td>106365.468525</td>\n",
       "      <td>10334.091649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107841.227180</td>\n",
       "      <td>2.472763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95373.022035</td>\n",
       "      <td>6293.442455</td>\n",
       "      <td>93371.369288</td>\n",
       "      <td>1034.722073</td>\n",
       "      <td>11618.142107</td>\n",
       "      <td>10.947611</td>\n",
       "      <td>109337.757279</td>\n",
       "      <td>1.006491e+06</td>\n",
       "      <td>104540.883376</td>\n",
       "      <td>2.573247</td>\n",
       "      <td>...</td>\n",
       "      <td>10.356015</td>\n",
       "      <td>10.514234</td>\n",
       "      <td>995.480813</td>\n",
       "      <td>898.329758</td>\n",
       "      <td>107044.005199</td>\n",
       "      <td>102704.104686</td>\n",
       "      <td>7697.875887</td>\n",
       "      <td>10.277760</td>\n",
       "      <td>103414.594212</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105066.272301</td>\n",
       "      <td>3279.162164</td>\n",
       "      <td>119554.079514</td>\n",
       "      <td>1114.014483</td>\n",
       "      <td>12127.235755</td>\n",
       "      <td>10.540204</td>\n",
       "      <td>106215.391332</td>\n",
       "      <td>1.022381e+06</td>\n",
       "      <td>109597.474506</td>\n",
       "      <td>2.693256</td>\n",
       "      <td>...</td>\n",
       "      <td>10.609811</td>\n",
       "      <td>10.991861</td>\n",
       "      <td>1117.179063</td>\n",
       "      <td>867.267810</td>\n",
       "      <td>100617.082858</td>\n",
       "      <td>108893.304959</td>\n",
       "      <td>6549.131099</td>\n",
       "      <td>9.337688</td>\n",
       "      <td>105722.857008</td>\n",
       "      <td>2.484935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98957.033333</td>\n",
       "      <td>4177.482190</td>\n",
       "      <td>97239.708338</td>\n",
       "      <td>1049.430921</td>\n",
       "      <td>10417.250336</td>\n",
       "      <td>10.618957</td>\n",
       "      <td>102736.470171</td>\n",
       "      <td>1.086871e+06</td>\n",
       "      <td>103340.057448</td>\n",
       "      <td>2.540610</td>\n",
       "      <td>...</td>\n",
       "      <td>10.397777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>863.943966</td>\n",
       "      <td>1041.278922</td>\n",
       "      <td>105352.672454</td>\n",
       "      <td>101705.692839</td>\n",
       "      <td>5388.312773</td>\n",
       "      <td>12.196382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.930136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x0           x1             x2           x3            x4  \\\n",
       "0  118345.392781  3104.010883   82378.542430  1086.678601  11395.883550   \n",
       "1            NaN  5889.055991   97932.067482  1116.564363  12172.212426   \n",
       "2   95373.022035  6293.442455   93371.369288  1034.722073  11618.142107   \n",
       "3  105066.272301  3279.162164  119554.079514  1114.014483  12127.235755   \n",
       "4   98957.033333  4177.482190   97239.708338  1049.430921  10417.250336   \n",
       "\n",
       "          x5             x6            x7             x8        x9  ...  \\\n",
       "0  10.455601  109886.476608  1.054926e+06  101877.946528  2.550290  ...   \n",
       "1  10.502997  100372.504488  1.011783e+06  108852.296962  2.579040  ...   \n",
       "2  10.947611  109337.757279  1.006491e+06  104540.883376  2.573247  ...   \n",
       "3  10.540204  106215.391332  1.022381e+06  109597.474506  2.693256  ...   \n",
       "4  10.618957  102736.470171  1.086871e+06  103340.057448  2.540610  ...   \n",
       "\n",
       "        x822       x823         x824         x825           x826  \\\n",
       "0  10.769524  10.245068  1021.907543  1031.645762  107440.039766   \n",
       "1  10.859822  10.088023   988.135968   999.044639  105238.779040   \n",
       "2  10.356015  10.514234   995.480813   898.329758  107044.005199   \n",
       "3  10.609811  10.991861  1117.179063   867.267810  100617.082858   \n",
       "4  10.397777        NaN   863.943966  1041.278922  105352.672454   \n",
       "\n",
       "            x827          x828       x829           x830      x831  \n",
       "0  107083.296966   5559.203921  10.861464  107548.413675  2.299202  \n",
       "1  106365.468525  10334.091649        NaN  107841.227180  2.472763  \n",
       "2  102704.104686   7697.875887  10.277760  103414.594212       NaN  \n",
       "3  108893.304959   6549.131099   9.337688  105722.857008  2.484935  \n",
       "4  101705.692839   5388.312773  12.196382            NaN  1.930136  \n",
       "\n",
       "[5 rows x 832 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = pd.read_csv(\"X_train.csv\")\n",
    "xtrain = xtrain.iloc[:, 1:]\n",
    "xtest = pd.read_csv(\"X_test.csv\")\n",
    "xtest = xtest.iloc[:, 1:]\n",
    "ytrain = pd.read_csv(\"Y_train.csv\")\n",
    "\n",
    "xtrain.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118345.392781</td>\n",
       "      <td>3104.010883</td>\n",
       "      <td>82378.542430</td>\n",
       "      <td>1086.678601</td>\n",
       "      <td>11395.883550</td>\n",
       "      <td>10.455601</td>\n",
       "      <td>109886.476608</td>\n",
       "      <td>1.054926e+06</td>\n",
       "      <td>101877.946528</td>\n",
       "      <td>2.550290</td>\n",
       "      <td>...</td>\n",
       "      <td>10.769524</td>\n",
       "      <td>10.245068</td>\n",
       "      <td>1021.907543</td>\n",
       "      <td>1031.645762</td>\n",
       "      <td>107440.039766</td>\n",
       "      <td>107083.296966</td>\n",
       "      <td>5559.203921</td>\n",
       "      <td>10.861464</td>\n",
       "      <td>107548.413675</td>\n",
       "      <td>2.299202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100215.152009</td>\n",
       "      <td>5889.055991</td>\n",
       "      <td>97932.067482</td>\n",
       "      <td>1116.564363</td>\n",
       "      <td>12172.212426</td>\n",
       "      <td>10.502997</td>\n",
       "      <td>100372.504488</td>\n",
       "      <td>1.011783e+06</td>\n",
       "      <td>108852.296962</td>\n",
       "      <td>2.579040</td>\n",
       "      <td>...</td>\n",
       "      <td>10.859822</td>\n",
       "      <td>10.088023</td>\n",
       "      <td>988.135968</td>\n",
       "      <td>999.044639</td>\n",
       "      <td>105238.779040</td>\n",
       "      <td>106365.468525</td>\n",
       "      <td>10334.091649</td>\n",
       "      <td>9.977797</td>\n",
       "      <td>107841.227180</td>\n",
       "      <td>2.472763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95373.022035</td>\n",
       "      <td>6293.442455</td>\n",
       "      <td>93371.369288</td>\n",
       "      <td>1034.722073</td>\n",
       "      <td>11618.142107</td>\n",
       "      <td>10.947611</td>\n",
       "      <td>109337.757279</td>\n",
       "      <td>1.006491e+06</td>\n",
       "      <td>104540.883376</td>\n",
       "      <td>2.573247</td>\n",
       "      <td>...</td>\n",
       "      <td>10.356015</td>\n",
       "      <td>10.514234</td>\n",
       "      <td>995.480813</td>\n",
       "      <td>898.329758</td>\n",
       "      <td>107044.005199</td>\n",
       "      <td>102704.104686</td>\n",
       "      <td>7697.875887</td>\n",
       "      <td>10.277760</td>\n",
       "      <td>103414.594212</td>\n",
       "      <td>2.292501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105066.272301</td>\n",
       "      <td>3279.162164</td>\n",
       "      <td>119554.079514</td>\n",
       "      <td>1114.014483</td>\n",
       "      <td>12127.235755</td>\n",
       "      <td>10.540204</td>\n",
       "      <td>106215.391332</td>\n",
       "      <td>1.022381e+06</td>\n",
       "      <td>109597.474506</td>\n",
       "      <td>2.693256</td>\n",
       "      <td>...</td>\n",
       "      <td>10.609811</td>\n",
       "      <td>10.991861</td>\n",
       "      <td>1117.179063</td>\n",
       "      <td>867.267810</td>\n",
       "      <td>100617.082858</td>\n",
       "      <td>108893.304959</td>\n",
       "      <td>6549.131099</td>\n",
       "      <td>9.337688</td>\n",
       "      <td>105722.857008</td>\n",
       "      <td>2.484935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98957.033333</td>\n",
       "      <td>4177.482190</td>\n",
       "      <td>97239.708338</td>\n",
       "      <td>1049.430921</td>\n",
       "      <td>10417.250336</td>\n",
       "      <td>10.618957</td>\n",
       "      <td>102736.470171</td>\n",
       "      <td>1.086871e+06</td>\n",
       "      <td>103340.057448</td>\n",
       "      <td>2.540610</td>\n",
       "      <td>...</td>\n",
       "      <td>10.397777</td>\n",
       "      <td>10.538567</td>\n",
       "      <td>863.943966</td>\n",
       "      <td>1041.278922</td>\n",
       "      <td>105352.672454</td>\n",
       "      <td>101705.692839</td>\n",
       "      <td>5388.312773</td>\n",
       "      <td>12.196382</td>\n",
       "      <td>104901.792534</td>\n",
       "      <td>1.930136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x0           x1             x2           x3            x4  \\\n",
       "0  118345.392781  3104.010883   82378.542430  1086.678601  11395.883550   \n",
       "1  100215.152009  5889.055991   97932.067482  1116.564363  12172.212426   \n",
       "2   95373.022035  6293.442455   93371.369288  1034.722073  11618.142107   \n",
       "3  105066.272301  3279.162164  119554.079514  1114.014483  12127.235755   \n",
       "4   98957.033333  4177.482190   97239.708338  1049.430921  10417.250336   \n",
       "\n",
       "          x5             x6            x7             x8        x9  ...  \\\n",
       "0  10.455601  109886.476608  1.054926e+06  101877.946528  2.550290  ...   \n",
       "1  10.502997  100372.504488  1.011783e+06  108852.296962  2.579040  ...   \n",
       "2  10.947611  109337.757279  1.006491e+06  104540.883376  2.573247  ...   \n",
       "3  10.540204  106215.391332  1.022381e+06  109597.474506  2.693256  ...   \n",
       "4  10.618957  102736.470171  1.086871e+06  103340.057448  2.540610  ...   \n",
       "\n",
       "        x822       x823         x824         x825           x826  \\\n",
       "0  10.769524  10.245068  1021.907543  1031.645762  107440.039766   \n",
       "1  10.859822  10.088023   988.135968   999.044639  105238.779040   \n",
       "2  10.356015  10.514234   995.480813   898.329758  107044.005199   \n",
       "3  10.609811  10.991861  1117.179063   867.267810  100617.082858   \n",
       "4  10.397777  10.538567   863.943966  1041.278922  105352.672454   \n",
       "\n",
       "            x827          x828       x829           x830      x831  \n",
       "0  107083.296966   5559.203921  10.861464  107548.413675  2.299202  \n",
       "1  106365.468525  10334.091649   9.977797  107841.227180  2.472763  \n",
       "2  102704.104686   7697.875887  10.277760  103414.594212  2.292501  \n",
       "3  108893.304959   6549.131099   9.337688  105722.857008  2.484935  \n",
       "4  101705.692839   5388.312773  12.196382  104901.792534  1.930136  \n",
       "\n",
       "[5 rows x 832 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treat missing values as column medians. Important (apparently) to use the medians from the training set in the test set\n",
    "\n",
    "xtrain = xtrain.fillna(xtrain.median())\n",
    "xtest = xtest.fillna(xtrain.median())\n",
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and test data\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "xtrain_scaled = scaler.fit_transform(xtrain)\n",
    "xtrain = pd.DataFrame(xtrain_scaled, columns = xtrain.columns)\n",
    "xtrain.head()\n",
    "\n",
    "xtest_scaled = scaler.fit_transform(xtest)\n",
    "xtest = pd.DataFrame(xtest_scaled, columns = xtest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y\n",
       "0  75.0\n",
       "1  53.0\n",
       "2  78.0\n",
       "3  65.0\n",
       "4  86.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove unnecessary id column from ytrain that just ***** things up\n",
    "\n",
    "ytrain1 = ytrain.loc[:, \"y\"]\n",
    "ytrain2 = pd.DataFrame(data = ytrain1.values, columns= ['y'])\n",
    "#ytrain2.head()\n",
    "ytrain = ytrain2\n",
    "ytrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estim:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estim:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estim:  50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estim:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estim:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ae5aa987a66c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 330\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1155\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1158\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Lasso\n",
    "\n",
    "x = xtrain.values\n",
    "y = ytrain.values\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "alphas = np.array([0.1, 0.2, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.35, 0.4, 1, 3, 10])\n",
    "#alphas = np.array([1,10,50,100,500])\n",
    "\n",
    "meanscores = []\n",
    "for i in alphas:\n",
    "    scores = []\n",
    "    print(\"estim: \", i)\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        X_train = x[train_index]\n",
    "        X_test = x[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        clf = Lasso(alpha = 0.3)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        Y_pred = clf.predict(X_test)\n",
    "        scores.append(r2_score(np.ravel(y_test), np.ravel(Y_pred)))\n",
    "    meanscores.append(np.mean(scores))\n",
    "    \n",
    "meanscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00334279 0.00354795 0.00336753 0.00339216 0.00233903 0.00755017\n",
      " 0.00326175 0.00280413 0.005042   0.00321472 0.0064555  0.00398008\n",
      " 0.00363362 0.0030434  0.00367348 0.00560317 0.00301334 0.00312043\n",
      " 0.00582623 0.0033812  0.00380942 0.01105547 0.24174755 0.00531165\n",
      " 0.00394784 0.01599936 0.00579329 0.00360392 0.00762414 0.00414732\n",
      " 0.00480209 0.00381545 0.00775176 0.00311807 0.00550621 0.01841667\n",
      " 0.00390967 0.06710978 0.00324534 0.00377565 0.0035977  0.00317517\n",
      " 0.00520801 0.00308501 0.00532781 0.00395549 0.00407129 0.01209869\n",
      " 0.00301703 0.00318855 0.01042441 0.00335618 0.0050676  0.00535393\n",
      " 0.00508026 0.00788286 0.00841562 0.00686925 0.00310275 0.00438395\n",
      " 0.02499382 0.00293398 0.00283542 0.0032673  0.00327785 0.0042503\n",
      " 0.03328775 0.0031729  0.0072215  0.03073211 0.00273744 0.02483072\n",
      " 0.00361677 0.00562878 0.00376428 0.01117627 0.00337063 0.00290358\n",
      " 0.00284545 0.00378543 0.00356519 0.00459    0.00934794 0.06750211\n",
      " 0.00249675 0.05786815 0.01332414 0.00266037 0.00467476 0.00337114\n",
      " 0.00405055 0.028577   0.00290928 0.00368545]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfeatures = (clf.coef_ != 0)\\nprint(features.shape)\\nxtrain = xtrain.loc[:, features]\\nxtest = xtest.loc[:, features]\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove features with zero weight from Lasso\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=50)\n",
    "clf.fit(xtrain, ytrain)\n",
    "\n",
    "importance = clf.feature_importances_\n",
    "print(importance)\n",
    "'''\n",
    "features = (clf.coef_ != 0)\n",
    "print(features.shape)\n",
    "xtrain = xtrain.loc[:, features]\n",
    "xtest = xtest.loc[:, features]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10517221 0.07539336]\n"
     ]
    }
   ],
   "source": [
    "# Now do PCA shit\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(xtrain)\n",
    "xpca = pd.DataFrame(data = principal_components, columns = ['PC1', 'PC2'])\n",
    "\n",
    "plt.scatter(xpca['PC1'], xpca['PC2'], alpha=0.5)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.plot([-8, -8], [-15, 15], marker='o')\n",
    "plt.plot([9, 9], [-15, 15], marker='o')\n",
    "plt.plot([-20, 20], [-7, -7], marker='o')\n",
    "plt.plot([-20, 20], [7, 7], marker='o')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "per_var = np.round(pca.explained_variance_ratio_ * 100, decimals=1)\n",
    "labels = ['PC' + str(x) for x in range(1, len(per_var) + 1)]\n",
    "plt.bar(x=range(1, len(per_var)+1), height=per_var, tick_label=labels)\n",
    "plt.ylabel('percentange of explained variance')\n",
    "plt.xlabel('principal component')\n",
    "plt.title('scree plot')\n",
    "plt.show()\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1155\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x4</th>\n",
       "      <th>x12</th>\n",
       "      <th>x22</th>\n",
       "      <th>x64</th>\n",
       "      <th>x84</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x108</th>\n",
       "      <th>x120</th>\n",
       "      <th>x129</th>\n",
       "      <th>...</th>\n",
       "      <th>x752</th>\n",
       "      <th>x757</th>\n",
       "      <th>x760</th>\n",
       "      <th>x766</th>\n",
       "      <th>x769</th>\n",
       "      <th>x786</th>\n",
       "      <th>x797</th>\n",
       "      <th>x809</th>\n",
       "      <th>x821</th>\n",
       "      <th>x830</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.454476</td>\n",
       "      <td>0.641522</td>\n",
       "      <td>-0.526024</td>\n",
       "      <td>-0.740642</td>\n",
       "      <td>0.199223</td>\n",
       "      <td>-0.373272</td>\n",
       "      <td>-0.236610</td>\n",
       "      <td>0.577454</td>\n",
       "      <td>-0.619985</td>\n",
       "      <td>1.033877</td>\n",
       "      <td>...</td>\n",
       "      <td>1.147683</td>\n",
       "      <td>0.869597</td>\n",
       "      <td>-0.170054</td>\n",
       "      <td>1.734303</td>\n",
       "      <td>-0.323955</td>\n",
       "      <td>0.403708</td>\n",
       "      <td>-0.628594</td>\n",
       "      <td>-0.275974</td>\n",
       "      <td>-0.008390</td>\n",
       "      <td>0.925679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.265954</td>\n",
       "      <td>-1.201704</td>\n",
       "      <td>1.512451</td>\n",
       "      <td>1.073093</td>\n",
       "      <td>0.501196</td>\n",
       "      <td>0.338884</td>\n",
       "      <td>-0.554347</td>\n",
       "      <td>0.195198</td>\n",
       "      <td>0.406709</td>\n",
       "      <td>1.090254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>1.726109</td>\n",
       "      <td>1.860696</td>\n",
       "      <td>-0.711604</td>\n",
       "      <td>0.498500</td>\n",
       "      <td>-1.434010</td>\n",
       "      <td>1.377539</td>\n",
       "      <td>-0.275974</td>\n",
       "      <td>0.016619</td>\n",
       "      <td>1.031616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.686798</td>\n",
       "      <td>0.428108</td>\n",
       "      <td>-0.754718</td>\n",
       "      <td>1.580733</td>\n",
       "      <td>-1.178433</td>\n",
       "      <td>-0.047456</td>\n",
       "      <td>0.622922</td>\n",
       "      <td>0.656719</td>\n",
       "      <td>0.759553</td>\n",
       "      <td>0.926249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.439515</td>\n",
       "      <td>0.345276</td>\n",
       "      <td>-0.596208</td>\n",
       "      <td>0.278350</td>\n",
       "      <td>2.099532</td>\n",
       "      <td>0.965567</td>\n",
       "      <td>-1.926625</td>\n",
       "      <td>6.953003</td>\n",
       "      <td>0.936008</td>\n",
       "      <td>-0.569888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.218941</td>\n",
       "      <td>-0.370244</td>\n",
       "      <td>-0.479087</td>\n",
       "      <td>-0.106118</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-1.280235</td>\n",
       "      <td>-0.346958</td>\n",
       "      <td>-0.270578</td>\n",
       "      <td>-1.252627</td>\n",
       "      <td>1.938747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580023</td>\n",
       "      <td>0.461303</td>\n",
       "      <td>1.026596</td>\n",
       "      <td>-0.018393</td>\n",
       "      <td>-0.091943</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-1.171589</td>\n",
       "      <td>0.152069</td>\n",
       "      <td>0.454378</td>\n",
       "      <td>0.265215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.431533</td>\n",
       "      <td>-1.321807</td>\n",
       "      <td>0.435917</td>\n",
       "      <td>1.641302</td>\n",
       "      <td>-1.138132</td>\n",
       "      <td>1.700972</td>\n",
       "      <td>0.075747</td>\n",
       "      <td>-1.851014</td>\n",
       "      <td>1.525983</td>\n",
       "      <td>-0.560213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334431</td>\n",
       "      <td>0.080972</td>\n",
       "      <td>-0.909855</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>0.628030</td>\n",
       "      <td>0.377739</td>\n",
       "      <td>-0.453301</td>\n",
       "      <td>1.573082</td>\n",
       "      <td>1.091439</td>\n",
       "      <td>-0.031837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x4       x12       x22       x64       x84       x93       x94  \\\n",
       "0  1.454476  0.641522 -0.526024 -0.740642  0.199223 -0.373272 -0.236610   \n",
       "1  2.265954 -1.201704  1.512451  1.073093  0.501196  0.338884 -0.554347   \n",
       "2  1.686798  0.428108 -0.754718  1.580733 -1.178433 -0.047456  0.622922   \n",
       "3  2.218941 -0.370244 -0.479087 -0.106118 -0.020148 -1.280235 -0.346958   \n",
       "4  0.431533 -1.321807  0.435917  1.641302 -1.138132  1.700972  0.075747   \n",
       "\n",
       "       x108      x120      x129  ...      x752      x757      x760      x766  \\\n",
       "0  0.577454 -0.619985  1.033877  ...  1.147683  0.869597 -0.170054  1.734303   \n",
       "1  0.195198  0.406709  1.090254  ... -0.000024  1.726109  1.860696 -0.711604   \n",
       "2  0.656719  0.759553  0.926249  ... -0.439515  0.345276 -0.596208  0.278350   \n",
       "3 -0.270578 -1.252627  1.938747  ...  0.580023  0.461303  1.026596 -0.018393   \n",
       "4 -1.851014  1.525983 -0.560213  ...  0.334431  0.080972 -0.909855  0.139201   \n",
       "\n",
       "       x769      x786      x797      x809      x821      x830  \n",
       "0 -0.323955  0.403708 -0.628594 -0.275974 -0.008390  0.925679  \n",
       "1  0.498500 -1.434010  1.377539 -0.275974  0.016619  1.031616  \n",
       "2  2.099532  0.965567 -1.926625  6.953003  0.936008 -0.569888  \n",
       "3 -0.091943 -1.357529 -1.171589  0.152069  0.454378  0.265215  \n",
       "4  0.628030  0.377739 -0.453301  1.573082  1.091439 -0.031837  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highly ad hoc way of removing outliers based on PCA plot above\n",
    "\n",
    "outliers = (xpca['PC1'] <= 9) & (xpca['PC1'] >= -8) & (xpca['PC2'] <= 7) & (xpca['PC2'] >= -7)\n",
    "print(np.count_nonzero(outliers))\n",
    "xtrain_without_outliers = xtrain[outliers]\n",
    "ytrain_without_outliers = ytrain[outliers]\n",
    "xtrain_without_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xtrain_without_outliers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6ed29ee7ee45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Lasso\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxtrain_without_outliers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mytrain_without_outliers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xtrain_without_outliers' is not defined"
     ]
    }
   ],
   "source": [
    "#Lasso\n",
    "\n",
    "x = xtrain_without_outliers.values\n",
    "y = ytrain_without_outliers.values\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "alphas = np.array([0, 0.01, 0.1, 0.2, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.35, 0.4, 1, 3, 10])\n",
    "meanscores = []\n",
    "for i in alphas:\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        X_train = x[train_index]\n",
    "        X_test = x[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        clf = Lasso(alpha=i, max_iter=5000)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        Y_pred = clf.predict(X_test)\n",
    "        scores.append(r2_score(y_test, Y_pred))\n",
    "    meanscores.append(np.mean(scores))\n",
    "    \n",
    "meanscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6424622447489994,\n",
       " 0.6513394906378386,\n",
       " 0.6352932036611696,\n",
       " 0.6431012695639,\n",
       " 0.6455978429449114,\n",
       " 0.6457407151381719,\n",
       " 0.6489765495323994,\n",
       " 0.6509799539989327,\n",
       " 0.645965658576476,\n",
       " 0.6515887910361476,\n",
       " 0.6470278257759257]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-fold CV with 10 splits on different values for lambda (Ridge)\n",
    "\n",
    "x = xtrain_without_outliers.values\n",
    "y = ytrain_without_outliers.values\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "alphas = np.array([0, 0.3, 1, 3, 10, 30, 50, 100, 120, 200, 300])\n",
    "meanscores = []\n",
    "for i in alphas:\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        X_train = x[train_index]\n",
    "        X_test = x[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        clf = Ridge(alpha=i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        Y_pred = clf.predict(X_test)\n",
    "        scores.append(r2_score(y_test, Y_pred))\n",
    "    meanscores.append(np.mean(scores))\n",
    "    \n",
    "meanscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.644991067959189"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regular linear regression\n",
    "\n",
    "x = xtrain_without_outliers.values\n",
    "y = ytrain_without_outliers.values\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(x):\n",
    "        X_train = x[train_index]\n",
    "        X_test = x[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        reg_model = LinearRegression()\n",
    "        reg_model.fit(X_train, y_train)\n",
    "        Y_pred = reg_model.predict(X_test)\n",
    "        scores.append(r2_score(y_test, Y_pred))\n",
    "\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x4</th>\n",
       "      <th>x12</th>\n",
       "      <th>x22</th>\n",
       "      <th>x64</th>\n",
       "      <th>x84</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x108</th>\n",
       "      <th>x120</th>\n",
       "      <th>x129</th>\n",
       "      <th>...</th>\n",
       "      <th>x752</th>\n",
       "      <th>x757</th>\n",
       "      <th>x760</th>\n",
       "      <th>x766</th>\n",
       "      <th>x769</th>\n",
       "      <th>x786</th>\n",
       "      <th>x797</th>\n",
       "      <th>x809</th>\n",
       "      <th>x821</th>\n",
       "      <th>x830</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.366961</td>\n",
       "      <td>0.207161</td>\n",
       "      <td>0.089723</td>\n",
       "      <td>1.249686</td>\n",
       "      <td>0.640825</td>\n",
       "      <td>-0.075040</td>\n",
       "      <td>-0.760750</td>\n",
       "      <td>-1.231735</td>\n",
       "      <td>0.660534</td>\n",
       "      <td>0.610043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165588</td>\n",
       "      <td>0.228209</td>\n",
       "      <td>1.045886</td>\n",
       "      <td>-0.343605</td>\n",
       "      <td>0.716521</td>\n",
       "      <td>1.095110</td>\n",
       "      <td>0.486149</td>\n",
       "      <td>-0.235359</td>\n",
       "      <td>0.802799</td>\n",
       "      <td>-0.897661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.200475</td>\n",
       "      <td>1.532888</td>\n",
       "      <td>1.773883</td>\n",
       "      <td>-0.582201</td>\n",
       "      <td>1.073678</td>\n",
       "      <td>-0.674123</td>\n",
       "      <td>0.589974</td>\n",
       "      <td>-0.646873</td>\n",
       "      <td>-1.111694</td>\n",
       "      <td>-0.929326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609527</td>\n",
       "      <td>-0.617402</td>\n",
       "      <td>-1.121557</td>\n",
       "      <td>-0.291798</td>\n",
       "      <td>-0.073786</td>\n",
       "      <td>-0.115332</td>\n",
       "      <td>-0.475065</td>\n",
       "      <td>-0.369801</td>\n",
       "      <td>-1.506319</td>\n",
       "      <td>0.844766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.012008</td>\n",
       "      <td>1.649202</td>\n",
       "      <td>1.629548</td>\n",
       "      <td>-1.151042</td>\n",
       "      <td>0.449470</td>\n",
       "      <td>0.142439</td>\n",
       "      <td>-0.033074</td>\n",
       "      <td>-1.128735</td>\n",
       "      <td>-0.913957</td>\n",
       "      <td>-0.028214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856530</td>\n",
       "      <td>-1.698646</td>\n",
       "      <td>-0.396122</td>\n",
       "      <td>0.095625</td>\n",
       "      <td>1.043549</td>\n",
       "      <td>1.076499</td>\n",
       "      <td>0.038817</td>\n",
       "      <td>2.242882</td>\n",
       "      <td>-0.306739</td>\n",
       "      <td>0.815519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014163</td>\n",
       "      <td>1.193644</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>-0.094336</td>\n",
       "      <td>1.955934</td>\n",
       "      <td>0.291232</td>\n",
       "      <td>-0.033074</td>\n",
       "      <td>0.708590</td>\n",
       "      <td>-0.464667</td>\n",
       "      <td>-1.967241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092668</td>\n",
       "      <td>-0.763613</td>\n",
       "      <td>-0.246509</td>\n",
       "      <td>-0.337129</td>\n",
       "      <td>-0.422863</td>\n",
       "      <td>0.749299</td>\n",
       "      <td>-0.587864</td>\n",
       "      <td>-0.043044</td>\n",
       "      <td>-1.654263</td>\n",
       "      <td>-1.476280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032613</td>\n",
       "      <td>-0.770075</td>\n",
       "      <td>-0.553363</td>\n",
       "      <td>1.815444</td>\n",
       "      <td>1.909415</td>\n",
       "      <td>0.866800</td>\n",
       "      <td>-0.247206</td>\n",
       "      <td>-0.176174</td>\n",
       "      <td>1.385495</td>\n",
       "      <td>-0.595387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451775</td>\n",
       "      <td>-1.103263</td>\n",
       "      <td>-0.020240</td>\n",
       "      <td>-0.079567</td>\n",
       "      <td>2.261521</td>\n",
       "      <td>-1.023202</td>\n",
       "      <td>-0.798678</td>\n",
       "      <td>-0.127907</td>\n",
       "      <td>2.902042</td>\n",
       "      <td>-1.194072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x4       x12       x22       x64       x84       x93       x94  \\\n",
       "0  0.366961  0.207161  0.089723  1.249686  0.640825 -0.075040 -0.760750   \n",
       "1  1.200475  1.532888  1.773883 -0.582201  1.073678 -0.674123  0.589974   \n",
       "2  2.012008  1.649202  1.629548 -1.151042  0.449470  0.142439 -0.033074   \n",
       "3 -0.014163  1.193644  0.014570 -0.094336  1.955934  0.291232 -0.033074   \n",
       "4  0.032613 -0.770075 -0.553363  1.815444  1.909415  0.866800 -0.247206   \n",
       "\n",
       "       x108      x120      x129  ...      x752      x757      x760      x766  \\\n",
       "0 -1.231735  0.660534  0.610043  ... -0.165588  0.228209  1.045886 -0.343605   \n",
       "1 -0.646873 -1.111694 -0.929326  ...  0.609527 -0.617402 -1.121557 -0.291798   \n",
       "2 -1.128735 -0.913957 -0.028214  ...  0.856530 -1.698646 -0.396122  0.095625   \n",
       "3  0.708590 -0.464667 -1.967241  ... -0.092668 -0.763613 -0.246509 -0.337129   \n",
       "4 -0.176174  1.385495 -0.595387  ...  0.451775 -1.103263 -0.020240 -0.079567   \n",
       "\n",
       "       x769      x786      x797      x809      x821      x830  \n",
       "0  0.716521  1.095110  0.486149 -0.235359  0.802799 -0.897661  \n",
       "1 -0.073786 -0.115332 -0.475065 -0.369801 -1.506319  0.844766  \n",
       "2  1.043549  1.076499  0.038817  2.242882 -0.306739  0.815519  \n",
       "3 -0.422863  0.749299 -0.587864 -0.043044 -1.654263 -1.476280  \n",
       "4  2.261521 -1.023202 -0.798678 -0.127907  2.902042 -1.194072  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "\n",
    "clf = Lasso(alpha = 0.3)\n",
    "clf.fit(xtrain_without_outliers, ytrain_without_outliers)\n",
    "\n",
    "y_pred = clf.predict(xtest)\n",
    "\n",
    "index = pd.read_csv(\"sample.csv\")\n",
    "index['y'] = y_pred\n",
    "\n",
    "index.to_csv(\"predictions2Lasso_for_feat.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now same as above but with a different outlier detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118345.392781</td>\n",
       "      <td>3104.010883</td>\n",
       "      <td>82378.542430</td>\n",
       "      <td>1086.678601</td>\n",
       "      <td>11395.883550</td>\n",
       "      <td>10.455601</td>\n",
       "      <td>109886.476608</td>\n",
       "      <td>1.054926e+06</td>\n",
       "      <td>101877.946528</td>\n",
       "      <td>2.550290</td>\n",
       "      <td>...</td>\n",
       "      <td>10.769524</td>\n",
       "      <td>10.245068</td>\n",
       "      <td>1021.907543</td>\n",
       "      <td>1031.645762</td>\n",
       "      <td>107440.039766</td>\n",
       "      <td>107083.296966</td>\n",
       "      <td>5559.203921</td>\n",
       "      <td>10.861464</td>\n",
       "      <td>107548.413675</td>\n",
       "      <td>2.299202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5889.055991</td>\n",
       "      <td>97932.067482</td>\n",
       "      <td>1116.564363</td>\n",
       "      <td>12172.212426</td>\n",
       "      <td>10.502997</td>\n",
       "      <td>100372.504488</td>\n",
       "      <td>1.011783e+06</td>\n",
       "      <td>108852.296962</td>\n",
       "      <td>2.579040</td>\n",
       "      <td>...</td>\n",
       "      <td>10.859822</td>\n",
       "      <td>10.088023</td>\n",
       "      <td>988.135968</td>\n",
       "      <td>999.044639</td>\n",
       "      <td>105238.779040</td>\n",
       "      <td>106365.468525</td>\n",
       "      <td>10334.091649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107841.227180</td>\n",
       "      <td>2.472763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95373.022035</td>\n",
       "      <td>6293.442455</td>\n",
       "      <td>93371.369288</td>\n",
       "      <td>1034.722073</td>\n",
       "      <td>11618.142107</td>\n",
       "      <td>10.947611</td>\n",
       "      <td>109337.757279</td>\n",
       "      <td>1.006491e+06</td>\n",
       "      <td>104540.883376</td>\n",
       "      <td>2.573247</td>\n",
       "      <td>...</td>\n",
       "      <td>10.356015</td>\n",
       "      <td>10.514234</td>\n",
       "      <td>995.480813</td>\n",
       "      <td>898.329758</td>\n",
       "      <td>107044.005199</td>\n",
       "      <td>102704.104686</td>\n",
       "      <td>7697.875887</td>\n",
       "      <td>10.277760</td>\n",
       "      <td>103414.594212</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105066.272301</td>\n",
       "      <td>3279.162164</td>\n",
       "      <td>119554.079514</td>\n",
       "      <td>1114.014483</td>\n",
       "      <td>12127.235755</td>\n",
       "      <td>10.540204</td>\n",
       "      <td>106215.391332</td>\n",
       "      <td>1.022381e+06</td>\n",
       "      <td>109597.474506</td>\n",
       "      <td>2.693256</td>\n",
       "      <td>...</td>\n",
       "      <td>10.609811</td>\n",
       "      <td>10.991861</td>\n",
       "      <td>1117.179063</td>\n",
       "      <td>867.267810</td>\n",
       "      <td>100617.082858</td>\n",
       "      <td>108893.304959</td>\n",
       "      <td>6549.131099</td>\n",
       "      <td>9.337688</td>\n",
       "      <td>105722.857008</td>\n",
       "      <td>2.484935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98957.033333</td>\n",
       "      <td>4177.482190</td>\n",
       "      <td>97239.708338</td>\n",
       "      <td>1049.430921</td>\n",
       "      <td>10417.250336</td>\n",
       "      <td>10.618957</td>\n",
       "      <td>102736.470171</td>\n",
       "      <td>1.086871e+06</td>\n",
       "      <td>103340.057448</td>\n",
       "      <td>2.540610</td>\n",
       "      <td>...</td>\n",
       "      <td>10.397777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>863.943966</td>\n",
       "      <td>1041.278922</td>\n",
       "      <td>105352.672454</td>\n",
       "      <td>101705.692839</td>\n",
       "      <td>5388.312773</td>\n",
       "      <td>12.196382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.930136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x0           x1             x2           x3            x4  \\\n",
       "0  118345.392781  3104.010883   82378.542430  1086.678601  11395.883550   \n",
       "1            NaN  5889.055991   97932.067482  1116.564363  12172.212426   \n",
       "2   95373.022035  6293.442455   93371.369288  1034.722073  11618.142107   \n",
       "3  105066.272301  3279.162164  119554.079514  1114.014483  12127.235755   \n",
       "4   98957.033333  4177.482190   97239.708338  1049.430921  10417.250336   \n",
       "\n",
       "          x5             x6            x7             x8        x9  ...  \\\n",
       "0  10.455601  109886.476608  1.054926e+06  101877.946528  2.550290  ...   \n",
       "1  10.502997  100372.504488  1.011783e+06  108852.296962  2.579040  ...   \n",
       "2  10.947611  109337.757279  1.006491e+06  104540.883376  2.573247  ...   \n",
       "3  10.540204  106215.391332  1.022381e+06  109597.474506  2.693256  ...   \n",
       "4  10.618957  102736.470171  1.086871e+06  103340.057448  2.540610  ...   \n",
       "\n",
       "        x822       x823         x824         x825           x826  \\\n",
       "0  10.769524  10.245068  1021.907543  1031.645762  107440.039766   \n",
       "1  10.859822  10.088023   988.135968   999.044639  105238.779040   \n",
       "2  10.356015  10.514234   995.480813   898.329758  107044.005199   \n",
       "3  10.609811  10.991861  1117.179063   867.267810  100617.082858   \n",
       "4  10.397777        NaN   863.943966  1041.278922  105352.672454   \n",
       "\n",
       "            x827          x828       x829           x830      x831  \n",
       "0  107083.296966   5559.203921  10.861464  107548.413675  2.299202  \n",
       "1  106365.468525  10334.091649        NaN  107841.227180  2.472763  \n",
       "2  102704.104686   7697.875887  10.277760  103414.594212       NaN  \n",
       "3  108893.304959   6549.131099   9.337688  105722.857008  2.484935  \n",
       "4  101705.692839   5388.312773  12.196382            NaN  1.930136  \n",
       "\n",
       "[5 rows x 832 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = pd.read_csv(\"X_train.csv\")\n",
    "xtrain = xtrain.iloc[:, 1:]\n",
    "xtest = pd.read_csv(\"X_test.csv\")\n",
    "xtest = xtest.iloc[:, 1:]\n",
    "ytrain = pd.read_csv(\"Y_train.csv\")\n",
    "\n",
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118345.392781</td>\n",
       "      <td>3104.010883</td>\n",
       "      <td>82378.542430</td>\n",
       "      <td>1086.678601</td>\n",
       "      <td>11395.883550</td>\n",
       "      <td>10.455601</td>\n",
       "      <td>109886.476608</td>\n",
       "      <td>1.054926e+06</td>\n",
       "      <td>101877.946528</td>\n",
       "      <td>2.550290</td>\n",
       "      <td>...</td>\n",
       "      <td>10.769524</td>\n",
       "      <td>10.245068</td>\n",
       "      <td>1021.907543</td>\n",
       "      <td>1031.645762</td>\n",
       "      <td>107440.039766</td>\n",
       "      <td>107083.296966</td>\n",
       "      <td>5559.203921</td>\n",
       "      <td>10.861464</td>\n",
       "      <td>107548.413675</td>\n",
       "      <td>2.299202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100215.152009</td>\n",
       "      <td>5889.055991</td>\n",
       "      <td>97932.067482</td>\n",
       "      <td>1116.564363</td>\n",
       "      <td>12172.212426</td>\n",
       "      <td>10.502997</td>\n",
       "      <td>100372.504488</td>\n",
       "      <td>1.011783e+06</td>\n",
       "      <td>108852.296962</td>\n",
       "      <td>2.579040</td>\n",
       "      <td>...</td>\n",
       "      <td>10.859822</td>\n",
       "      <td>10.088023</td>\n",
       "      <td>988.135968</td>\n",
       "      <td>999.044639</td>\n",
       "      <td>105238.779040</td>\n",
       "      <td>106365.468525</td>\n",
       "      <td>10334.091649</td>\n",
       "      <td>9.977797</td>\n",
       "      <td>107841.227180</td>\n",
       "      <td>2.472763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95373.022035</td>\n",
       "      <td>6293.442455</td>\n",
       "      <td>93371.369288</td>\n",
       "      <td>1034.722073</td>\n",
       "      <td>11618.142107</td>\n",
       "      <td>10.947611</td>\n",
       "      <td>109337.757279</td>\n",
       "      <td>1.006491e+06</td>\n",
       "      <td>104540.883376</td>\n",
       "      <td>2.573247</td>\n",
       "      <td>...</td>\n",
       "      <td>10.356015</td>\n",
       "      <td>10.514234</td>\n",
       "      <td>995.480813</td>\n",
       "      <td>898.329758</td>\n",
       "      <td>107044.005199</td>\n",
       "      <td>102704.104686</td>\n",
       "      <td>7697.875887</td>\n",
       "      <td>10.277760</td>\n",
       "      <td>103414.594212</td>\n",
       "      <td>2.292501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105066.272301</td>\n",
       "      <td>3279.162164</td>\n",
       "      <td>119554.079514</td>\n",
       "      <td>1114.014483</td>\n",
       "      <td>12127.235755</td>\n",
       "      <td>10.540204</td>\n",
       "      <td>106215.391332</td>\n",
       "      <td>1.022381e+06</td>\n",
       "      <td>109597.474506</td>\n",
       "      <td>2.693256</td>\n",
       "      <td>...</td>\n",
       "      <td>10.609811</td>\n",
       "      <td>10.991861</td>\n",
       "      <td>1117.179063</td>\n",
       "      <td>867.267810</td>\n",
       "      <td>100617.082858</td>\n",
       "      <td>108893.304959</td>\n",
       "      <td>6549.131099</td>\n",
       "      <td>9.337688</td>\n",
       "      <td>105722.857008</td>\n",
       "      <td>2.484935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98957.033333</td>\n",
       "      <td>4177.482190</td>\n",
       "      <td>97239.708338</td>\n",
       "      <td>1049.430921</td>\n",
       "      <td>10417.250336</td>\n",
       "      <td>10.618957</td>\n",
       "      <td>102736.470171</td>\n",
       "      <td>1.086871e+06</td>\n",
       "      <td>103340.057448</td>\n",
       "      <td>2.540610</td>\n",
       "      <td>...</td>\n",
       "      <td>10.397777</td>\n",
       "      <td>10.538567</td>\n",
       "      <td>863.943966</td>\n",
       "      <td>1041.278922</td>\n",
       "      <td>105352.672454</td>\n",
       "      <td>101705.692839</td>\n",
       "      <td>5388.312773</td>\n",
       "      <td>12.196382</td>\n",
       "      <td>104901.792534</td>\n",
       "      <td>1.930136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x0           x1             x2           x3            x4  \\\n",
       "0  118345.392781  3104.010883   82378.542430  1086.678601  11395.883550   \n",
       "1  100215.152009  5889.055991   97932.067482  1116.564363  12172.212426   \n",
       "2   95373.022035  6293.442455   93371.369288  1034.722073  11618.142107   \n",
       "3  105066.272301  3279.162164  119554.079514  1114.014483  12127.235755   \n",
       "4   98957.033333  4177.482190   97239.708338  1049.430921  10417.250336   \n",
       "\n",
       "          x5             x6            x7             x8        x9  ...  \\\n",
       "0  10.455601  109886.476608  1.054926e+06  101877.946528  2.550290  ...   \n",
       "1  10.502997  100372.504488  1.011783e+06  108852.296962  2.579040  ...   \n",
       "2  10.947611  109337.757279  1.006491e+06  104540.883376  2.573247  ...   \n",
       "3  10.540204  106215.391332  1.022381e+06  109597.474506  2.693256  ...   \n",
       "4  10.618957  102736.470171  1.086871e+06  103340.057448  2.540610  ...   \n",
       "\n",
       "        x822       x823         x824         x825           x826  \\\n",
       "0  10.769524  10.245068  1021.907543  1031.645762  107440.039766   \n",
       "1  10.859822  10.088023   988.135968   999.044639  105238.779040   \n",
       "2  10.356015  10.514234   995.480813   898.329758  107044.005199   \n",
       "3  10.609811  10.991861  1117.179063   867.267810  100617.082858   \n",
       "4  10.397777  10.538567   863.943966  1041.278922  105352.672454   \n",
       "\n",
       "            x827          x828       x829           x830      x831  \n",
       "0  107083.296966   5559.203921  10.861464  107548.413675  2.299202  \n",
       "1  106365.468525  10334.091649   9.977797  107841.227180  2.472763  \n",
       "2  102704.104686   7697.875887  10.277760  103414.594212  2.292501  \n",
       "3  108893.304959   6549.131099   9.337688  105722.857008  2.484935  \n",
       "4  101705.692839   5388.312773  12.196382  104901.792534  1.930136  \n",
       "\n",
       "[5 rows x 832 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treat missing values as column medians. Important (apparently) to use the medians from the training set in the test set\n",
    "\n",
    "xtrain = xtrain.fillna(xtrain.median())\n",
    "xtest = xtest.fillna(xtrain.median())\n",
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and test data\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "xtrain_scaled = scaler.fit_transform(xtrain)\n",
    "xtrain = pd.DataFrame(xtrain_scaled, columns = xtrain.columns)\n",
    "xtrain.head()\n",
    "\n",
    "xtest_scaled = scaler.fit_transform(xtest)\n",
    "xtest = pd.DataFrame(xtest_scaled, columns = xtest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y\n",
       "0  75.0\n",
       "1  53.0\n",
       "2  78.0\n",
       "3  65.0\n",
       "4  86.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove unnecessary id column from ytrain that just ***** things up\n",
    "\n",
    "ytrain1 = ytrain.loc[:, \"y\"]\n",
    "ytrain2 = pd.DataFrame(data = ytrain1.values, columns= ['y'])\n",
    "#ytrain2.head()\n",
    "ytrain = ytrain2\n",
    "ytrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features with zero weight from Lasso\n",
    "\n",
    "clf = Lasso(alpha=0.3)\n",
    "clf.fit(xtrain, ytrain)\n",
    "\n",
    "features = (clf.coef_ != 0)\n",
    "\n",
    "xtrain = xtrain.loc[:, features]\n",
    "xtest = xtest.loc[:, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x4</th>\n",
       "      <th>x12</th>\n",
       "      <th>x22</th>\n",
       "      <th>x64</th>\n",
       "      <th>x84</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x108</th>\n",
       "      <th>x120</th>\n",
       "      <th>x129</th>\n",
       "      <th>...</th>\n",
       "      <th>x757</th>\n",
       "      <th>x760</th>\n",
       "      <th>x766</th>\n",
       "      <th>x769</th>\n",
       "      <th>x786</th>\n",
       "      <th>x797</th>\n",
       "      <th>x809</th>\n",
       "      <th>x821</th>\n",
       "      <th>x830</th>\n",
       "      <th>Absolute mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.454476</td>\n",
       "      <td>0.641522</td>\n",
       "      <td>-0.526024</td>\n",
       "      <td>-0.740642</td>\n",
       "      <td>0.199223</td>\n",
       "      <td>-0.373272</td>\n",
       "      <td>-0.236610</td>\n",
       "      <td>0.577454</td>\n",
       "      <td>-0.619985</td>\n",
       "      <td>1.033877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869597</td>\n",
       "      <td>-0.170054</td>\n",
       "      <td>1.734303</td>\n",
       "      <td>-0.323955</td>\n",
       "      <td>0.403708</td>\n",
       "      <td>-0.628594</td>\n",
       "      <td>-0.275974</td>\n",
       "      <td>-0.008390</td>\n",
       "      <td>0.925679</td>\n",
       "      <td>0.673178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.265954</td>\n",
       "      <td>-1.201704</td>\n",
       "      <td>1.512451</td>\n",
       "      <td>1.073093</td>\n",
       "      <td>0.501196</td>\n",
       "      <td>0.338884</td>\n",
       "      <td>-0.554347</td>\n",
       "      <td>0.195198</td>\n",
       "      <td>0.406709</td>\n",
       "      <td>1.090254</td>\n",
       "      <td>...</td>\n",
       "      <td>1.726109</td>\n",
       "      <td>1.860696</td>\n",
       "      <td>-0.711604</td>\n",
       "      <td>0.498500</td>\n",
       "      <td>-1.434010</td>\n",
       "      <td>1.377539</td>\n",
       "      <td>-0.275974</td>\n",
       "      <td>0.016619</td>\n",
       "      <td>1.031616</td>\n",
       "      <td>1.010956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.686798</td>\n",
       "      <td>0.428108</td>\n",
       "      <td>-0.754718</td>\n",
       "      <td>1.580733</td>\n",
       "      <td>-1.178433</td>\n",
       "      <td>-0.047456</td>\n",
       "      <td>0.622922</td>\n",
       "      <td>0.656719</td>\n",
       "      <td>0.759553</td>\n",
       "      <td>0.926249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345276</td>\n",
       "      <td>-0.596208</td>\n",
       "      <td>0.278350</td>\n",
       "      <td>2.099532</td>\n",
       "      <td>0.965567</td>\n",
       "      <td>-1.926625</td>\n",
       "      <td>6.953003</td>\n",
       "      <td>0.936008</td>\n",
       "      <td>-0.569888</td>\n",
       "      <td>0.975555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.218941</td>\n",
       "      <td>-0.370244</td>\n",
       "      <td>-0.479087</td>\n",
       "      <td>-0.106118</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-1.280235</td>\n",
       "      <td>-0.346958</td>\n",
       "      <td>-0.270578</td>\n",
       "      <td>-1.252627</td>\n",
       "      <td>1.938747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461303</td>\n",
       "      <td>1.026596</td>\n",
       "      <td>-0.018393</td>\n",
       "      <td>-0.091943</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-1.171589</td>\n",
       "      <td>0.152069</td>\n",
       "      <td>0.454378</td>\n",
       "      <td>0.265215</td>\n",
       "      <td>0.779240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.431533</td>\n",
       "      <td>-1.321807</td>\n",
       "      <td>0.435917</td>\n",
       "      <td>1.641302</td>\n",
       "      <td>-1.138132</td>\n",
       "      <td>1.700972</td>\n",
       "      <td>0.075747</td>\n",
       "      <td>-1.851014</td>\n",
       "      <td>1.525983</td>\n",
       "      <td>-0.560213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080972</td>\n",
       "      <td>-0.909855</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>0.628030</td>\n",
       "      <td>0.377739</td>\n",
       "      <td>-0.453301</td>\n",
       "      <td>1.573082</td>\n",
       "      <td>1.091439</td>\n",
       "      <td>-0.031837</td>\n",
       "      <td>0.805025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x4       x12       x22       x64       x84       x93       x94  \\\n",
       "0  1.454476  0.641522 -0.526024 -0.740642  0.199223 -0.373272 -0.236610   \n",
       "1  2.265954 -1.201704  1.512451  1.073093  0.501196  0.338884 -0.554347   \n",
       "2  1.686798  0.428108 -0.754718  1.580733 -1.178433 -0.047456  0.622922   \n",
       "3  2.218941 -0.370244 -0.479087 -0.106118 -0.020148 -1.280235 -0.346958   \n",
       "4  0.431533 -1.321807  0.435917  1.641302 -1.138132  1.700972  0.075747   \n",
       "\n",
       "       x108      x120      x129  ...      x757      x760      x766      x769  \\\n",
       "0  0.577454 -0.619985  1.033877  ...  0.869597 -0.170054  1.734303 -0.323955   \n",
       "1  0.195198  0.406709  1.090254  ...  1.726109  1.860696 -0.711604  0.498500   \n",
       "2  0.656719  0.759553  0.926249  ...  0.345276 -0.596208  0.278350  2.099532   \n",
       "3 -0.270578 -1.252627  1.938747  ...  0.461303  1.026596 -0.018393 -0.091943   \n",
       "4 -1.851014  1.525983 -0.560213  ...  0.080972 -0.909855  0.139201  0.628030   \n",
       "\n",
       "       x786      x797      x809      x821      x830  Absolute mean  \n",
       "0  0.403708 -0.628594 -0.275974 -0.008390  0.925679       0.673178  \n",
       "1 -1.434010  1.377539 -0.275974  0.016619  1.031616       1.010956  \n",
       "2  0.965567 -1.926625  6.953003  0.936008 -0.569888       0.975555  \n",
       "3 -1.357529 -1.171589  0.152069  0.454378  0.265215       0.779240  \n",
       "4  0.377739 -0.453301  1.573082  1.091439 -0.031837       0.805025  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain[\"Absolute mean\"] = np.absolute(xtrain).mean(axis = 1)\n",
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x4</th>\n",
       "      <th>x12</th>\n",
       "      <th>x22</th>\n",
       "      <th>x64</th>\n",
       "      <th>x84</th>\n",
       "      <th>x93</th>\n",
       "      <th>x94</th>\n",
       "      <th>x108</th>\n",
       "      <th>x120</th>\n",
       "      <th>x129</th>\n",
       "      <th>...</th>\n",
       "      <th>x752</th>\n",
       "      <th>x757</th>\n",
       "      <th>x760</th>\n",
       "      <th>x766</th>\n",
       "      <th>x769</th>\n",
       "      <th>x786</th>\n",
       "      <th>x797</th>\n",
       "      <th>x809</th>\n",
       "      <th>x821</th>\n",
       "      <th>x830</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.454476</td>\n",
       "      <td>0.641522</td>\n",
       "      <td>-0.526024</td>\n",
       "      <td>-0.740642</td>\n",
       "      <td>0.199223</td>\n",
       "      <td>-0.373272</td>\n",
       "      <td>-0.236610</td>\n",
       "      <td>0.577454</td>\n",
       "      <td>-0.619985</td>\n",
       "      <td>1.033877</td>\n",
       "      <td>...</td>\n",
       "      <td>1.147683</td>\n",
       "      <td>0.869597</td>\n",
       "      <td>-0.170054</td>\n",
       "      <td>1.734303</td>\n",
       "      <td>-0.323955</td>\n",
       "      <td>0.403708</td>\n",
       "      <td>-0.628594</td>\n",
       "      <td>-0.275974</td>\n",
       "      <td>-0.008390</td>\n",
       "      <td>0.925679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.218941</td>\n",
       "      <td>-0.370244</td>\n",
       "      <td>-0.479087</td>\n",
       "      <td>-0.106118</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-1.280235</td>\n",
       "      <td>-0.346958</td>\n",
       "      <td>-0.270578</td>\n",
       "      <td>-1.252627</td>\n",
       "      <td>1.938747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580023</td>\n",
       "      <td>0.461303</td>\n",
       "      <td>1.026596</td>\n",
       "      <td>-0.018393</td>\n",
       "      <td>-0.091943</td>\n",
       "      <td>-1.357529</td>\n",
       "      <td>-1.171589</td>\n",
       "      <td>0.152069</td>\n",
       "      <td>0.454378</td>\n",
       "      <td>0.265215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.431533</td>\n",
       "      <td>-1.321807</td>\n",
       "      <td>0.435917</td>\n",
       "      <td>1.641302</td>\n",
       "      <td>-1.138132</td>\n",
       "      <td>1.700972</td>\n",
       "      <td>0.075747</td>\n",
       "      <td>-1.851014</td>\n",
       "      <td>1.525983</td>\n",
       "      <td>-0.560213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334431</td>\n",
       "      <td>0.080972</td>\n",
       "      <td>-0.909855</td>\n",
       "      <td>0.139201</td>\n",
       "      <td>0.628030</td>\n",
       "      <td>0.377739</td>\n",
       "      <td>-0.453301</td>\n",
       "      <td>1.573082</td>\n",
       "      <td>1.091439</td>\n",
       "      <td>-0.031837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.036660</td>\n",
       "      <td>-0.007466</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>0.138172</td>\n",
       "      <td>-0.112458</td>\n",
       "      <td>2.103257</td>\n",
       "      <td>-1.682375</td>\n",
       "      <td>0.125008</td>\n",
       "      <td>2.010082</td>\n",
       "      <td>0.608177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159213</td>\n",
       "      <td>0.080972</td>\n",
       "      <td>2.433026</td>\n",
       "      <td>0.149947</td>\n",
       "      <td>-0.561947</td>\n",
       "      <td>-0.167011</td>\n",
       "      <td>-0.100310</td>\n",
       "      <td>-0.887822</td>\n",
       "      <td>0.111470</td>\n",
       "      <td>0.110551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.389393</td>\n",
       "      <td>0.488456</td>\n",
       "      <td>-0.201728</td>\n",
       "      <td>-0.009973</td>\n",
       "      <td>-0.479038</td>\n",
       "      <td>-1.249154</td>\n",
       "      <td>-1.455774</td>\n",
       "      <td>0.379499</td>\n",
       "      <td>-0.695547</td>\n",
       "      <td>-0.980907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420681</td>\n",
       "      <td>0.493678</td>\n",
       "      <td>0.742838</td>\n",
       "      <td>0.223970</td>\n",
       "      <td>-1.237522</td>\n",
       "      <td>1.460016</td>\n",
       "      <td>1.852793</td>\n",
       "      <td>-0.468339</td>\n",
       "      <td>-0.186732</td>\n",
       "      <td>1.355413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x4       x12       x22       x64       x84       x93       x94  \\\n",
       "0  1.454476  0.641522 -0.526024 -0.740642  0.199223 -0.373272 -0.236610   \n",
       "3  2.218941 -0.370244 -0.479087 -0.106118 -0.020148 -1.280235 -0.346958   \n",
       "4  0.431533 -1.321807  0.435917  1.641302 -1.138132  1.700972  0.075747   \n",
       "6 -0.036660 -0.007466  0.036855  0.138172 -0.112458  2.103257 -1.682375   \n",
       "8 -0.389393  0.488456 -0.201728 -0.009973 -0.479038 -1.249154 -1.455774   \n",
       "\n",
       "       x108      x120      x129  ...      x752      x757      x760      x766  \\\n",
       "0  0.577454 -0.619985  1.033877  ...  1.147683  0.869597 -0.170054  1.734303   \n",
       "3 -0.270578 -1.252627  1.938747  ...  0.580023  0.461303  1.026596 -0.018393   \n",
       "4 -1.851014  1.525983 -0.560213  ...  0.334431  0.080972 -0.909855  0.139201   \n",
       "6  0.125008  2.010082  0.608177  ...  0.159213  0.080972  2.433026  0.149947   \n",
       "8  0.379499 -0.695547 -0.980907  ...  0.420681  0.493678  0.742838  0.223970   \n",
       "\n",
       "       x769      x786      x797      x809      x821      x830  \n",
       "0 -0.323955  0.403708 -0.628594 -0.275974 -0.008390  0.925679  \n",
       "3 -0.091943 -1.357529 -1.171589  0.152069  0.454378  0.265215  \n",
       "4  0.628030  0.377739 -0.453301  1.573082  1.091439 -0.031837  \n",
       "6 -0.561947 -0.167011 -0.100310 -0.887822  0.111470  0.110551  \n",
       "8 -1.237522  1.460016  1.852793 -0.468339 -0.186732  1.355413  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.count_nonzero(xtrain[\"Absolute mean\"] > 0.85)\n",
    "x = xtrain[xtrain[\"Absolute mean\"] < 0.85]\n",
    "x = x.drop([\"Absolute mean\"], axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.39631358389202626,\n",
       " 0.3798309341940291,\n",
       " 0.39551005128775796,\n",
       " 0.3899030476409952,\n",
       " 0.3853602315103709,\n",
       " 0.38914714805296524,\n",
       " 0.39246316701883316,\n",
       " 0.39408578874526295,\n",
       " 0.3915646882524771,\n",
       " 0.3896368587433562,\n",
       " 0.3873838416738572,\n",
       " 0.37994890344287946,\n",
       " 0.3857371983663966,\n",
       " 0.3817585986063733,\n",
       " 0.35827971752788557,\n",
       " 0.36712571769717334]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lasso with alpha = 0.3 and different values of the outlier parameter\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "outlier_param = np.array([1.1, 1.09, 1.08, 1.07, 1.06, 1.05, 1.04, 1.03, 1.02, 1.01, 1, 0.98, 0.96, 0.94, 0.92, 0.9])\n",
    "meanscores = []\n",
    "for i in outlier_param:\n",
    "    x = xtrain[xtrain[\"Absolute mean\"] < i].drop([\"Absolute mean\"], axis=1).values\n",
    "    y = ytrain[xtrain[\"Absolute mean\"] < i].values\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        X_train = x[train_index]\n",
    "        X_test = x[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        clf = Lasso(alpha=0.3, max_iter=5000)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        Y_pred = clf.predict(X_test)\n",
    "        scores.append(r2_score(y_test, Y_pred))\n",
    "    meanscores.append(np.mean(scores))\n",
    "    \n",
    "meanscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
